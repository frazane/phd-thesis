@article{hohlein_comparative_2020,
	title = {A comparative study of convolutional neural network models for wind field downscaling},
	volume = {27},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.1961},
	doi = {10.1002/met.1961},
	abstract = {Abstract 
            We analyze the applicability of convolutional neural network ({CNN}) architectures for downscaling of short‐range forecasts of near‐surface winds on extended spatial domains. Short‐range wind forecasts (at the 100 m level) from European Centre for Medium Range Weather Forecasts {ERA}5 reanalysis initial conditions at 31 km horizontal resolution are downscaled to mimic high resolution ({HRES}) (deterministic) short‐range forecasts at 9 km resolution. We evaluate the downscaling quality of four exemplary {CNN} architectures and compare these against a multilinear regression model. We conduct a qualitative and quantitative comparison of model predictions and examine whether the predictive skill of {CNNs} can be enhanced by incorporating additional atmospheric variables, such as geopotential height and forecast surface roughness, or static high‐resolution fields, like land–sea mask and topography. We further propose {DeepRU}, a novel U‐Net‐based {CNN} architecture, which is able to infer situation‐dependent wind structures that cannot be reconstructed by other models. Inferring a target 9 km resolution wind field from the low‐resolution input fields over the Alpine area takes less than 10 ms on our graphics processing unit target architecture, which compares favorably to an overhead in simulation time of minutes or hours between low‐ and high‐resolution forecast simulations.},
	pages = {e1961},
	number = {6},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Höhlein, Kevin and Kern, Michael and Hewson, Timothy and Westermann, Rüdiger},
	urldate = {2024-06-25},
	date = {2020-11},
	langid = {english},
}

@article{allen_conditional_2023,
	title = {A conditional decomposition of proper scores: quantifying the sources of information in a forecast},
	volume = {149},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4478},
	doi = {10.1002/qj.4478},
	shorttitle = {A conditional decomposition of proper scores},
	abstract = {Abstract 
            Scoring rules condense all information regarding the performance of a probabilistic forecast into a single numerical value, providing a convenient framework with which to rank and compare competing prediction schemes objectively. Although scoring rules provide only a single measure of forecast accuracy, the expected score can be decomposed into components that each assess a distinct aspect of the forecast, such as its calibration or information content. Since these components could depend on several factors, it is useful to evaluate forecast performance under different circumstances; if a forecaster were able to identify situations in which their forecasts perform particularly poorly, then they could more easily develop their forecast strategy to account for these deficiencies. To help forecasters identify such situations, a novel decomposition of scores is introduced that quantifies conditional forecast biases, allowing for a more detailed examination of the sources of information in the forecast. From this, we claim that decompositions of proper scores provide a broad generalisation of the well‐known analysis of variance ({ANOVA}) framework. The new decomposition is applied to the Brier score, which is then used to evaluate forecasts that the daily maximum temperature will exceed a range of thresholds, issued by the Swiss Federal Office of Meteorology and Climatology ({MeteoSwiss}). We demonstrate how the additional information provided by this decomposition can be used to improve the performance of these forecasts, by identifying appropriate auxiliary information to include within statistical postprocessing methods.},
	pages = {1704--1725},
	number = {754},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Allen, Sam and Ferro, Christopher A. T. and Kwasniok, Frank},
	urldate = {2024-05-21},
	date = {2023-07},
	langid = {english},
	keywords = {scoring rules, verification},
}

@article{han_deep_2021,
	title = {A Deep Learning Method for Bias Correction of {ECMWF} 24–240 h Forecasts},
	volume = {38},
	issn = {1861-9533},
	url = {https://doi.org/10.1007/s00376-021-0215-y},
	doi = {10.1007/s00376-021-0215-y},
	abstract = {Correcting the forecast bias of numerical weather prediction models is important for severe weather warnings. The refined grid forecast requires direct correction on gridded forecast products, as opposed to correcting forecast data only at individual weather stations. In this study, a deep learning method called {CU}-net is proposed to correct the gridded forecasts of four weather variables from the European Centre for Medium-Range Weather Forecast Integrated Forecasting System global model ({ECMWF}-{IFS}): 2-m temperature, 2-m relative humidity, 10-m wind speed, and 10-m wind direction, with a forecast lead time of 24 h to 240 h in North China. First, the forecast correction problem is transformed into an image-to-image translation problem in deep learning under the {CU}-net architecture, which is based on convolutional neural networks. Second, the {ECMWF}-{IFS} forecasts and {ECMWF} reanalysis data ({ERA}5) from 2005 to 2018 are used as training, validation, and testing datasets. The predictors and labels (ground truth) of the model are created using the {ECMWF}-{IFS} and {ERA}5, respectively. Finally, the correction performance of {CU}-net is compared with a conventional method, anomaly numerical correction with observations ({ANO}). Results show that forecasts from {CU}-net have lower root mean square error, bias, mean absolute error, and higher correlation coefficient than those from {ANO} for all forecast lead times from 24 h to 240 h. {CU}-net improves upon the {ECMWF}-{IFS} forecast for all four weather variables in terms of the above evaluation metrics, whereas {ANO} improves upon {ECMWF}-{IFS} performance only for 2-m temperature and relative humidity. For the correction of the 10-m wind direction forecast, which is often difficult to achieve, {CU}-net also improves the correction performance.},
	pages = {1444--1459},
	number = {9},
	journaltitle = {Advances in Atmospheric Sciences},
	shortjournal = {Adv. Atmos. Sci.},
	author = {Han, Lei and Chen, Mingxuan and Chen, Kangkai and Chen, Haonan and Zhang, Yanbiao and Lu, Bing and Song, Linye and Qin, Rui},
	urldate = {2024-05-22},
	date = {2021-09-01},
	langid = {english},
	keywords = {deep learning, post-processing},
}

@article{kirkwood_framework_2021,
	title = {A framework for probabilistic weather forecast post-processing across models and lead times using machine learning},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0099},
	doi = {10.1098/rsta.2020.0099},
	abstract = {Forecasting the weather is an increasingly data-intensive exercise. Numerical weather prediction ({NWP}) models are becoming more complex, with higher resolutions, and there are increasing numbers of different models in operation. While the forecasting skill of {NWP} models continues to improve, the number and complexity of these models poses a new challenge for the operational meteorologist: how should the information from all available models, each with their own unique biases and limitations, be combined in order to provide stakeholders with well-calibrated probabilistic forecasts to use in decision making? In this paper, we use a road surface temperature example to demonstrate a three-stage framework that uses machine learning to bridge the gap between sets of separate forecasts from {NWP} models and the ‘ideal’ forecast for decision support: probabilities of future weather outcomes. First, we use quantile regression forests to learn the error profile of each numerical model, and use these to apply empirically derived probability distributions to forecasts. Second, we combine these probabilistic forecasts using quantile averaging. Third, we interpolate between the aggregate quantiles in order to generate a full predictive distribution, which we demonstrate has properties suitable for decision support. Our results suggest that this approach provides an effective and operationally viable framework for the cohesive post-processing of weather forecasts across multiple models and lead times to produce a well-calibrated probabilistic output.This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	pages = {20200099},
	number = {2194},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Kirkwood, Charlie and Economou, Theo and Odbert, Henry and Pugeault, Nicolas},
	urldate = {2021-10-13},
	date = {2021-04-05},
	keywords = {post-processing, quantile regression},
}

@article{murphy_general_1987,
	title = {A General Framework for Forecast Verification},
	volume = {115},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/115/7/1520-0493_1987_115_1330_agfffv_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1987)115<1330:AGFFFV>2.0.CO;2},
	abstract = {Abstract A general framework for forecast verification based on the joint distribution of forecasts and observations is described. For further elaboration of the framework, two factorizations of the joint distribution are investigated: 1) the calibration-refinement factorization, which involves the conditional distributions of observations given forecasts and the marginal distribution of forecasts, and 2) the likelihood-base factorization, which involve the conditional distributions of forecasts given observations and the marginal distribution of observations. The names given to the factorizations reflect the fact that they relate to different attributes of the forecasts and/or observations. Several examples are used to illustrate the interpretation of these factorizations in the context of verification and to describe the relationship between the respective factorizations. Some insight into the potential utility of the framework is provided by demonstrating that basic elements and summary measures of the joint, conditional, and marginal distributions play key roles in current verification methods. The need for further investigation of the implications of this framework for verification theory and practice is emphasized, and some possible directions for future research in this area are identified.},
	pages = {1330--1338},
	number = {7},
	journaltitle = {Monthly Weather Review},
	author = {Murphy, Allan H. and Winkler, Robert L.},
	urldate = {2024-06-11},
	date = {1987-07-01},
	keywords = {verification},
}

@article{wang_geostatistical_2016,
	title = {A geostatistical approach to the change-of-support problem and variable-support data fusion in spatial analysis},
	volume = {18},
	issn = {1435-5949},
	url = {https://doi.org/10.1007/s10109-015-0224-4},
	doi = {10.1007/s10109-015-0224-4},
	abstract = {A key issue to address in synthesizing spatial data with variable-support in spatial analysis and modeling is the change-of-support problem. We present an approach for solving the change-of-support and variable-support data fusion problems. This approach is based on geostatistical inverse modeling that explicitly accounts for differences in spatial support. The inverse model is applied here to produce both the best predictions of a target support and prediction uncertainties, based on one or more measurements, while honoring measurements. Spatial data covering large geographic areas often exhibit spatial nonstationarity and can lead to computational challenge due to the large data size. We developed a local-window geostatistical inverse modeling approach to accommodate these issues of spatial nonstationarity and alleviate computational burden. We conducted experiments using synthetic and real-world raster data. Synthetic data were generated and aggregated to multiple supports and downscaled back to the original support to analyze the accuracy of spatial predictions and the correctness of prediction uncertainties. Similar experiments were conducted for real-world raster data. Real-world data with variable-support were statistically fused to produce single-support predictions and associated uncertainties. The modeling results demonstrate that geostatistical inverse modeling can produce accurate predictions and associated prediction uncertainties. It is shown that the local-window geostatistical inverse modeling approach suggested offers a practical way to solve the well-known change-of-support problem and variable-support data fusion problem in spatial analysis and modeling.},
	pages = {45--66},
	number = {1},
	journaltitle = {Journal of Geographical Systems},
	shortjournal = {J Geogr Syst},
	author = {Wang, Jun and Wang, Yang and Zeng, Hui},
	urldate = {2024-07-21},
	date = {2016-01-01},
	langid = {english},
	keywords = {geostatistics},
}

@article{born_global_2021,
	title = {A global meta-analysis of climate services and decision-making in agriculture},
	volume = {22},
	issn = {2405-8807},
	url = {https://www.sciencedirect.com/science/article/pii/S2405880721000194},
	doi = {10.1016/j.cliser.2021.100231},
	abstract = {Harmonizing the supply of climate information with the type of information needed by next-users is crucial for effective weather and climate services ({CS}). Understanding of information demand could help reshape supply-side based {CS} that have dominated the field over the last few decades. Most {CS} have been developed using a ‘loading dock’ model, whereby products are designed by information suppliers with little input from or consultation with users of climate services. Notably, a focus on climate modelling and prediction has largely resulted in a lack of consideration of the demand-side when producing climate services. Here, we contribute to understanding of {CS} demand by presenting a global meta-analysis – a ‘decision matrix’ - of farmers’ climate-influenced decisions. We identify 41 studies that encompass 186 decisions, three forecast timescales (weather, dekadal, seasonal), and five forecast variables (precipitation, temperature, wind, soil moisture and soil temperature). Several insights were offered by this literature review into the value of climate services and the way forward in considering users’ needs. We find that the seasonal precipitation is the most frequently used forecast variable for decision-making, particularly of crop sowing date. Forecasts such as temperature, soil moisture and soil temperature appeared to be less used by farmers, according to the decision matrix. It is apparent that more investigation is necessary into how farmers use climate information in their decision-making to better establish the value of {CS}. We suggest that different sectors should make their respective decision matrices to explore decision spaces and engage with users of climate information in various sectors.},
	pages = {100231},
	journaltitle = {Climate Services},
	shortjournal = {Climate Services},
	author = {Born, Lorna and Prager, Steven and Ramirez-Villegas, Julian and Imbach, Pablo},
	urldate = {2024-03-29},
	date = {2021-04-01},
	keywords = {decision-making, weather and climate services},
}

@article{hewson_low-cost_2021,
	title = {A low-cost post-processing technique improves weather forecasts around the world},
	volume = {2},
	rights = {2021 The Author(s)},
	issn = {2662-4435},
	url = {https://www.nature.com/articles/s43247-021-00185-9},
	doi = {10.1038/s43247-021-00185-9},
	abstract = {Computer-generated weather forecasts divide the Earth’s surface into gridboxes, each currently spanning about 400 km2, and predict one value per gridbox. If weather varies markedly within a gridbox, forecasts for specific sites inevitably fail. Here we present a statistical post-processing method for ensemble forecasts that accounts for the degree of variation within each gridbox, bias on the gridbox scale, and the weather dependence of each. When applying this post-processing, skill improves substantially across the globe; for extreme rainfall, for example, useful forecasts extend 5 days ahead, compared to less than 1 day without post-processing. Skill improvements are attributed to creation of huge calibration datasets by aggregating, globally rather than locally, forecast-observation differences wherever and whenever the observed “weather type” was similar. A strong focus on meteorological understanding also contributes. We suggest that applications for our methodology include improved flash flood warnings, physics-related insights into model weaknesses and global pointwise re-analyses.},
	pages = {1--10},
	number = {1},
	journaltitle = {Communications Earth \& Environment},
	shortjournal = {Commun Earth Environ},
	author = {Hewson, Timothy David and Pillosu, Fatima Maria},
	urldate = {2024-07-23},
	date = {2021-06-23},
	langid = {english},
	keywords = {post-processing, precipitation},
}

@article{jiang_new_2023,
	title = {A New Method for Postprocessing Numerical Weather Predictions Using Quantile Mapping in the Frequency Domain},
	volume = {151},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/151/8/MWR-D-22-0217.1.xml},
	doi = {10.1175/MWR-D-22-0217.1},
	abstract = {Abstract Improving lead time for forecasting floods is important to minimize property damage and ensure the safety of the public and emergency services during flood events. Numerical weather prediction ({NWP}) models are important components of flood forecasting systems and have been vital in extending forecasting lead time under complex weather and terrain conditions. However, {NWP} forecasts still have significant uncertainty associated with the precipitation fields that are the main inputs of the hydrologic models and thus the resulting flood forecasts. An issue often overlooked is the importance of correctly representing variability over a range of different temporal scales. To address this gap, here a new wavelet-based method for postprocessing {NWP} precipitation forecasts is proposed. First, precipitation forecasts are decomposed into the frequency domain using a wavelet transform, providing estimates of the amplitudes and phases of the time series at different frequencies. Quantile mapping is then used to correct bias in the amplitudes of each frequency. Randomized phases are used to generate an ensemble of realizations of the precipitation forecasts. The postprocessed precipitation forecasts are reconstructed by taking the inverse of adjusted time-frequency decompositions with the corrected amplitudes and randomized phases. The proposed method was used to postprocess {NWP} precipitation forecasts in the Sydney region of Australia. There is a significant improvement in postprocessed precipitation forecasts across multiple time scales in terms of bias and temporal and spatial correlation structures. The postprocessed precipitation fields can be used for the modeling of fully distributed hydrologic systems, improving runoff stimulation, flood depth estimation, and flood early warning. Significance Statement A new method accounting for the timing and spatial errors of {NWP} precipitation forecasts is proposed, and it can improve the skill of forecasts across multiple time scales, especially at short lead times. The proposed method provides a practical and effective way to correct these errors by incorporating spatiotemporal neighborhood information through the frequency domain using sophisticated wavelet transforms. With systematic timing and spatial errors removed, precipitation forecasts will be more skillful, and hydrological modeling using the postprocessed forecasts can provide higher accuracy of streamflow estimation.},
	pages = {1909--1925},
	number = {8},
	journaltitle = {Monthly Weather Review},
	author = {Jiang, Ze and Johnson, Fiona},
	urldate = {2024-05-22},
	date = {2023-07-25},
	keywords = {post-processing, quantile mapping},
}

@article{murphy_note_1967,
	title = {A Note on Probability Forecasts and “Hedging”},
	volume = {6},
	issn = {1520-0450},
	url = {https://journals.ametsoc.org/view/journals/apme/6/6/1520-0450_1967_006_1002_anopfa_2_0_co_2.xml},
	doi = {10.1175/1520-0450(1967)006<1002:ANOPFA>2.0.CO;2},
	abstract = {Abstract The consideration of a maxim and a statement, both of which are concerned with “hedging” on the part of meteorologists who prepare probability forecasts, leads to the identification of a property which all proper scoring systems for such forecasts should possess. A scoring system, to be proper, should encourage the meteorologist to make his probabilities correspond to his true beliefs. The conditions which a proper scoring system must satisfy are formulated in mathematical terms. Several existing scoring systems are examined to ascertain whether or not the systems are proper.},
	pages = {1002--1004},
	number = {6},
	journaltitle = {Journal of Applied Meteorology and Climatology},
	author = {Murphy, Allan H. and Epstein, Edward S.},
	urldate = {2024-07-17},
	date = {1967-12-01},
}

@article{murphy_note_1966,
	title = {A Note on the Utility of Probabilistic Predictions and the Probability Score in the Cost-Loss Ratio Decision Situation},
	volume = {5},
	issn = {1520-0450},
	url = {https://journals.ametsoc.org/view/journals/apme/5/4/1520-0450_1966_005_0534_anotuo_2_0_co_2.xml},
	doi = {10.1175/1520-0450(1966)005<0534:ANOTUO>2.0.CO;2},
	abstract = {Abstract},
	pages = {534--537},
	number = {4},
	journaltitle = {Journal of Applied Meteorology and Climatology},
	author = {Murphy, Allan H.},
	urldate = {2024-06-11},
	date = {1966-08-01},
	note = {Publisher: American Meteorological Society
Section: Journal of Applied Meteorology and Climatology},
	keywords = {weather and climate services},
}

@article{raisanen_probability_2001,
	title = {A Probability and Decision-Model Analysis of a Multimodel Ensemble of Climate Change Simulations},
	volume = {14},
	issn = {0894-8755, 1520-0442},
	url = {https://journals.ametsoc.org/view/journals/clim/14/15/1520-0442_2001_014_3212_apadma_2.0.co_2.xml},
	doi = {10.1175/1520-0442(2001)014<3212:APADMA>2.0.CO;2},
	abstract = {Abstract Because of the inherent uncertainties in the computational representation of climate and because of unforced chaotic climate variability, it is argued that climate change projections should be expressed in probabilistic form. In this paper, 17 Coupled Model Intercomparison Project second-phase experiments sharing the same gradual increase in atmospheric {CO}2 are treated as a probabilistic multimodel ensemble projection of future climate. Tools commonly used for evaluation of probabilistic weather and seasonal forecasts are applied to this climate change ensemble. The probabilities of some temperature- and precipitation-related events defined for 20-yr seasonal means of climate are first studied. A cross-verification exercise is then used to obtain an upper estimate of the quality of these probability forecasts in terms of Brier skill scores, reliability diagrams, and potential economic value. Skill and value estimates are consistently higher for temperature-related events (e.g., will the 20-yr period around the doubling of {CO}2 be at least 1°C warmer than the present?) than for precipitation-related events (e.g., will the mean precipitation decrease by 10\% or more?). For large enough {CO}2 forcing, however, probabilistic projections of precipitation-related events also exhibit substantial potential economic value for a range of cost–loss ratios. The treatment of climate change information in a probabilistic rather than deterministic manner (e.g., using the ensemble consensus forecast) can greatly enhance its potential value.},
	pages = {3212--3226},
	number = {15},
	journaltitle = {Journal of Climate},
	author = {Räisänen, Jouni and Palmer, T. N.},
	urldate = {2024-03-29},
	date = {2001-08-01},
	keywords = {climate, decision-making, ensemble prediction},
}

@article{vergara_review_2014,
	title = {A review of feature selection methods based on mutual information},
	volume = {24},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-013-1368-0},
	doi = {10.1007/s00521-013-1368-0},
	abstract = {In this work, we present a review of the state of the art of information-theoretic feature selection methods. The concepts of feature relevance, redundance, and complementarity (synergy) are clearly defined, as well as Markov blanket. The problem of optimal feature selection is defined. A unifying theoretical framework is described, which can retrofit successful heuristic criteria, indicating the approximations made by each method. A number of open problems in the field are presented.},
	pages = {175--186},
	number = {1},
	journaltitle = {Neural Computing and Applications},
	shortjournal = {Neural Comput \& Applic},
	author = {Vergara, Jorge R. and Estévez, Pablo A.},
	urldate = {2024-07-22},
	date = {2014-01-01},
	langid = {english},
	keywords = {Complementarity, Feature selection, Markov blanket, Mutual information, Redundancy, Relevance, Sinergy},
}

@inproceedings{jovic_review_2015,
	location = {Opatija, Croatia},
	title = {A review of feature selection methods with applications},
	isbn = {9789532330823},
	url = {http://ieeexplore.ieee.org/document/7160458/},
	doi = {10.1109/MIPRO.2015.7160458},
	eventtitle = {2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics ({MIPRO})},
	pages = {1200--1205},
	booktitle = {2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics ({MIPRO})},
	publisher = {{IEEE}},
	author = {Jovic, A. and Brkic, K. and Bogunovic, N.},
	urldate = {2024-07-22},
	date = {2015-05},
}

@article{gultepe_review_2023,
	title = {A Review on Weather Impact on Aviation Operations: Visibility, Wind, Precipitation, Icing},
	volume = {2},
	rights = {Copyright (c) 2023},
	issn = {2949-7698},
	url = {http://jaoam.com/index.php/jaoam/article/view/43},
	doi = {10.56801/jaoam.v2i1.1},
	shorttitle = {A Review on Weather Impact on Aviation Operations},
	abstract = {Meteorological conditions affect aviation, marine, and land transportation, and play an important role in aviation accidents and operations. Wind (Uh), visibility (Vis), and Precipitation rate and amount ({PR} and {PA}) are the most important meteorological parameters that affect the terminal weather and in- flight conditions. Weather is considered a causal factor in about 30\% of all {US} aviation accidents ({NASA}, 1999). Fatal aviation accidents based on the {NTSB} data related to ceiling, fog, and wind are estimated at 20\%, 14\%, and 10\%, correspondingly. Knowing weather conditions can help to improve operational planning, including fuel consumption and people safety. Wind shear and gust, and turbulence need to be measured or predicted for the flight route and airport terminal weather. In addition, low Vis and ceiling are the second most important weather events affecting aviation operations. Lastly, precipitation type, rate and amount are the third important group of parameters that severely affect the flight operations such as de-icing. Earlier analysis of these events suggested that the meteorological conditions need to be studied in detail to better predict and monitor weather conditions for operational needs. In this respect, both observations quality and numerical weather predictions model simulations should be improved, and both new technologies and statistical models such as machine learning and artificial intelligence analysis should be developed for the aviation operations.},
	pages = {1--44},
	number = {1},
	journaltitle = {Journal of Airline Operations and Aviation Management},
	author = {Gultepe, Ismail},
	urldate = {2024-03-29},
	date = {2023-08-15},
	langid = {english},
	keywords = {aviation, review, weather and climate services},
}

@article{wilks_skill_2001,
	title = {A skill score based on economic value for probability forecasts},
	volume = {8},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1017/S1350482701002092},
	doi = {10.1017/S1350482701002092},
	abstract = {Abstract 
            An approach to evaluating probability forecasts for dichotomous events, based on their economic value over all possible cost/loss ratio decision problems, is proposed. The resulting Value Score ({VS}) curve shows non‐dimensionalised relative economic value as a function of the cost/loss ratios for different decision‐makers, over their full meaningful range. The {VS} curve is similar in terms of computational mechanics and graphical display to the Relative Operating Characteristic ({ROC}) curve, but the {ROC} curve is shown to be insensitive to either conditional or unconditional biases and thus to reflect potential rather than actual skill. The possibility of collapsing the {VS} curve into a single scalar score is addressed, and it is shown that the results can depend very strongly on the assumed distribution of cost/loss ratios in the community of forecast users. Copyright © 2001 Royal Meteorological Society},
	pages = {209--219},
	number = {2},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Wilks, D S},
	urldate = {2024-03-29},
	date = {2001-06},
	langid = {english},
	keywords = {decision-making, economic value, verification},
}

@article{chandrashekar_survey_2014,
	title = {A survey on feature selection methods},
	volume = {40},
	issn = {0045-7906},
	url = {https://www.sciencedirect.com/science/article/pii/S0045790613003066},
	doi = {10.1016/j.compeleceng.2013.11.024},
	series = {40th-year commemorative issue},
	abstract = {Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques.},
	pages = {16--28},
	number = {1},
	journaltitle = {Computers \& Electrical Engineering},
	shortjournal = {Computers \& Electrical Engineering},
	author = {Chandrashekar, Girish and Sahin, Ferat},
	urldate = {2024-07-22},
	date = {2014-01-01},
}

@article{alerskans_transformer_2022,
	title = {A transformer neural network for predicting {\textless}span style="font-variant:small-caps;"{\textgreater}near‐surface{\textless}/span{\textgreater} temperature},
	volume = {29},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.2098},
	doi = {10.1002/met.2098},
	shorttitle = {A transformer neural network for predicting {\textless}span style="font-variant},
	abstract = {Abstract 
            A new method based on the Transformer model is proposed for post‐processing of numerical weather prediction ({NWP}) forecasts of 2 m air temperature. The Transformer is a machine learning ({ML}) model based on self‐attention, which extracts information about which inputs are most important for the prediction. It is trained using time series input from {NWP} variables and crowd‐sourced 2 m air temperature observations from more than 1000 private weather stations ({PWSs}). The performance of the new post‐processing model is evaluated using both observational data from {PWSs} and completely independent observations from the Danish Meteorological Institute ({DMI}) network of surface synoptic observations ({SYNOP}) stations. The performance of the Transformer model is compared against the raw {NWP} forecast, as well as against two benchmark post‐processing models; a linear regression ({LR}) model and a neural network ({NN}). The results evaluated using {PWS} observations show an improvement in the 2 m temperature forecasts with respect to both bias and standard deviation ({STD}) for all three post‐processing models, with the Transformer model showing the largest improvement. The raw {NWP} forecast, {LR}, {NN} and Transformer model have a bias and {STD} of 0.34 and 1.96°C, 0.03 and 1.63°C, 0.10 and 1.53°C and 0.02 and 1.13°C, respectively. The corresponding results using {DMI} {SYNOP} stations also show improved forecasts, where the Transformer model performs better than both the raw {NWP} forecast and the two benchmark models. However, a dependence on distance to the coast and cold temperatures is observed.},
	pages = {e2098},
	number = {5},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Alerskans, Emy and Nyborg, Joachim and Birk, Morten and Kaas, Eigil},
	urldate = {2024-05-22},
	date = {2022-09},
	langid = {english},
	keywords = {post-processing, temperature},
}

@article{baran_twostep_2024,
	title = {A two‐step machine‐learning approach to statistical post‐processing of weather forecasts for power generation},
	volume = {150},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4635},
	doi = {10.1002/qj.4635},
	abstract = {By the end of 2021, the renewable energy share of the global electricity capacity reached 38.3\% and the new installations were dominated by wind and solar energy, showing global increases of 12.7\% and 18.5\% respectively. However, both wind and photovoltaic energy sources are highly volatile, making planning difficult for grid operators; thuss, accurate forecasts of the corresponding weather variables are essential for reliable electricity predictions. The most advanced approach in weather prediction is the ensemble method, which opens the door for probabilistic forecasting. However, ensemble forecasts are often underdispersive and subject to systematic bias. Hence, they require some form of statistical post‐processing, where parametric models provide full predictive distributions of the weather variables at hand. We propose a general two‐step machine‐learning‐based approach to calibrating ensemble weather forecasts, where, in the first step, improved point forecasts are generated, which then together with various ensemble statistics serve as input features of the neural network estimating the parameters of the predictive distribution. In two case studies based on 100 m wind speed and global horizontal irradiance forecasts of the operational ensemble prediction system of the Hungarian Meteorological Service, the predictive performance of this novel method is compared with the forecast skill of the raw ensemble and the state‐of‐the‐art parametric approaches. Both case studies confirm that, at least up to 48 hr, statistical post‐processing substantially improves the predictive performance of the raw ensemble for all forecast horizons considered. The variants of the proposed two‐step method investigated outperform in skill their competitors, and the suggested new approach is well applicable for different weather quantities and for a fair range of predictive distributions.},
	pages = {1029--1047},
	number = {759},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Baran, Ágnes and Baran, Sándor},
	urldate = {2024-07-23},
	date = {2024-01},
	langid = {english},
	keywords = {post-processing},
}

@misc{vaughan_aardvark_2024,
	title = {Aardvark Weather: end-to-end data-driven weather forecasting},
	url = {http://arxiv.org/abs/2404.00411},
	doi = {10.48550/arXiv.2404.00411},
	shorttitle = {Aardvark Weather},
	abstract = {Machine learning is revolutionising medium-range weather prediction. However it has only been applied to specific and individual components of the weather prediction pipeline. Consequently these data-driven approaches are unable to be deployed without input from conventional operational numerical weather prediction ({NWP}) systems, which is computationally costly and does not support end-to-end optimisation. In this work, we take a radically different approach and replace the entire {NWP} pipeline with a machine learning model. We present Aardvark Weather, the first end-to-end data-driven forecasting system which takes raw observations as input and provides both global and local forecasts. These global forecasts are produced for 24 variables at multiple pressure levels at one-degree spatial resolution and 24 hour temporal resolution, and are skillful with respect to hourly climatology at five to seven day lead times. Local forecasts are produced for temperature, mean sea level pressure, and wind speed at a geographically diverse set of weather stations, and are skillful with respect to an {IFS}-{HRES} interpolation baseline at multiple lead-times. Aardvark, by virtue of its simplicity and scalability, opens the door to a new paradigm for performing accurate and efficient data-driven medium-range weather forecasting.},
	number = {{arXiv}:2404.00411},
	publisher = {{arXiv}},
	author = {Vaughan, Anna and Markou, Stratis and Tebbutt, Will and Requeima, James and Bruinsma, Wessel P. and Andersson, Tom R. and Herzog, Michael and Lane, Nicholas D. and Hosking, J. Scott and Turner, Richard E.},
	urldate = {2024-06-05},
	date = {2024-03-30},
	eprinttype = {arxiv},
	eprint = {2404.00411 [physics]},
	note = {version: 1},
	keywords = {data-driven weather prediction},
}

@article{schmidli_accuracy_2018,
	title = {Accuracy of Simulated Diurnal Valley Winds in the Swiss Alps: Influence of Grid Resolution, Topography Filtering, and Land Surface Datasets},
	volume = {9},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2073-4433},
	url = {https://www.mdpi.com/2073-4433/9/5/196},
	doi = {10.3390/atmos9050196},
	shorttitle = {Accuracy of Simulated Diurnal Valley Winds in the Swiss Alps},
	abstract = {We evaluate the near-surface representation of thermally driven winds in the Swiss Alps in a numerical weather prediction model at km-scale resolution. In addition, the influence of grid resolution (2.2 km and 1.1 km), topography filtering, and land surface datasets on the accuracy of the simulated valley winds is investigated. The simulations are evaluated against a comprehensive set of surface observations for an 18-day fair-weather summer period in July 2006. The episode is characterized by strong diurnal wind systems and the formation of shallow convection over the mountains, which transitions to precipitating convection in some areas. The near-surface winds (10 m above ground level) follow a typical diurnal pattern with strong daytime up-valley flow and weaker nighttime down-valley flow. At a 2.2 km resolution the valley winds are poorly simulated for most stations, while at a 1.1 km resolution the diurnal cycle of the valley winds is well represented in most large (e.g., Rhein valley at Chur and Rhone valley at Visp) and medium-sized valleys (e.g., Linth valley at Glarus). In the smaller valleys (e.g., Maggia valley at Cevio), the amplitude of the valley wind is still significantly underestimated, even at a 1.1 km resolution. Detailed sensitivity experiments show that the use of high-resolution land surface datasets, for both the soil characteristics as well as for the land cover, and reduced filtering of the topography are essential to achieve good performance at a 1.1 km resolution.},
	pages = {196},
	number = {5},
	journaltitle = {Atmosphere},
	author = {Schmidli, Juerg and Böing, Steven and Fuhrer, Oliver},
	urldate = {2024-03-25},
	date = {2018-05},
	langid = {english},
	keywords = {complex terrain, wind},
}

@article{bi_accurate_2023,
	title = {Accurate medium-range global weather forecasting with 3D neural networks},
	volume = {619},
	rights = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06185-3},
	doi = {10.1038/s41586-023-06185-3},
	abstract = {Weather forecasting is important for science and society. At present, the most accurate forecast system is the numerical weather prediction ({NWP}) method, which represents atmospheric states as discretized grids and numerically solves partial differential equations that describe the transition between those states1. However, this procedure is computationally expensive. Recently, artificial-intelligence-based methods2 have shown potential in accelerating weather forecasting by orders of magnitude, but the forecast accuracy is still significantly lower than that of {NWP} methods. Here we introduce an artificial-intelligence-based method for accurate, medium-range global weather forecasting. We show that three-dimensional deep networks equipped with Earth-specific priors are effective at dealing with complex patterns in weather data, and that a hierarchical temporal aggregation strategy reduces accumulation errors in medium-range forecasting. Trained on 39 years of global data, our program, Pangu-Weather, obtains stronger deterministic forecast results on reanalysis data in all tested variables when compared with the world’s best {NWP} system, the operational integrated forecasting system of the European Centre for Medium-Range Weather Forecasts ({ECMWF})3. Our method also works well with extreme weather forecasts and ensemble forecasts. When initialized with reanalysis data, the accuracy of tracking tropical cyclones is also higher than that of {ECMWF}-{HRES}.},
	pages = {533--538},
	number = {7970},
	journaltitle = {Nature},
	author = {Bi, Kaifeng and Xie, Lingxi and Zhang, Hengheng and Chen, Xin and Gu, Xiaotao and Tian, Qi},
	urldate = {2024-05-29},
	date = {2023-07},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@article{beucler_achieving_2019,
	title = {Achieving Conservation of Energy in Neural Network Emulators for Climate Modeling},
	url = {http://arxiv.org/abs/1906.06622},
	abstract = {Artificial neural-networks have the potential to emulate cloud processes with higher accuracy than the semi-empirical emulators currently used in climate models. However, neural-network models do not intrinsically conserve energy and mass, which is an obstacle to using them for long-term climate predictions. Here, we propose two methods to enforce linear conservation laws in neural-network emulators of physical models: Constraining (1) the loss function or (2) the architecture of the network itself. Applied to the emulation of explicitly-resolved cloud processes in a prototype multi-scale climate model, we show that architecture constraints can enforce conservation laws to satisfactory numerical precision, while all constraints help the neural-network better generalize to conditions outside of its training set, such as global warming.},
	journaltitle = {{arXiv}:1906.06622 [physics]},
	author = {Beucler, Tom and Rasp, Stephan and Pritchard, Michael and Gentine, Pierre},
	urldate = {2021-03-30},
	date = {2019-06-15},
	eprinttype = {arxiv},
	eprint = {1906.06622},
}

@misc{zhuang_adabelief_2020,
	title = {{AdaBelief} Optimizer: Adapting Stepsizes by the Belief in Observed Gradients},
	url = {http://arxiv.org/abs/2010.07468},
	doi = {10.48550/arXiv.2010.07468},
	shorttitle = {{AdaBelief} Optimizer},
	abstract = {Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent ({SGD}) with momentum). For many models such as convolutional neural networks ({CNNs}), adaptive methods typically converge faster but generalize worse compared to {SGD}; for complex settings such as generative adversarial networks ({GANs}), adaptive methods are typically the default because of their stability.We propose {AdaBelief} to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in {SGD}, and training stability. The intuition for {AdaBelief} is to adapt the stepsize according to the "belief" in the current gradient direction. Viewing the exponential moving average ({EMA}) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate {AdaBelief} in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on {ImageNet}, {AdaBelief} achieves comparable accuracy to {SGD}. Furthermore, in the training of a {GAN} on Cifar10, {AdaBelief} demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at https://github.com/juntang-zhuang/Adabelief-Optimizer},
	number = {{arXiv}:2010.07468},
	publisher = {{arXiv}},
	author = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James S.},
	urldate = {2024-04-06},
	date = {2020-12-20},
	eprinttype = {arxiv},
	eprint = {2010.07468 [cs, stat]},
}

@misc{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	number = {{arXiv}:1412.6980},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2024-07-13},
	date = {2017-01-29},
	eprinttype = {arxiv},
	eprint = {1412.6980 [cs]},
}

@thesis{allen_advanced_2021,
	title = {Advanced statistical post-processing of ensemble weather forecasts},
	rights = {http://www.rioxx.net/licenses/all-rights-reserved},
	url = {https://ore.exeter.ac.uk/repository/handle/10871/126003},
	abstract = {Today, weather forecasts are generated by evolving the current state of the atmosphere through time subject to established mathematical and physical laws. The resulting forecasts are considerably more accurate than those produced using any other approach that humans have devised to predict the weather. Nonetheless, these forecasts are imperfect. In particular, errors arise in the forecast due to limitations in both our theoretical understanding of the atmosphere and our practical ability to reproduce it. This, combined with the atmosphere's chaotic nature, means obtaining a perfect forecast of the future weather is, for practical purposes, impossible. It is therefore imperative that a forecast is issued alongside its associated uncertainty. This is often achieved by generating an ensemble of weather forecasts that differ in their initial conditions, and possibly also the formulation of the dynamical weather model which with they are produced. However, due to errors in their construction, operational ensemble forecasts themselves possess systematic deficiencies. For this reason, it is necessary to apply an a posteriori adjustment to the ensemble forecast, so that it provides a more realistic representation of the weather that will occur. Several statistical methods have been proposed for this purpose that can not only correct for systematic errors present in the dynamical models, but can issue forecasts that are probabilistic, thus accounting for the uncertainty inherent in the forecast scenario. Such statistical post-processing methods have become an integral component of operational forecasting suites over the last decade. Recently, however, studies have demonstrated that conventional post-processing methods can be ameliorated by leveraging additional sources of information within the statistical models. With this in mind, this thesis seeks to recognise circumstances under which the performance of dynamical weather models is expected to change, thereby indicating what information should be incorporated within statistical post-processing methods. In particular, previous studies have indicated that the errors in dynamical weather models may depend on the occurrence of certain patterns in the synoptic-scale behaviour of the atmosphere, and we therefore postulate that these atmospheric regimes can be utilised when post-processing. A general framework for incorporating this regime information into established post-processing methods is proposed, and its merits are demonstrated in a variety of circumstances. A novel approach to evaluate the performance of forecasts is also introduced that can help to identify situations where incorporating information into post-processing methods is expected to be beneficial.},
	type = {phdthesis},
	author = {Allen, S.},
	urldate = {2024-05-22},
	date = {2021-06-14},
	langid = {english},
	keywords = {post-processing},
}

@misc{keller_ai-based_2024,
	title = {{AI}-based data assimilation: Learning the functional of analysis estimation},
	url = {http://arxiv.org/abs/2406.00390},
	doi = {10.48550/arXiv.2406.00390},
	shorttitle = {{AI}-based data assimilation},
	abstract = {The integration of observational data into numerical models, known as data assimilation ({DA}), is fundamental for making Numerical Weather Prediction ({NWP}) possible, with breathtaking success over the past 60 years (Bauer et al. 2015). Traditional {DA} methods, such as variational techniques and ensemble Kalman filters, are basic pillars of current {NWP} by incorporating diverse observational data. However, the emergence of artificial intelligence ({AI}) presents new opportunities for further improvements. {AI}-based approaches can emulate the complex computations of traditional {NWP} models at a reduced computational cost, offering the potential to speed up and improve analyses and forecasts dramatically (e.g. Pathak et al., 2022; Bi et al., 2023; Lam et al., 2023; Bouallegue et al., 2023). {AI} itself plays a growing role in optimization (e.g. Fan et al., 2024), which offers new possibilities also beyond model emulation. In this paper, we introduce a novel {AI}-based variational {DA} approach designed to replace classical methods of {DA} by leveraging deep learning techniques. Unlike previous hybrid approaches, our method integrates the {DA} process directly into a neural network, utilizing the variational {DA} framework. This innovative {AI}-based system, termed {AI}-Var, employs a neural network trained to minimize the variational cost function, enabling it to perform {DA} without relying on pre-existing analysis datasets. We present a proof-of-concept implementation of this approach, demonstrating its feasibility through a series of idealized and real-world test cases. Our results indicate that the {AI}-Var system can efficiently assimilate observations and produce accurate initial conditions for {NWP}, highlighting its potential to carry out the {DA} process in weather forecasting. This advancement paves the way for fully data-driven {NWP} systems, offering a significant leap forward in computational efficiency.},
	number = {{arXiv}:2406.00390},
	publisher = {{arXiv}},
	author = {Keller, Jan D. and Potthast, Roland},
	urldate = {2024-06-07},
	date = {2024-06-01},
	eprinttype = {arxiv},
	eprint = {2406.00390 [physics]},
	keywords = {data-driven weather prediction},
}

@misc{lang_aifs_2024,
	title = {{AIFS} - {ECMWF}'s data-driven forecasting system},
	url = {http://arxiv.org/abs/2406.01465},
	doi = {10.48550/arXiv.2406.01465},
	abstract = {Machine learning-based weather forecasting models have quickly emerged as a promising methodology for accurate medium-range global weather forecasting. Here, we introduce the Artificial Intelligence Forecasting System ({AIFS}), a data driven forecast model developed by the European Centre for Medium-Range Weather Forecasts ({ECMWF}). {AIFS} is based on a graph neural network ({GNN}) encoder and decoder, and a sliding window transformer processor, and is trained on {ECMWF}'s {ERA}5 re-analysis and {ECMWF}'s operational numerical weather prediction ({NWP}) analyses. It has a flexible and modular design and supports several levels of parallelism to enable training on high-resolution input data. {AIFS} forecast skill is assessed by comparing its forecasts to {NWP} analyses and direct observational data. We show that {AIFS} produces highly skilled forecasts for upper-air variables, surface weather parameters and tropical cyclone tracks. {AIFS} is run four times daily alongside {ECMWF}'s physics-based {NWP} model and forecasts are available to the public under {ECMWF}'s open data policy.},
	number = {{arXiv}:2406.01465},
	publisher = {{arXiv}},
	author = {Lang, Simon and Alexe, Mihai and Chantry, Matthew and Dramsch, Jesper and Pinault, Florian and Raoult, Baudouin and Clare, Mariana C. A. and Lessig, Christian and Maier-Gerber, Michael and Magnusson, Linus and Bouallègue, Zied Ben and Nemesio, Ana Prieto and Dueben, Peter D. and Brown, Andrew and Pappenberger, Florian and Rabier, Florence},
	urldate = {2024-06-06},
	date = {2024-06-03},
	eprinttype = {arxiv},
	eprint = {2406.01465 [physics]},
	keywords = {data-driven weather prediction},
}

@article{klasa_evaluation_2018,
	title = {An evaluation of the convection-permitting ensemble {COSMO}-E for three contrasting precipitation events in Switzerland: {KLASA} \textit{et al.} .},
	volume = {144},
	issn = {00359009},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qj.3245},
	doi = {10.1002/qj.3245},
	shorttitle = {An evaluation of the convection-permitting ensemble {COSMO}-E for three contrasting precipitation events in Switzerland},
	pages = {744--764},
	number = {712},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Q.J.R. Meteorol. Soc.},
	author = {Klasa, Christina and Arpagaus, Marco and Walser, André and Wernli, Heini},
	urldate = {2022-10-18},
	date = {2018-04},
	langid = {english},
}

@misc{couairon_archesweather_2024,
	title = {{ArchesWeather}: An efficient {AI} weather forecasting model at 1.5\{{\textbackslash}deg\} resolution},
	url = {http://arxiv.org/abs/2405.14527},
	doi = {10.48550/arXiv.2405.14527},
	shorttitle = {{ArchesWeather}},
	abstract = {One of the guiding principles for designing {AI}-based weather forecasting systems is to embed physical constraints as inductive priors in the neural network architecture. A popular prior is locality, where the atmospheric data is processed with local neural interactions, like 3D convolutions or 3D local attention windows as in Pangu-Weather. On the other hand, some works have shown great success in weather forecasting without this locality principle, at the cost of a much higher parameter count. In this paper, we show that the 3D local processing in Pangu-Weather is computationally sub-optimal. We design {ArchesWeather}, a transformer model that combines 2D attention with a column-wise attention-based feature interaction module, and demonstrate that this design improves forecasting skill. {ArchesWeather} is trained at 1.5\{{\textbackslash}deg\} resolution and 24h lead time, with a training budget of a few {GPU}-days and a lower inference cost than competing methods. An ensemble of two of our best models shows competitive {RMSE} scores with the {IFS} {HRES} and outperforms the 1.4\{{\textbackslash}deg\} 50-members {NeuralGCM} ensemble for one day ahead forecasting. Code and models will be made publicly available at https://github.com/gcouairon/{ArchesWeather}.},
	number = {{arXiv}:2405.14527},
	publisher = {{arXiv}},
	author = {Couairon, Guillaume and Lessig, Christian and Charantonis, Anastase and Monteleoni, Claire},
	urldate = {2024-06-07},
	date = {2024-05-23},
	eprinttype = {arxiv},
	eprint = {2405.14527 [cs]},
	note = {version: 1},
	keywords = {data-driven weather prediction},
}

@article{neumann_assessing_2019,
	title = {Assessing the scales in numerical weather and climate predictions: will exascale be the rescue?},
	volume = {377},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0148},
	doi = {10.1098/rsta.2018.0148},
	shorttitle = {Assessing the scales in numerical weather and climate predictions},
	abstract = {We discuss scientific features and computational performance of kilometre-scale global weather and climate simulations, considering the Icosahedral Non-hydrostatic ({ICON}) model and the Integrated Forecast System ({IFS}). Scalability measurements and a performance modelling approach are used to derive performance estimates for these models on upcoming exascale supercomputers. This is complemented by preliminary analyses of the model data that illustrate the importance of high-resolution models to gain improvements in the accuracy of convective processes, a better understanding of physics dynamics interactions and poorly resolved or parametrized processes, such as gravity waves, convection and boundary layer.This article is part of the theme issue ‘Multiscale modelling, simulation and computing: from the desktop to the exascale’.},
	pages = {20180148},
	number = {2142},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Neumann, Philipp and Düben, Peter and Adamidis, Panagiotis and Bauer, Peter and Brück, Matthias and Kornblueh, Luis and Klocke, Daniel and Stevens, Bjorn and Wedi, Nils and Biercamp, Joachim},
	urldate = {2021-10-19},
	date = {2019-04-08},
	keywords = {computing},
}

@article{chinta_assessment_2021,
	title = {Assessment of {WRF} Model Parameter Sensitivity for High‐Intensity Precipitation Events During the Indian Summer Monsoon},
	volume = {8},
	issn = {2333-5084, 2333-5084},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020EA001471},
	doi = {10.1029/2020EA001471},
	abstract = {Abstract 
            Default values for many parameters in Numerical Weather Prediction models are typically adopted based on theoretical or experimental investigations by scheme designers. Short‐range forecasts are substantially affected by the specification of parameters in the Weather Research and Forecasting ({WRF}) model. The presence of a multitude of parameters and several output variables in the {WRF} model renders appropriate parameter value identification quite challenging. This study aims to identify the parameters that most strongly influence the model output variables using a Global Sensitivity Analysis ({GSA}) method. Morris One‐At‐a‐Time ({MOAT}), a {GSA} method, is used to identify the sensitivities of 23 chosen tunable parameters corresponding to seven physical parameterization schemes of the {WRF} model. The sensitivity measures ({MOAT} mean and standard deviation) are evaluated for 11 output variables simulated by the {WRF} model, corresponding to different parameters. Twelve high‐intensity 4‐day precipitation events during the Indian summer monsoon during 2015, 2016, and 2017 over India's monsoon core region are considered for the study. Though the parameter sensitivities vary depending on the model output variable, overall results suggest a general trend. The consistency of sensitivity analysis results with different initial and lateral boundary conditions is also assessed. 
          ,  
            Key Points 
             
               
                 
                  Sensitivities of 23 chosen tunable model parameters are evaluated 
                 
                 
                  Nine parameters exert a significant influence on the output variables 
                 
                 
                  Sensitivity analysis results are consistent with different initial and lateral boundary conditions},
	pages = {e2020EA001471},
	number = {6},
	journaltitle = {Earth and Space Science},
	shortjournal = {Earth and Space Science},
	author = {Chinta, Sandeep and Yaswanth Sai, J. and Balaji, C.},
	urldate = {2024-07-08},
	date = {2021-06},
	langid = {english},
}

@book{emanuel_atmospheric_1994,
	location = {New York},
	title = {Atmospheric convection},
	isbn = {9780195066302},
	pagetotal = {580},
	publisher = {Oxford University Press},
	author = {Emanuel, Kerry A.},
	date = {1994},
}

@misc{bodnar_aurora_2024,
	title = {Aurora: A Foundation Model of the Atmosphere},
	url = {http://arxiv.org/abs/2405.13063},
	doi = {10.48550/arXiv.2405.13063},
	shorttitle = {Aurora},
	abstract = {Deep learning foundation models are revolutionizing many facets of science by leveraging vast amounts of data to learn general-purpose representations that can be adapted to tackle diverse downstream tasks. Foundation models hold the promise to also transform our ability to model our planet and its subsystems by exploiting the vast expanse of Earth system data. Here we introduce Aurora, a large-scale foundation model of the atmosphere trained on over a million hours of diverse weather and climate data. Aurora leverages the strengths of the foundation modelling approach to produce operational forecasts for a wide variety of atmospheric prediction problems, including those with limited training data, heterogeneous variables, and extreme events. In under a minute, Aurora produces 5-day global air pollution predictions and 10-day high-resolution weather forecasts that outperform state-of-the-art classical simulation tools and the best specialized deep learning models. Taken together, these results indicate that foundation models can transform environmental forecasting.},
	number = {{arXiv}:2405.13063},
	publisher = {{arXiv}},
	author = {Bodnar, Cristian and Bruinsma, Wessel P. and Lucic, Ana and Stanley, Megan and Brandstetter, Johannes and Garvan, Patrick and Riechert, Maik and Weyn, Jonathan and Dong, Haiyu and Vaughan, Anna and Gupta, Jayesh K. and Tambiratnam, Kit and Archibald, Alex and Heider, Elizabeth and Welling, Max and Turner, Richard E. and Perdikaris, Paris},
	urldate = {2024-06-10},
	date = {2024-05-28},
	eprinttype = {arxiv},
	eprint = {2405.13063 [physics]},
	keywords = {data-driven weather prediction},
}

@misc{patacchiola_bayesian_2020,
	title = {Bayesian Meta-Learning for the Few-Shot Setting via Deep Kernels},
	url = {http://arxiv.org/abs/1910.05199},
	doi = {10.48550/arXiv.1910.05199},
	abstract = {Recently, different machine learning methods have been introduced to tackle the challenging few-shot learning scenario that is, learning from a small labeled dataset related to a specific task. Common approaches have taken the form of meta-learning: learning to learn on the new problem given the old. Following the recognition that meta-learning is implementing learning in a multi-level model, we present a Bayesian treatment for the meta-learning inner loop through the use of deep kernels. As a result we can learn a kernel that transfers to new tasks; we call this Deep Kernel Transfer ({DKT}). This approach has many advantages: is straightforward to implement as a single optimizer, provides uncertainty quantification, and does not require estimation of task-specific parameters. We empirically demonstrate that {DKT} outperforms several state-of-the-art algorithms in few-shot classification, and is the state of the art for cross-domain adaptation and regression. We conclude that complex meta-learning routines can be replaced by a simpler Bayesian model without loss of accuracy.},
	number = {{arXiv}:1910.05199},
	publisher = {{arXiv}},
	author = {Patacchiola, Massimiliano and Turner, Jack and Crowley, Elliot J. and O'Boyle, Michael and Storkey, Amos},
	urldate = {2024-05-27},
	date = {2020-10-13},
	eprinttype = {arxiv},
	eprint = {1910.05199 [cs, stat]},
	keywords = {gaussian processes, neural networks},
}

@article{dorrington_beyond_2020,
	title = {Beyond skill scores: exploring sub‐seasonal forecast value through a case‐study of French month‐ahead energy prediction},
	volume = {146},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3863},
	doi = {10.1002/qj.3863},
	shorttitle = {Beyond skill scores},
	abstract = {Abstract 
            We quantify the value of sub‐seasonal forecasts for a real‐world prediction problem: the forecasting of French month‐ahead energy demand. Using surface temperature as a predictor, we construct a trading strategy and assess the financial value of using meteorological forecasts, based on actual energy demand and price data. We show that forecasts with lead times greater than two weeks can have value for this application, both on their own and in conjunction with shorter‐range forecasts, especially during boreal winter. We consider a cost/loss framework based on this example, and show that, while it captures the performance of the short‐range forecasts well, it misses the marginal value present in medium‐range forecasts. We also contrast our assessment of forecast value to that given by traditional skill scores, which we show could be misleading if used in isolation. We emphasise the importance of basing assessment of forecast skill on variables actually used by end‐users.},
	pages = {3623--3637},
	number = {733},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Dorrington, Joshua and Finney, Isla and Palmer, Tim and Weisheimer, Antje},
	urldate = {2024-03-29},
	date = {2020-10},
	langid = {english},
	keywords = {verification},
}

@article{du_beyond_2021,
	title = {Beyond Strictly Proper Scoring Rules: The Importance of Being Local},
	volume = {36},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/36/2/WAF-D-19-0205.1.xml},
	doi = {10.1175/WAF-D-19-0205.1},
	shorttitle = {Beyond Strictly Proper Scoring Rules},
	abstract = {Abstract The evaluation of probabilistic forecasts plays a central role both in the interpretation and in the use of forecast systems and their development. Probabilistic scores (scoring rules) provide statistical measures to assess the quality of probabilistic forecasts. Often, many probabilistic forecast systems are available while evaluations of their performance are not standardized, with different scoring rules being used to measure different aspects of forecast performance. Even when the discussion is restricted to strictly proper scoring rules, there remains considerable variability between them; indeed strictly proper scoring rules need not rank competing forecast systems in the same order when none of these systems are perfect. The locality property is explored to further distinguish scoring rules. The nonlocal strictly proper scoring rules considered are shown to have a property that can produce “unfortunate” evaluations, particularly the fact that the continuous rank probability score prefers the outcome close to the median of the forecast distribution regardless of the probability mass assigned to the value at/near the median raises concern to its use. The only local strictly proper scoring rule, the logarithmic score, has direct interpretations in terms of probabilities and bits of information. The nonlocal strictly proper scoring rules, on the other hand, lack meaningful direct interpretation for decision support. The logarithmic score is also shown to be invariant under smooth transformation of the forecast variable, while the nonlocal strictly proper scoring rules considered may, however, change their preferences due to the transformation. It is therefore suggested that the logarithmic score always be included in the evaluation of probabilistic forecasts.},
	pages = {457--468},
	number = {2},
	journaltitle = {Weather and Forecasting},
	author = {Du, Hailiang},
	urldate = {2024-07-18},
	date = {2021-04-01},
}

@article{jacobson_beyond_2020,
	title = {Beyond univariate calibration: verifying spatial structure in ensembles of forecast fields},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/411/2020/},
	doi = {10.5194/npg-27-411-2020},
	shorttitle = {Beyond univariate calibration},
	abstract = {Most available verification metrics for ensemble forecasts focus on univariate quantities. That is, they assess whether the ensemble provides an adequate representation of the forecast uncertainty about the quantity of interest at a particular location and time. For spatially indexed ensemble forecasts, however, it is also important that forecast fields reproduce the spatial structure of the observed field and represent the uncertainty about spatial properties such as the size of the area for which heavy precipitation, high winds, critical fire weather conditions, etc., are expected. In this article we study the properties of the fraction of threshold exceedance ({FTE}) histogram, a new diagnostic tool designed for spatially indexed ensemble forecast fields. Defined as the fraction of grid points where a prescribed threshold is exceeded, the {FTE} is calculated for the verification field and separately for each ensemble member. It yields a projection of a – possibly high-dimensional – multivariate quantity onto a univariate quantity that can be studied with standard tools like verification rank histograms. This projection is appealing since it reflects a spatial property that is intuitive and directly relevant in applications, though it is not obvious whether the {FTE} is sufficiently sensitive to misrepresentation of spatial structure in the ensemble. In a comprehensive simulation study we find that departures from uniformity of the {FTE} histograms can indeed be related to forecast ensembles with biased spatial variability and that these histograms detect shortcomings in the spatial structure of ensemble forecast fields that are not obvious by eye. For demonstration, {FTE} histograms are applied in the context of spatially downscaled ensemble precipitation forecast fields from {NOAA}'s Global Ensemble Forecast System.},
	pages = {411--427},
	number = {3},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Jacobson, Josh and Kleiber, William and Scheuerer, Michael and Bellier, Joseph},
	urldate = {2024-05-22},
	date = {2020-08-31},
}

@article{fathi_big_2022,
	title = {Big Data Analytics in Weather Forecasting: A Systematic Review},
	volume = {29},
	issn = {1886-1784},
	url = {https://doi.org/10.1007/s11831-021-09616-4},
	doi = {10.1007/s11831-021-09616-4},
	shorttitle = {Big Data Analytics in Weather Forecasting},
	abstract = {Weather forecasting, as an important and indispensable procedure in people’s daily lives, evaluates the alteration happening in the current condition of the atmosphere. Big data analytics is the process of analyzing big data to extract the concealed patterns and applicable information that can yield better results. Nowadays, several parts of society are interested in big data, and the meteorological institute is not excluded. Therefore, big data analytics will give better results in weather forecasting and will help forecasters to forecast weather more accurately. In order to achieve this goal and to recommend favorable solutions, several big data techniques and technologies have been suggested to manage and analyze the huge volume of weather data from different resources. By employing big data analytics in weather forecasting, the challenges related to traditional data management techniques and technology can be solved. This paper tenders a systematic literature review method for big data analytic approaches in weather forecasting (published between 2014 and August 2020). A feasible taxonomy of the current reviewed papers is proposed as technique-based, technology-based, and hybrid approaches. Moreover, this paper presents a comparison of the aforementioned categories regarding accuracy, scalability, execution time, and other Quality of Service factors. The types of algorithms, measurement environments, modeling tools, and the advantages and disadvantages per paper are extracted. In addition, open issues and future trends are debated.},
	pages = {1247--1275},
	number = {2},
	journaltitle = {Archives of Computational Methods in Engineering},
	shortjournal = {Arch Computat Methods Eng},
	author = {Fathi, Marzieh and Haghi Kashani, Mostafa and Jameii, Seyed Mahdi and Mahdipour, Ebrahim},
	urldate = {2024-03-29},
	date = {2022-03-01},
	langid = {english},
	keywords = {economic value, review, weather and climate services, weather services},
}

@article{lang_bivariate_2019,
	title = {Bivariate Gaussian models for wind vectors in a distributional regression framework},
	volume = {5},
	issn = {2364-3579},
	url = {https://ascmo.copernicus.org/articles/5/115/2019/},
	doi = {10.5194/ascmo-5-115-2019},
	abstract = {A new probabilistic post-processing method for wind vectors is presented in a distributional regression framework employing the bivariate Gaussian distribution. In contrast to previous studies, all parameters of the distribution are simultaneously modeled, namely the location and scale parameters for both wind components and also the correlation coefficient between them employing flexible regression splines. To capture a possible mismatch between the predicted and observed wind direction, ensemble forecasts of both wind components are included using flexible two-dimensional smooth functions. This encompasses a smooth rotation of the wind direction conditional on the season and the forecasted ensemble wind direction.

 The performance of the new method is tested for stations located in plains, in mountain foreland, and within an alpine valley, employing {ECMWF} ensemble forecasts as explanatory variables for all distribution parameters. The rotation-allowing model shows distinct improvements in terms of predictive skill for all sites compared to a baseline model that post-processes each wind component separately. Moreover, different correlation specifications are tested, and small improvements compared to the model setup with no estimated correlation could be found for stations located in alpine valleys.},
	pages = {115--132},
	number = {2},
	journaltitle = {Advances in Statistical Climatology, Meteorology and Oceanography},
	author = {Lang, Moritz N. and Mayr, Georg J. and Stauffer, Reto and Zeileis, Achim},
	urldate = {2024-05-22},
	date = {2019-07-18},
}

@article{taillardat_calibrated_2016,
	title = {Calibrated Ensemble Forecasts Using Quantile Regression Forests and Ensemble Model Output Statistics},
	volume = {144},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/144/6/mwr-d-15-0260.1.xml},
	doi = {10.1175/MWR-D-15-0260.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="{abstractTitle} text-title my-1" id="d869e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Ensembles used for probabilistic weather forecasting tend to be biased and underdispersive. This paper proposes a statistical method for postprocessing ensembles based on quantile regression forests ({QRF}), a generalization of random forests for quantile regression. This method does not fit a parametric probability density function ({PDF}) like in ensemble model output statistics ({EMOS}) but provides an estimation of desired quantiles. This is a nonparametric approach that eliminates any assumption on the variable subject to calibration. This method can estimate quantiles using not only members of the ensemble but any predictor available including statistics on other variables.{\textless}/p{\textgreater}{\textless}p{\textgreater}The method is applied to the Météo-France 35-member ensemble forecast ({PEARP}) for surface temperature and wind speed for available lead times from 3 up to 54 h and compared to {EMOS}. All postprocessed ensembles are much better calibrated than the {PEARP} raw ensemble and experiments on real data also show that {QRF} performs better than {EMOS}, and can bring a real gain for human forecasters compared to {EMOS}. {QRF} provides sharp and reliable probabilistic forecasts. At last, classical scoring rules to verify predictive forecasts are completed by the introduction of entropy as a general measure of reliability.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	pages = {2375--2393},
	number = {6},
	journaltitle = {Monthly Weather Review},
	author = {Taillardat, Maxime and Mestre, Olivier and Zamo, Michaël and Naveau, Philippe},
	urldate = {2020-12-16},
	date = {2016-06-01},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
}

@article{gneiting_calibrated_2005,
	title = {Calibrated Probabilistic Forecasting Using Ensemble Model Output Statistics and Minimum {CRPS} Estimation},
	volume = {133},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/133/5/mwr2904.1.xml},
	doi = {10.1175/MWR2904.1},
	abstract = {Abstract Ensemble prediction systems typically show positive spread-error correlation, but they are subject to forecast bias and dispersion errors, and are therefore uncalibrated. This work proposes the use of ensemble model output statistics ({EMOS}), an easy-to-implement postprocessing technique that addresses both forecast bias and underdispersion and takes into account the spread-skill relationship. The technique is based on multiple linear regression and is akin to the superensemble approach that has traditionally been used for deterministic-style forecasts. The {EMOS} technique yields probabilistic forecasts that take the form of Gaussian predictive probability density functions ({PDFs}) for continuous weather variables and can be applied to gridded model output. The {EMOS} predictive mean is a bias-corrected weighted average of the ensemble member forecasts, with coefficients that can be interpreted in terms of the relative contributions of the member models to the ensemble, and provides a highly competitive deterministic-style forecast. The {EMOS} predictive variance is a linear function of the ensemble variance. For fitting the {EMOS} coefficients, the method of minimum continuous ranked probability score ({CRPS}) estimation is introduced. This technique finds the coefficient values that optimize the {CRPS} for the training data. The {EMOS} technique was applied to 48-h forecasts of sea level pressure and surface temperature over the North American Pacific Northwest in spring 2000, using the University of Washington mesoscale ensemble. When compared to the bias-corrected ensemble, deterministic-style {EMOS} forecasts of sea level pressure had root-mean-square error 9\% less and mean absolute error 7\% less. The {EMOS} predictive {PDFs} were sharp, and much better calibrated than the raw ensemble or the bias-corrected ensemble.},
	pages = {1098--1118},
	number = {5},
	journaltitle = {Monthly Weather Review},
	author = {Gneiting, Tilmann and Raftery, Adrian E. and Westveld, Anton H. and Goldman, Tom},
	urldate = {2023-05-11},
	date = {2005-05-01},
	keywords = {calibration, probabilistic},
}

@article{yang_calibration_2023,
	title = {Calibration of Gridded Wind Speed Forecasts Based on Deep Learning},
	volume = {37},
	issn = {2198-0934},
	url = {https://doi.org/10.1007/s13351-023-3001-1},
	doi = {10.1007/s13351-023-3001-1},
	abstract = {The challenges of applying deep learning ({DL}) to correct deterministic numerical weather prediction ({NWP}) biases with non-Gaussian distributions are discussed in this paper. It is known that the {DL} {UNet} model is incapable of correcting the bias of strong winds with the traditional loss functions such as the {MSE} (mean square error), {MAE} (mean absolute error), and {WMAE} (weighted mean absolute error). To solve this, a new loss function embedded with a physical constraint called {MAE}\_MR (miss ratio) is proposed. The performance of the {UNet} model with {MAE}\_MR is compared to {UNet} traditional loss functions, and statistical post-processing methods like Kalman filter ({KF}) and the machine learning methods like random forest ({RF}) in correcting wind speed biases in gridded forecasts from the {ECMWF} high-resolution model ({HRES}) in East China for lead times of 1–7 days. In addition to {MAE} for full wind speed, wind force scales based on the Beaufort scale are derived and evaluated. Compared to raw {HRES} winds, the {MAE} of winds corrected by {UNet} ({MAE}\_MR) improves by 22.8\% on average at 24–168 h, while {UNet} ({MAE}), {UNet} ({WMAE}), {UNet} ({MSE}), {RF}, and {KF} improve by 18.9\%, 18.9\%, 17.9\%, 13.8\%, and 4.3\%, respectively. {UNet} with {MSE}, {MAE}, and {WMAE} shows good correction for wind forces 1–3 and 4, but negative correction for 6 or higher. {UNet} ({MAE}\_MR) overcomes this, improving accuracy for forces 1–3, 4, 5, and 6 or higher by 11.7\%, 16.9\%, 11.6\%, and 6.4\% over {HRES}. A case study of a strong wind event further shows {UNet} ({MAE}\_MR) outperforms traditional post-processing in correcting strong wind biases.},
	pages = {757--774},
	number = {6},
	journaltitle = {Journal of Meteorological Research},
	shortjournal = {J Meteorol Res},
	author = {Yang, Xuan and Dai, Kan and Zhu, Yuejian},
	urldate = {2024-05-22},
	date = {2023-12-01},
	langid = {english},
	keywords = {deep learning, grid forecasting, post-processing},
}

@article{dueben_challenges_2018,
	title = {Challenges and design choices for global weather and climate models based on machine learning},
	volume = {11},
	issn = {1991-959X},
	url = {https://gmd.copernicus.org/articles/11/3999/2018/},
	doi = {10.5194/gmd-11-3999-2018},
	abstract = {Can models that are based on deep learning and trained on atmospheric data compete with weather and climate models that are based on physical principles and the basic equations of motion? This question has been asked often recently due to the boom in deep-learning techniques. The question is valid given the huge amount of data that are available, the computational efficiency of deep-learning techniques and the limitations of today's weather and climate models in particular with respect to resolution and complexity.

In this paper, the question will be discussed in the context of global weather forecasts. A toy model for global weather predictions will be presented and used to identify challenges and fundamental design choices for a forecast system based on neural networks.},
	pages = {3999--4009},
	number = {10},
	journaltitle = {Geoscientific Model Development},
	author = {Dueben, Peter D. and Bauer, Peter},
	urldate = {2024-06-06},
	date = {2018-10-01},
	keywords = {data-driven weather prediction},
}

@article{brotzge_challenges_2023,
	title = {Challenges and Opportunities in Numerical Weather Prediction},
	volume = {104},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/104/3/BAMS-D-22-0172.1.xml},
	doi = {10.1175/BAMS-D-22-0172.1},
	abstract = {"Challenges and Opportunities in Numerical Weather Prediction" published on 28 Mar 2023 by American Meteorological Society.},
	pages = {E698--E705},
	number = {3},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Brotzge, Jerald A. and Berchoff, Don and Carlis, {DaNa} L. and Carr, Frederick H. and Carr, Rachel Hogan and Gerth, Jordan J. and Gross, Brian D. and Hamill, Thomas M. and Haupt, Sue Ellen and Jacobs, Neil and {McGovern}, Amy and Stensrud, David J. and Szatkowski, Gary and Szunyogh, Istvan and Wang, Xuguang},
	urldate = {2024-05-06},
	date = {2023-03-28},
}

@incollection{wood_chapter_2021,
	title = {Chapter 1 - Dynamical cores for {NWP}: An uncertain landscape*},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B978012815491500001X},
	shorttitle = {Dynamical cores for {NWP}},
	abstract = {In an numerical weather prediction ({NWP}) model, the complex interplay, in a rotating frame of reference, between the winds, the highs and lows of pressure, and the transport of mass and thermal energy are the responsibility of the dynamical core. A recent review lists 26 existing {NWP} dynamical cores. So why, after more than 50 years of operational {NWP}, does there remain such a plethora of dynamical cores with little hint of convergence in the choice of which schemes to use? Indeed, as the architectures of supercomputers are on the brink of changing significantly, what convergence there might have been seems set to dissipate. The same review lists 28 models under development. By exploring some of the physical properties of the equations that lie at the heart of the dynamical core and revealing the challenges for the numerical schemes used to discretize those equations, this chapter attempts to uncover some of the reasons for this uncertain landscape in such a critical component of {NWP}. In particular, the chapter introduces and discusses in a little detail a variety of different numerical approaches to discretizing the equations in both the temporal and spatial dimensions. Discussing these in terms of their accuracy and numerical stability, as well as aspects of their efficiency on supercomputer architectures, it hopefully emerges why there is not a dominant strategy for designing a dynamical core.},
	pages = {1--46},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Wood, Nigel},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-10},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00001-X},
}

@incollection{sodemann_chapter_2021,
	title = {Chapter 12 - Numerical methods to identify model uncertainty},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154915000124},
	abstract = {Accessing model uncertainty is a prerequisite to targeted measures for both fundamental changes and incremental long-term model improvement. Model uncertainty is often buried in many facets of the complexity of a numerical weather prediction model. This Chapter presents two numerical approaches to identify model uncertainty: (i) numerical tracer variables, that target the advection of active or passive tracer substances throughout parts or the entire range of model components; and (ii) tendency diagnostics for model simulations, that can provide fine-grained information on the contribution from and interaction between individual subgrid scale processes in numerical models. Using examples from the available literature, we provide an overview of the concepts, the challenges, and the perspectives for identifying model uncertainty by numerical methods.},
	pages = {309--329},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Sodemann, Harald and Joos, Hanna},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-24},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00012-4},
}

@incollection{wang_chapter_2021,
	title = {Chapter 2 - Numerical uncertainties in discretization of the shallow-water equations for weather predication models},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154915000021},
	abstract = {Uncertainties in the simulation of fluid dynamics in weather predication models have several sources: uncertainties in the initial conditions, uncertainties of the governing equations in simulating real atmosphere and ocean states, and uncertainties in the numerical implementation of the governing equations. In this chapter, we discuss the uncertainties arising from the discretization of the shallow-water equations ({SWE}), with focus on the numerical design for the global grid model. Numerical design of a {SWE} includes model selecting a grid and staggering scheme based on the form of the equations to be discretized, applying and devising consistent and stable numerical methods that are suitable for the discretization grid, and using numerical techniques to remove computational modes and increase the stability and efficiency of numerical simulation. The discussions are presented for the three most commonly used grids in modern global atmospheric and oceanic modeling, the Cartesian grid, the icosahedral grid, and the cubed-sphere grid.},
	pages = {47--80},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Wang, Ning},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-24},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00002-1},
}

@incollection{buizza_chapter_2021,
	title = {Chapter 3 - Probabilistic view of numerical weather prediction and ensemble prediction},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154915000033},
	abstract = {Numerical weather prediction ({NWP}) has become a fundamental source of extremely valuable information for a wide range of human activities. It all started about 50 years ago when scientists tried to solve simplified versions of the fluid equations applied to the atmosphere on a rotating sphere. A major step forward was taken at the beginning of the 1980s when some key meteorological institutions started issuing daily weather forecasts, generated by solving numerically more complete sets of equations capable to describe the atmospheric flow. During the 1970s and 1980s, satellite programs started providing meteorological services with an increased number of good quality observations, which helped model development and improved forecast accuracy. In the subsequent years, the timely availability of an increasing number of higher quality observations, the development of more complete and realistic models, and the availability of increasingly powerful computers led to further advances. On average, since the 1980s forecasters saw an increase in predictability of about 1-day per decade. Still, every now and then forecasts would have extremely large errors, and people started wondering whether one could devise a way to identify these cases. In other words, people started asking whether it would be possible to complement the forecast of the most likely state of the future with a confidence interval. They were asking for a reliable measure of how accurate the forecast was going to be, expressed, for example, in terms of a probabilistic forecast or of a range of different weather scenarios. This led to the developments of ensemble methods, which so far are the only feasible ways to provide, operationally, accurate and reliable estimates of the range of possible analyses and forecast states. In this chapter, we will briefly review the main steps of {NWP}, discuss the need for a probabilistic approach, introduce ensemble prediction, and illustrate how ensembles are used to generate probabilistic forecasts.},
	pages = {81--117},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Buizza, Roberto},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-24},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00003-3},
}

@incollection{schefzik_chapter_2018,
	title = {Chapter 4 - Ensemble Postprocessing Methods Incorporating Dependence Structures},
	isbn = {9780128123720},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128123720000042},
	abstract = {Focusing on the key example of weather prediction, ensemble postprocessing methods that account for intervariable, spatial, and/or temporal dependence structures are reviewed. One strategy is to design postprocessing methods that yield truly multivariate predictive distributions. For many such multivariate approaches, copulas and Sklar's theorem provide the mathematical background. Essentially, two classes of multivariate ensemble postprocessing methods can be distinguished. Parametric approaches, such as Gaussian copula-based techniques, are typically tailored to specific intervariable, spatial, or temporal settings and work well in low-dimensional scenarios. In contrast, nonparametric, empirical copula-based approaches, including ensemble copula coupling and Schaake shuffle-based methods, are more general and can handle nearly any dimensionality. In such techniques, univariate postprocessed ensemble forecasts are arranged according to the rank order structure of a specifically chosen template. Alternatively, there are postprocessing methods yielding univariate predictive distributions, but accounting for dependencies by means of the design of the estimation procedure for the model parameters.},
	pages = {91--125},
	booktitle = {Statistical Postprocessing of Ensemble Forecasts},
	publisher = {Elsevier},
	author = {Schefzik, Roman and Möller, Annette},
	editor = {Vannitsem, Stéphane and Wilks, Daniel S. and Messner, Jakob W.},
	urldate = {2024-07-15},
	date = {2018-01-01},
	doi = {10.1016/B978-0-12-812372-0.00004-2},
}

@incollection{buizza_chapter_2021-1,
	title = {Chapter 4 - Predictability},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154915000045},
	abstract = {In this chapter, we discuss predictability from the point of view of a forecaster, who is trying to predict a system's behavior. As such, predictability is determined by forecast error growth: as models improve, and as the initial conditions’ errors decrease, the forecast error is reduced and the forecast skill horizon is lengthened. Current-day estimates of the forecast skill horizon, defined as the lead time when a forecast ceases to be more skilful than a climatological forecast, indicate that it is scale and phenomena's dependent: while it is still only a few days for small/fast scales, it can be as long as weeks and months for large/slow scale phenomena. Model's continuous improvements, the inclusion of all the relevant processes, increased resolution, the utilization of more and better observations, improved data assimilation, a better understanding of the sources of predictability, can lead to further extensions of the predictability limits. Predictability is finite, but we do not think that we have reached the limit of what it is possible. In this chapter, the link between predictability and error growth is discussed. An error growth model is presented, and applied to investigate how forecasts’ performance has been improving throughout the years. The forecast skill horizon concept and diagram are introduced, and used to visualize the scale dependency of predictability. Sources of predictability are discussed, and a schematic of scales’ interactions and teleconnection is introduced to understand the sources’ of predictability, and how predictable signals propagate and can affect distant, local weather. Predictability is finite, but we do not think that the predictability limit has yet been reached, since we believe that there are ways to further reduce the initial conditions’ and model errors.},
	pages = {119--146},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Buizza, Roberto},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-24},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00004-5},
}

@incollection{thorarinsdottir_chapter_2018,
	title = {Chapter 6 - Verification: Assessment of Calibration and Accuracy},
	isbn = {9780128123720},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128123720000066},
	shorttitle = {Chapter 6 - Verification},
	abstract = {In ensemble forecasting, forecast verification methods are needed to diagnose both the need for statistical postprocessing and the effectiveness of the postprocessing methods in producing calibrated and accurate forecasts. This chapter discusses an array of techniques that can be used in this context, making the distinction between verification tools that are useful for ranking competing forecasters and those that are more appropriate for improving our understanding of the performance of a single method. With a focus on continuous variables, verification methods for both univariate and multivariate forecasts are discussed, including approaches that are specifically tailored to the evaluation of extreme events.},
	pages = {155--186},
	booktitle = {Statistical Postprocessing of Ensemble Forecasts},
	publisher = {Elsevier},
	author = {Thorarinsdottir, Thordis L. and Schuhen, Nina},
	editor = {Vannitsem, Stéphane and Wilks, Daniel S. and Messner, Jakob W.},
	urldate = {2024-06-07},
	date = {2018-01-01},
	doi = {10.1016/B978-0-12-812372-0.00006-6},
	keywords = {scoring rules, verification},
}

@incollection{li_chapter_2021,
	title = {Chapter 8 - Uncertainties in the surface layer physics parameterizations},
	isbn = {978-0-12-815491-5},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128154915000082},
	abstract = {The principal processes that dynamically couple the atmosphere and the underneath surface are those involving turbulent exchanges of energy and mass. In this chapter, major uncertainties in the parameterizations of these processes are briefly reviewed and discussed.},
	pages = {229--236},
	booktitle = {Uncertainties in Numerical Weather Prediction},
	publisher = {Elsevier},
	author = {Li, Haiqin and Bao, Jian-Wen},
	editor = {Ólafsson, Haraldur and Bao, Jian-Wen},
	urldate = {2024-05-24},
	date = {2021-01-01},
	doi = {10.1016/B978-0-12-815491-5.00008-2},
}

@incollection{pinson_chapter_2018,
	title = {Chapter 9 - Application of Postprocessing for Renewable Energy},
	isbn = {9780128123720},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128123720000091},
	abstract = {Renewable energy generation capacities are being deployed at a rapid pace, now reaching a total of more than 800 {GW} worldwide, if adding up generation capacities for wind and solar power. Power generation from those sources is tightly linked to weather conditions, hence making renewable energy forecasting tightly linked to meteorological forecasting. Even though probabilistic forecasts of renewable power generation still often rely on deterministic weather forecasts, ensemble forecasts will necessarily be an increasing trend in order to issue the most complete information for future power generation. The basic and key concepts of postprocessing ensemble weather forecasts for renewable energy applications are described and discussed here, based on the example of wind power generation. These include the conversion of ensemble weather forecasts to power and generation of calibrated forecast products. Finally, perspectives regarding future developments in this area are given.},
	pages = {241--266},
	booktitle = {Statistical Postprocessing of Ensemble Forecasts},
	publisher = {Elsevier},
	author = {Pinson, Pierre and Messner, Jakob W.},
	editor = {Vannitsem, Stéphane and Wilks, Daniel S. and Messner, Jakob W.},
	urldate = {2022-10-18},
	date = {2018-01-01},
	langid = {english},
	doi = {10.1016/B978-0-12-812372-0.00009-1},
	keywords = {Kernel dressing, Nonlinear regression, Recursive estimation, Renewable energy, Wind power},
}

@incollection{wilks_chapter_2019,
	title = {Chapter 9 - Forecast Verification},
	isbn = {9780128158234},
	url = {https://www.sciencedirect.com/science/article/pii/B9780128158234000092},
	pages = {369--483},
	booktitle = {Statistical Methods in the Atmospheric Sciences (Fourth Edition)},
	publisher = {Elsevier},
	author = {Wilks, Daniel S.},
	editor = {Wilks, Daniel S.},
	urldate = {2024-06-11},
	date = {2019-01-01},
	doi = {10.1016/B978-0-12-815823-4.00009-2},
	keywords = {verification},
}

@incollection{mohrlen_chapter_2023,
	title = {Chapter Fifteen - Best practice recommendations for forecast evaluation},
	isbn = {9780443186813},
	url = {https://www.sciencedirect.com/science/article/pii/B9780443186813000271},
	series = {Wind Energy Engineering},
	pages = {147--184},
	booktitle = {{IEA} Wind Recommended Practice for the Implementation of Renewable Energy Forecasting Solutions},
	publisher = {Academic Press},
	author = {Möhrlen, Corinna and Zack, John W. and Giebel, Gregor},
	editor = {Möhrlen, Corinna and Zack, John W. and Giebel, Gregor},
	urldate = {2023-05-10},
	date = {2023-01-01},
	langid = {english},
	doi = {10.1016/B978-0-44-318681-3.00027-1},
}

@article{ebert-uphoff_cira_2021,
	title = {{CIRA} Guide to Custom Loss Functions for Neural Networks in Environmental Sciences -- Version 1},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2106.09757},
	doi = {10.48550/ARXIV.2106.09757},
	abstract = {Neural networks are increasingly used in environmental science applications. Furthermore, neural network models are trained by minimizing a loss function, and it is crucial to choose the loss function very carefully for environmental science applications, as it determines what exactly is being optimized. Standard loss functions do not cover all the needs of the environmental sciences, which makes it important for scientists to be able to develop their own custom loss functions so that they can implement many of the classic performance measures already developed in environmental science, including measures developed for spatial model verification. However, there are very few resources available that cover the basics of custom loss function development comprehensively, and to the best of our knowledge none that focus on the needs of environmental scientists. This document seeks to fill this gap by providing a guide on how to write custom loss functions targeted toward environmental science applications. Topics include the basics of writing custom loss functions, common pitfalls, functions to use in loss functions, examples such as fractions skill score as loss function, how to incorporate physical constraints, discrete and soft discretization, and concepts such as focal, robust, and adaptive loss. While examples are currently provided in this guide for Python with Keras and the {TensorFlow} backend, the basic concepts also apply to other environments, such as Python with {PyTorch}. Similarly, while the sample loss functions provided here are from meteorology, these are just examples of how to create custom loss functions. Other fields in the environmental sciences have very similar needs for custom loss functions, e.g., for evaluating spatial forecasts effectively, and the concepts discussed here can be applied there as well. All code samples are provided in a {GitHub} repository.},
	author = {Ebert-Uphoff, Imme and Lagerquist, Ryan and Hilburn, Kyle and Lee, Yoonjin and Haynes, Katherine and Stock, Jason and Kumler, Christina and Stewart, Jebb Q.},
	urldate = {2022-12-05},
	date = {2021},
}

@article{beucler_climate-invariant_2024,
	title = {Climate-invariant machine learning},
	volume = {10},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.adj7250},
	doi = {10.1126/sciadv.adj7250},
	abstract = {Projecting climate change is a generalization problem: We extrapolate the recent past using physical models across past, present, and future climates. Current climate models require representations of processes that occur at scales smaller than model grid size, which have been the main source of model projection uncertainty. Recent machine learning ({ML}) algorithms hold promise to improve such process representations but tend to extrapolate poorly to climate regimes that they were not trained on. To get the best of the physical and statistical worlds, we propose a framework, termed “climate-invariant” {ML}, incorporating knowledge of climate processes into {ML} algorithms, and show that it can maintain high offline accuracy across a wide range of climate conditions and configurations in three distinct atmospheric models. Our results suggest that explicitly incorporating physical knowledge into data-driven models of Earth system processes can improve their consistency, data efficiency, and generalizability across climate regimes. 
          ,  
            Physically informed transformations aid the machine learning of Earth system model processes that generalize across climates.},
	pages = {eadj7250},
	number = {6},
	journaltitle = {Science Advances},
	shortjournal = {Sci. Adv.},
	author = {Beucler, Tom and Gentine, Pierre and Yuval, Janni and Gupta, Ankitesh and Peng, Liran and Lin, Jerry and Yu, Sungduk and Rasp, Stephan and Ahmed, Fiaz and O’Gorman, Paul A. and Neelin, J. David and Lutsko, Nicholas J. and Pritchard, Michael},
	urldate = {2024-07-22},
	date = {2024-02-09},
	langid = {english},
	keywords = {climate},
}

@article{clare_combining_2021,
	title = {Combining distribution‐based neural networks to predict weather forecast probabilities},
	volume = {147},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4180},
	doi = {10.1002/qj.4180},
	abstract = {Abstract 
            The success of deep learning techniques over the last decades has opened up a new avenue of research for weather forecasting. Here, we take the novel approach of using a neural network to predict full probability density functions at each point in space and time rather than a single output value, thus producing a probabilistic weather forecast. This enables the calculation of both uncertainty and skill metrics for the neural network predictions, and overcomes the common difficulty of inferring uncertainty from these predictions. This approach is data‐driven and the neural network is trained on the {WeatherBench} dataset (processed {ERA}5 data) to forecast geopotential and temperature 3 and 5 days ahead. Data exploration leads to the identification of the most important input variables. In order to increase computational efficiency, several neural networks are trained on small subsets of these variables. The outputs are then combined through a stacked neural network, the first time such a technique has been applied to weather data. Our approach is found to be more accurate than some coarse numerical weather prediction models and as accurate as more complex alternative neural networks, with the added benefit of providing key probabilistic information necessary for making informed weather forecasts.},
	pages = {4337--4357},
	number = {741},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Clare, Mariana C.A. and Jamil, Omar and Morcrette, Cyril J.},
	urldate = {2024-06-06},
	date = {2021-10},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@article{gneiting_combining_2013,
	title = {Combining predictive distributions},
	volume = {7},
	issn = {1935-7524, 1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-7/issue-none/Combining-predictive-distributions/10.1214/13-EJS823.full},
	doi = {10.1214/13-EJS823},
	abstract = {In probabilistic forecasting combination formulas for the aggregation of predictive distributions need to be estimated based on past experience and training data. We study combination formulas and aggregation methods for predictive cumulative distribution functions from the perspectives of calibration and dispersion, taking an original prediction space approach that applies to discrete, mixed discrete-continuous and continuous predictive distributions alike. The key idea is that aggregation methods ought to be parsimonious, yet sufficiently flexible to accommodate any type of dispersion in the component distributions. Both linear and non-linear aggregation methods are investigated, including generalized, spread-adjusted and beta-transformed linear pools. The effects and techniques are demonstrated theoretically, in simulation examples, and in case studies, where we fit combination formulas for density forecasts of S\&P 500 returns and daily maximum temperature at Seattle-Tacoma Airport.},
	pages = {1747--1782},
	issue = {none},
	journaltitle = {Electronic Journal of Statistics},
	author = {Gneiting, Tilmann and Ranjan, Roopesh},
	urldate = {2024-07-08},
	date = {2013-01},
	keywords = {probabilistic forecasting, statistics, verification},
}

@article{berrocal_combining_2007,
	title = {Combining Spatial Statistical and Ensemble Information in Probabilistic Weather Forecasts},
	volume = {135},
	issn = {1520-0493, 0027-0644},
	url = {http://journals.ametsoc.org/doi/10.1175/MWR3341.1},
	doi = {10.1175/MWR3341.1},
	abstract = {Abstract 
            Forecast ensembles typically show a spread–skill relationship, but they are also often underdispersive, and therefore uncalibrated. Bayesian model averaging ({BMA}) is a statistical postprocessing method for forecast ensembles that generates calibrated probabilistic forecast products for weather quantities at individual sites. This paper introduces the spatial {BMA} technique, which combines {BMA} and the geostatistical output perturbation ({GOP}) method, and extends {BMA} to generate calibrated probabilistic forecasts of whole weather fields simultaneously, rather than just weather events at individual locations. At any site individually, spatial {BMA} reduces to the original {BMA} technique. The spatial {BMA} method provides statistical ensembles of weather field forecasts that take the spatial structure of observed fields into account and honor the flow-dependent information contained in the dynamical ensemble. The members of the spatial {BMA} ensemble are obtained by dressing the weather field forecasts from the dynamical ensemble with simulated spatially correlated error fields, in proportions that correspond to the {BMA} weights for the member models in the dynamical ensemble. Statistical ensembles of any size can be generated at minimal computational cost. The spatial {BMA} technique was applied to 48-h forecasts of surface temperature over the Pacific Northwest in 2004, using the University of Washington mesoscale ensemble. The spatial {BMA} ensemble generally outperformed the {BMA} and {GOP} ensembles and showed much better verification results than the raw ensemble, both at individual sites, for weather field forecasts, and for forecasts of composite quantities, such as average temperature in National Weather Service forecast zones and minimum temperature along the Interstate 90 Mountains to Sound Greenway.},
	pages = {1386--1402},
	number = {4},
	journaltitle = {Monthly Weather Review},
	author = {Berrocal, Veronica J. and Raftery, Adrian E. and Gneiting, Tilmann},
	urldate = {2024-07-15},
	date = {2007-04-01},
	langid = {english},
}

@article{zabini_communication_2015,
	title = {Communication and interpretation of regional weather forecasts: a survey of the Italian public: Survey analysis on the interpretation of weather forecasts},
	volume = {22},
	issn = {13504827},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/met.1480},
	doi = {10.1002/met.1480},
	shorttitle = {Communication and interpretation of regional weather forecasts},
	pages = {495--504},
	number = {3},
	journaltitle = {Meteorological Applications},
	shortjournal = {Met. Apps},
	author = {Zabini, Federica and Grasso, Valentina and Magno, Ramona and Meneguzzo, Francesco and Gozzini, Bernardo},
	urldate = {2024-03-29},
	date = {2015-07},
	langid = {english},
	keywords = {weather and climate services},
}

@article{whan_comparing_2018,
	title = {Comparing Area Probability Forecasts of (Extreme) Local Precipitation Using Parametric and Machine Learning Statistical Postprocessing Methods},
	volume = {146},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/146/11/mwr-d-17-0290.1.xml},
	doi = {10.1175/MWR-D-17-0290.1},
	abstract = {Abstract Probabilistic forecasts, which communicate forecast uncertainties, enable users to make better weather-based decisions. Using precipitation and numerous instability indices from the deterministic model {HARMONIE}–{AROME} ({HA}; a nonhydrostatic numerical weather prediction model) as potential predictors, we generate summer areal probabilistic maximum hourly precipitation forecasts across 11 regions of the Netherlands. We compare the skill of three statistical postprocessing methods: an extended logistic regression ({ELR}), a zero-adjusted gamma distribution ({ZAGA}), and a machine learning-based method, quantile regression forests ({QRF}). Forecast skill for low and moderate precipitation thresholds increases with the inclusion of extra predictors, in addition to {HA} precipitation. {HA} precipitation is the most important predictor at all lead times in {ELR} and {QRF}, while in {ZAGA}, the most important predictor for the location parameter shifts over lead times from {HA} precipitation to indices of atmospheric instability. All three methods improve upon a climatological forecast for low and moderate precipitation thresholds. {ZAGA} and {QRF} are generally the most skillful methods at moderate thresholds. {QRF} tends to be the most skillful method at higher thresholds, particularly during the afternoon period. Forecasts are reliable at low and moderate thresholds but tend to be overconfident at higher thresholds. {QRF} and {ZAGA} have more potential economic value than the deterministic forecast, with value remaining at high thresholds. A maximum local hourly precipitation threshold of 30 mm h−1 (a criterion in the Royal Netherlands Meteorological Institute’s code yellow warning for severe thunderstorms) is skillfully forecast by {QRF} in the afternoon period at short lead times.},
	pages = {3651--3673},
	number = {11},
	journaltitle = {Monthly Weather Review},
	author = {Whan, Kirien and Schmeits, Maurice},
	urldate = {2024-03-29},
	date = {2018-11-01},
}

@article{wilks_comparison_2007,
	title = {Comparison of Ensemble-{MOS} Methods Using {GFS} Reforecasts},
	volume = {135},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/135/6/mwr3402.1.xml},
	doi = {10.1175/MWR3402.1},
	abstract = {Abstract Three recently proposed and promising methods for postprocessing ensemble forecasts based on their historical error characteristics (i.e., ensemble-model output statistics methods) are compared using a multidecadal reforecast dataset. Logistic regressions and nonhomogeneous Gaussian regressions are generally preferred for daily temperature, and for medium-range (6–10 and 8–14 day) temperature and precipitation forecasts. However, the better sharpness of medium-range ensemble-dressing forecasts sometimes yields the best Brier scores even though their calibration is somewhat worse. Using the long (15 or 25 yr) training samples that are available with these reforecasts improves the accuracy and skill of these probabilistic forecasts to levels that are approximately equivalent to gains of 1 day of lead time, relative to using short (1 or 2 yr) training samples.},
	pages = {2379--2390},
	number = {6},
	journaltitle = {Monthly Weather Review},
	author = {Wilks, Daniel S. and Hamill, Thomas M.},
	urldate = {2024-05-22},
	date = {2007-06-01},
	keywords = {post-processing},
}

@article{lakatos_comparison_2023,
	title = {Comparison of multivariate post‐processing methods using global {ECMWF} ensemble forecasts},
	volume = {149},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4436},
	doi = {10.1002/qj.4436},
	abstract = {Abstract 
            An influential step in weather forecasting was the introduction of ensemble forecasts in operational use owing to their capability to account for the uncertainties in the future state of the atmosphere. However, ensemble weather forecasts are often underdispersive and might also contain bias, which calls for some form of post‐processing. A popular approach to calibration is the ensemble model output statistics approach resulting in a full predictive distribution for a given weather variable. However, this form of univariate post‐processing may ignore the prevailing spatial and/or temporal correlation structures among different dimensions. Since many applications call for spatially and/or temporally coherent forecasts, multivariate post‐processing aims to capture these possibly lost dependencies. We compare the forecast skill of different non‐parametric multivariate approaches to modeling temporal dependence of ensemble weather forecasts with different forecast horizons. The focus is on two‐step methods, where, after univariate post‐processing, the ensemble model output statistics predictive distributions corresponding to different forecast horizons are combined to a multivariate calibrated prediction using an empirical copula. Based on global ensemble predictions of temperature, wind speed, and precipitation accumulation of the European Centre for Medium‐Range Weather Forecasts from January 2002 to March 2014, we investigate the forecast skill of different versions of ensemble copula coupling ({ECC}) and Schaake shuffle. In general, compared with the raw and independently calibrated forecasts, multivariate post‐processing substantially improves the forecast skill. Although even the simplest {ECC} approach with low computational cost provides a powerful benchmark method, recently proposed advanced extensions of the {ECC} and the Schaake shuffle are found to not provide any significant improvements over their basic counterparts.},
	pages = {856--877},
	number = {752},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Lakatos, Mária and Lerch, Sebastian and Hemri, Stephan and Baran, Sándor},
	urldate = {2024-05-22},
	date = {2023-04},
	langid = {english},
	keywords = {post-processing},
}

@article{lakatos_comparison_2023-1,
	title = {Comparison of multivariate post‐processing methods using global {ECMWF} ensemble forecasts},
	volume = {149},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4436},
	doi = {10.1002/qj.4436},
	abstract = {Abstract 
            An influential step in weather forecasting was the introduction of ensemble forecasts in operational use owing to their capability to account for the uncertainties in the future state of the atmosphere. However, ensemble weather forecasts are often underdispersive and might also contain bias, which calls for some form of post‐processing. A popular approach to calibration is the ensemble model output statistics approach resulting in a full predictive distribution for a given weather variable. However, this form of univariate post‐processing may ignore the prevailing spatial and/or temporal correlation structures among different dimensions. Since many applications call for spatially and/or temporally coherent forecasts, multivariate post‐processing aims to capture these possibly lost dependencies. We compare the forecast skill of different non‐parametric multivariate approaches to modeling temporal dependence of ensemble weather forecasts with different forecast horizons. The focus is on two‐step methods, where, after univariate post‐processing, the ensemble model output statistics predictive distributions corresponding to different forecast horizons are combined to a multivariate calibrated prediction using an empirical copula. Based on global ensemble predictions of temperature, wind speed, and precipitation accumulation of the European Centre for Medium‐Range Weather Forecasts from January 2002 to March 2014, we investigate the forecast skill of different versions of ensemble copula coupling ({ECC}) and Schaake shuffle. In general, compared with the raw and independently calibrated forecasts, multivariate post‐processing substantially improves the forecast skill. Although even the simplest {ECC} approach with low computational cost provides a powerful benchmark method, recently proposed advanced extensions of the {ECC} and the Schaake shuffle are found to not provide any significant improvements over their basic counterparts.},
	pages = {856--877},
	number = {752},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Lakatos, Mária and Lerch, Sebastian and Hemri, Stephan and Baran, Sándor},
	urldate = {2024-07-15},
	date = {2023-04},
	langid = {english},
}

@misc{huang_compressing_2023,
	title = {Compressing multidimensional weather and climate data into neural networks},
	url = {http://arxiv.org/abs/2210.12538},
	doi = {10.48550/arXiv.2210.12538},
	abstract = {Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor {SZ}3 in terms of weighted {RMSE}, {MAE}. It can faithfully preserve important large scale atmosphere structures and does not introduce artifacts. When using the resulting neural network as a 790x compressed dataloader to train the {WeatherBench} forecasting model, its {RMSE} increases by less than 2\%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions.},
	number = {{arXiv}:2210.12538},
	publisher = {{arXiv}},
	author = {Huang, Langwen and Hoefler, Torsten},
	urldate = {2024-07-24},
	date = {2023-04-14},
	eprinttype = {arxiv},
	eprint = {2210.12538 [physics]},
}

@article{mitchell_configuration_2020,
	title = {Configuration of Statistical Postprocessing Techniques for Improved Low-Level Wind Speed Forecasts in West Texas},
	volume = {35},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/35/1/waf-d-18-0186.1.xml},
	doi = {10.1175/WAF-D-18-0186.1},
	abstract = {Abstract The wind energy industry needs accurate forecasts of wind speeds at turbine hub height and in the rotor layer to accurately predict power output from a wind farm. Current numerical weather prediction ({NWP}) models struggle to accurately predict low-level winds, partially due to systematic errors within the models due to deficiencies in physics parameterization schemes. These types of errors are addressed in this study with two statistical postprocessing techniques—model output statistics ({MOS}) and the analog ensemble ({AnEn})—to understand the value of each technique in improving rotor-layer wind forecasts. This study is unique in that it compares the techniques using a sonic detection and ranging ({SODAR}) wind speed dataset that spans the entire turbine rotor layer. This study uses reforecasts from the Weather Research and Forecasting ({WRF}) Model and observations in west Texas over periods of up to two years to examine the skill added to forecasts when applying both {MOS} and the {AnEn}. Different aspects of the techniques are tested, including model horizontal and vertical resolution, number of predictors, and training set length. Both {MOS} and the {AnEn} are applied to several levels representing heights in the turbine rotor layer (40, 60, 80, 100, and 120 m). This study demonstrates the degree of improvement that different configurations of each technique provides to raw {WRF} forecasts, to help guide their use for low-level wind speed forecasts. It was found that both {AnEn} and {MOS} show significant improvement over the raw {WRF} forecasts, but the two methods do not differ significantly from each other.},
	pages = {129--147},
	number = {1},
	journaltitle = {Weather and Forecasting},
	author = {Mitchell, Meghan J. and Ancell, Brian and Lee, Jared A. and Smith, Nicholas H.},
	urldate = {2024-05-16},
	date = {2020-02-01},
	keywords = {post-processing, wind},
}

@misc{hengl_continental_2020,
	title = {Continental Europe Digital Terrain Model at 30 m resolution based on {GEDI}, {ICESat}-2, {AW}3D, {GLO}-30, {EUDEM}, {MERIT} {DEM} and background layers},
	url = {https://zenodo.org/records/4724549},
	doi = {10.5281/zenodo.4724549},
	abstract = {Digital Terrain Model for Continental Europe based on the three publicly available Digital Surface Models and predicted using an Ensemble Machine Learning ({EML}). {EML} was trainined using {GEDI} level 2B points (Level 2A; "elev\_lowestmode") and {ICESat}-2 ({ATL}08; "h\_te\_mean"): about 9 million points were overlaid vs {MERITDEM}, {AW}3D30, {GLO}-30, {EU} {DEM}, {GLAD} canopy height, tree cover and surface water cover maps, then an ensemble prediction model (mlr package in R) was fitted using random forest, Cubist and {GLM}, and used to predict most probable terrain height (bare earth). Input layers used to train the {EML} include:



	
"lcv\_bare.earth\_glcf.landsat": {UMD} {GLAD} bare earth estimate for year 2010 based on Landsat time series,
	
"dtm\_elev.dsm\_alos.aw3d": Digital Surface Model based on {ALOS} {AW}3D, 
	
"dtm\_canopy.height\_glad.umd": {UMD} {GLAD} canopy height for 2019 based on {GEDI} data,
	
"dtm\_elev.dsm\_eudem.eea": Copernicus {EU} {DEM} based on the {SRTM} and {ASTER} {DEMs},
	
"hyd\_surface.water\_jrc.gswe": {JRC} Global Surface Water Explorer surface water probability based on the Landsat time-series,
	
"lcv\_landcover.12\_pflugmacher2019": land cover map of Europe at 30 based on Pflugmacher et al. (2019),
	
"lcv\_tree.cover\_umd.landsat\_2000": forest tree cover for year 2000 based on the Global Forest Change data,
	
"lcv\_tree.cover\_umd.landsat\_2010": forest tree cover for year 2010 based on the Global Forest Change data,



Detailed processing steps can be found here. Read more about the processing steps here.


Training data set can be obtained in the file "gedi\_elev.lowestmode\_2019\_eumap.{RDS}". The initial linear model fitted using the four independent Digital Surface / Digital Terrain models shows:


Residuals:
  Min       1Q   Median       3Q      Max 
-124.627   -1.097    0.973    2.544   59.324 
 
Coefficients:
  Estimate Std. Error t value Pr({\textgreater}{\textbar}t{\textbar})    
(Intercept)         -1.6220640  0.0032415  -500.4   {\textless}2e-16 ***
  eu\_dem25m\_          -0.1092988  0.0005531  -197.6   {\textless}2e-16 ***
  eu\_AW3Dv2012\_30m\_    0.0933774  0.0005957   156.7   {\textless}2e-16 ***
  eu\_GLO30\_30m\_        0.2637153  0.0006062   435.1   {\textless}2e-16 ***
  eu\_MERITv1.0.1\_30m\_  0.7496494  0.0005009  1496.6   {\textless}2e-16 ***
  ---
  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 7.059 on 9588230 degrees of freedom
(2046196 observations deleted due to missingness)
Multiple R-squared:  0.9996,	Adjusted R-squared:  0.9996 
F-statistic: 5.343e+09 on 4 and 9588230 {DF},  p-value: {\textless} 2.2e-16


Which show that {MERIT} {DEM} (Yamazaki et al., 2019) is the most correlated {DEM} with {GEDI} and {ICESat}-2, most likely because it has been systematically post-processed and majority of canopy problems have been removed. Summary results of the model training (mlr::{makeStackedLearner}) using all covariates (including canopy height, tree cover, bare earth cover) shows:


Variable: elev\_lowestmode.f 
R-square: 1 
Fitted values sd: 333 
{RMSE}: 6.54 

Ensemble model:
Call:
stats::lm(formula = f, data = d)

Residuals:
     Min       1Q   Median       3Q      Max 
-118.788   -0.871    0.569    1.956  165.119 

Coefficients:
             Estimate Std. Error t value Pr({\textgreater}{\textbar}t{\textbar})    
(Intercept) -0.198402   0.003045  -65.15   {\textless}2e-16 ***
regr.ranger  0.452543   0.001117  405.04   {\textless}2e-16 ***
regr.cubist  0.527011   0.001516  347.61   {\textless}2e-16 ***
regr.glm     0.020033   0.001217   16.47   {\textless}2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.544 on 9588231 degrees of freedom
Multiple R-squared:  0.9996,	Adjusted R-squared:  0.9996 
F-statistic: 8.29e+09 on 3 and 9588231 {DF},  p-value: {\textless} 2.2e-16


Which indicates that the elevation errors are in average (2/3rd of pixels) between +1-2 m. The variable importance based on Random Forest package ranger shows:


Variable importance:
               variable   importance
4   eu\_MERITv1.0.1\_30m\_ 430641370770
1     eu\_AW3Dv2012\_30m\_ 291483345389
2         eu\_GLO30\_30m\_ 201517488587
3            eu\_dem25m\_ 132742500162
9 eu\_canopy\_height\_30m\_   5148617173
7             bare2010\_   2087304901
8        treecover2000\_   1761597272
6        treecover2010\_    141670217


The output predicted terrain model includes the following two layers:



	
"dtm\_elev.lowestmode\_gedi.eml\_mf": mean estimate of the terrain elevation in dm (decimeters) filtered using Gaussian filter and 2x pixel window in {SAGA} {GIS},
	
"dtm\_elev.lowestmode\_gedi.eml\_md": standard deviation of the independently fitted stacked predictors quantifying the prediction uncertainty in dm (decimeters),



The predicted elevations are based on the {GEDI} data hence the reference water surface ({WGS}84 ellipsoid) is about 43 m higher than the sea water surface for a specific {EU} country. Before modeling, we have corrected the reference elevations to the Earth Gravitational Model 2008 ({EGM}2008) by using the 5-arcdegree resolution correction surface (Pavlis et al, 2012).


All {GeoTIFFs} were prepared using Integer format (elevations rounded to 1 m) and have been converted to Cloud Optimized {GeoTIFFs} using {GDAL}.


Disclaimer: The output {DTM} still shows forest canopy (overestimation of the terrain elevation) and has not been hydrologically corrected for spurious sinks and similar. This data set is continuously updated. To report a bug or suggest an improvement, please visit here. To access {DTM} derivatives at 30-m, 100-m and 250-m please visit here. To register for updates please subscribe to: https://twitter.com/{HarmonizerGeo}.},
	version = {v0.3},
	publisher = {Zenodo},
	author = {Hengl, Tomislav and Leal Parente, Leandro and Krizan, Josip and Bonannella, Carmelo},
	urldate = {2024-07-26},
	date = {2020-09-28},
	keywords = {Europe, {GEDI}, {ICESat}-2, digital terrain model, elevation data, ensemble machine learning, geomorphometry},
}

@misc{lerch_convolutional_2022,
	title = {Convolutional autoencoders for spatially-informed ensemble post-processing},
	url = {http://arxiv.org/abs/2204.05102},
	doi = {10.48550/arXiv.2204.05102},
	abstract = {Ensemble weather predictions typically show systematic errors that have to be corrected via post-processing. Even state-of-the-art post-processing methods based on neural networks often solely rely on location-specific predictors that require an interpolation of the physical weather model's spatial forecast fields to the target locations. However, potentially useful predictability information contained in large-scale spatial structures within the input fields is potentially lost in this interpolation step. Therefore, we propose the use of convolutional autoencoders to learn compact representations of spatial input fields which can then be used to augment location-specific information as additional inputs to post-processing models. The benefits of including this spatial information is demonstrated in a case study of 2-m temperature forecasts at surface stations in Germany.},
	number = {{arXiv}:2204.05102},
	publisher = {{arXiv}},
	author = {Lerch, Sebastian and Polsterer, Kai L.},
	urldate = {2024-05-22},
	date = {2022-04-08},
	eprinttype = {arxiv},
	eprint = {2204.05102 [physics]},
	keywords = {convolutional neural network, ensemble prediction, neural networks, post-processing},
}

@article{demaeyer_correcting_2020,
	title = {Correcting for model changes in statistical postprocessing – an approach based on response theory},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/307/2020/},
	doi = {10.5194/npg-27-307-2020},
	abstract = {For most statistical postprocessing schemes used to correct weather forecasts, changes to the forecast model induce a considerable reforecasting effort. We present a new approach based on response theory to cope with slight model changes. In this framework, the model change is seen as a perturbation of the original forecast model. The response theory allows us then to evaluate the variation induced on the parameters involved in the statistical postprocessing, provided that the magnitude of this perturbation is not too large. This approach is studied in the context of a simple Ornstein–Uhlenbeck model and then on a more realistic, yet simple, quasi-geostrophic model. The analytical results for the former case help to pose the problem, while the application to the latter provides a proof of concept and assesses the potential performance of response theory in a chaotic system. In both cases, the parameters of the statistical postprocessing used – the Error-in-Variables Model Output Statistics ({EVMOS}) method – are appropriately corrected when facing a model change. The potential application in an operational environment is also discussed.},
	pages = {307--327},
	number = {2},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Demaeyer, Jonathan and Vannitsem, Stéphane},
	urldate = {2024-05-22},
	date = {2020-05-27},
	keywords = {post-processing},
}

@article{furrer_covariance_2006,
	title = {Covariance Tapering for Interpolation of Large Spatial Datasets},
	volume = {15},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186006X132178},
	doi = {10.1198/106186006X132178},
	pages = {502--523},
	number = {3},
	journaltitle = {Journal of Computational and Graphical Statistics},
	shortjournal = {Journal of Computational and Graphical Statistics},
	author = {Furrer, Reinhard and Genton, Marc G and Nychka, Douglas},
	urldate = {2024-05-27},
	date = {2006-09},
	langid = {english},
	keywords = {geostatistics},
}

@article{rasp_datadriven_2021,
	title = {Data‐Driven Medium‐Range Weather Prediction With a Resnet Pretrained on Climate Simulations: A New Model for {WeatherBench}},
	volume = {13},
	issn = {1942-2466, 1942-2466},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020MS002405},
	doi = {10.1029/2020MS002405},
	shorttitle = {Data‐Driven Medium‐Range Weather Prediction With a Resnet Pretrained on Climate Simulations},
	abstract = {Abstract 
            Numerical weather prediction has traditionally been based on the models that discretize the dynamical and physical equations of the atmosphere. Recently, however, the rise of deep learning has created increased interest in purely data‐driven medium‐range weather forecasting with first studies exploring the feasibility of such an approach. To accelerate progress in this area, the {WeatherBench} benchmark challenge was defined. Here, we train a deep residual convolutional neural network (Resnet) to predict geopotential, temperature and precipitation at 5.625° resolution up to 5 days ahead. To avoid overfitting and improve forecast skill, we pretrain the model using historical climate model output before fine‐tuning on reanalysis data. The resulting forecasts outperform previous submissions to {WeatherBench} and are comparable in skill to a physical baseline at similar resolution. We also analyze how the neural network creates its predictions and find that, for the case studies analyzed, the model has learned physically reasonable correlations. Finally, we perform scaling experiments to estimate the potential skill of data‐driven approaches at higher resolutions. 
          ,  
            Plain Language Summary 
            Weather forecasts are created by running hugely complex computer simulations that encapsulate our knowledge of how the atmosphere works. This approach has served us well but is there a different way? The paradigm of machine learning proposes learning an algorithm from data rather than building it from physical principles. For several areas like computer vision and natural language processing this has worked exceedingly well, so it just makes sense to try it as well for weather forecasting. This paper presents the latest attempt at training a machine learning weather forecasting model. It is shown that the learned model produces reasonable forecasts, approximately on par with traditional models run on much lower resolution. However, there is still a large gap to current state–of–the–art high–resolution weather models that is unlikely to be closed with a purely data–driven approach because not enough training data exists. 
          ,  
            Key Points 
             
               
                 
                  A large convolutional neural network is trained for the {WeatherBench} challenge 
                 
                 
                  Pretraining on climate model data improves skill and prevents overfitting 
                 
                 
                  The model sets a new state‐of‐the‐art for data‐driven medium‐range forecasting},
	pages = {e2020MS002405},
	number = {2},
	journaltitle = {Journal of Advances in Modeling Earth Systems},
	shortjournal = {J Adv Model Earth Syst},
	author = {Rasp, Stephan and Thuerey, Nils},
	urldate = {2024-06-05},
	date = {2021-02},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@collection{quinonero-candela_dataset_2009,
	location = {Cambridge, Mass},
	title = {Dataset shift in machine learning},
	isbn = {9780262170055 9780262545877},
	series = {Neural information processing series},
	pagetotal = {229},
	publisher = {{MIT} Press},
	editor = {Quiñonero-Candela, Joaquin},
	date = {2009},
	note = {{OCLC}: ocn227205909},
	keywords = {Machine learning},
}

@article{mylne_decisionmaking_2002,
	title = {Decision‐making from probability forecasts based on forecast value},
	volume = {9},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1017/S1350482702003043},
	doi = {10.1017/S1350482702003043},
	abstract = {Abstract 
            A method of estimating the economic value of weather forecasts for decision‐making is described. This method has recently been used for user‐oriented verification of probability forecasts, but is here applied to aid forecast users in optimising their decision‐making from probability forecasts. Value may be calculated in the same way for either probability forecasts or deterministic forecasts, and thus provides the user with a direct comparison of the value of each in terms of money saved, which is more relevant than most standard verification scores. The method is illustrated using site‐specific probability forecasts generated from the {ECMWF} ensemble prediction system and deterministic forecasts from the {ECMWF} high‐resolution global model. It is found that for most forecast events and for most users the probability forecasts have greater value than the deterministic forecasts from a higher resolution model. Copyright © 2002 Royal Meteorological Society.},
	pages = {307--315},
	number = {3},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Mylne, Kenneth R.},
	urldate = {2024-03-29},
	date = {2002-09},
	langid = {english},
	keywords = {decision-making, economic value, weather and climate services},
}

@article{hersbach_decomposition_2000,
	title = {Decomposition of the Continuous Ranked Probability Score for Ensemble Prediction Systems},
	volume = {15},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/15/5/1520-0434_2000_015_0559_dotcrp_2_0_co_2.xml},
	doi = {10.1175/1520-0434(2000)015<0559:DOTCRP>2.0.CO;2},
	abstract = {Abstract Some time ago, the continuous ranked probability score ({CRPS}) was proposed as a new verification tool for (probabilistic) forecast systems. Its focus is on the entire permissible range of a certain (weather) parameter. The {CRPS} can be seen as a ranked probability score with an infinite number of classes, each of zero width. Alternatively, it can be interpreted as the integral of the Brier score over all possible threshold values for the parameter under consideration. For a deterministic forecast system the {CRPS} reduces to the mean absolute error. In this paper it is shown that for an ensemble prediction system the {CRPS} can be decomposed into a reliability part and a resolution/uncertainty part, in a way that is similar to the decomposition of the Brier score. The reliability part of the {CRPS} is closely connected to the rank histogram of the ensemble, while the resolution/uncertainty part can be related to the average spread within the ensemble and the behavior of its outliers. The usefulness of such a decomposition is illustrated for the ensemble prediction system running at the European Centre for Medium-Range Weather Forecasts. The evaluation of the {CRPS} and its decomposition proposed in this paper can be extended to systems issuing continuous probability forecasts, by realizing that these can be interpreted as the limit of ensemble forecasts with an infinite number of members.},
	pages = {559--570},
	number = {5},
	journaltitle = {Weather and Forecasting},
	author = {Hersbach, Hans},
	urldate = {2024-06-18},
	date = {2000-10-01},
	keywords = {scoring rules, verification},
}

@misc{arnold_decompositions_2023,
	title = {Decompositions of the mean continuous ranked probability score},
	url = {http://arxiv.org/abs/2311.14122},
	doi = {10.48550/arXiv.2311.14122},
	abstract = {The continuous ranked probability score (crps) is the most commonly used scoring rule in the evaluation of probabilistic forecasts for real-valued outcomes. To assess and rank forecasting methods, researchers compute the mean crps over given sets of forecast situations, based on the respective predictive distributions and outcomes. We propose a new, isotonicity-based decomposition of the mean crps into interpretable components that quantify miscalibration ({MSC}), discrimination ability ({DSC}), and uncertainty ({UNC}), respectively. In a detailed theoretical analysis, we compare the new approach to empirical decompositions proposed earlier, generalize to population versions, analyse their properties and relationships, and relate to a hierarchy of notions of calibration. The isotonicity-based decomposition guarantees the nonnegativity of the components and quantifies calibration in a sense that is stronger than for other types of decompositions, subject to the nondegeneracy of empirical decompositions. We illustrate the usage of the isotonicity-based decomposition in case studies from weather prediction and machine learning.},
	number = {{arXiv}:2311.14122},
	publisher = {{arXiv}},
	author = {Arnold, Sebastian and Walz, Eva-Maria and Ziegel, Johanna and Gneiting, Tilmann},
	urldate = {2024-07-19},
	date = {2023-11-23},
	eprinttype = {arxiv},
	eprint = {2311.14122 [stat]},
	keywords = {scoring rules, verification},
}

@misc{wilson_deep_2015,
	title = {Deep Kernel Learning},
	url = {http://arxiv.org/abs/1511.02222},
	doi = {10.48550/arXiv.1511.02222},
	abstract = {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods. Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation. These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability. We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process. Inference and learning cost \$O(n)\$ for \$n\$ training points, and predictions cost \$O(1)\$ per test point. On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.},
	number = {{arXiv}:1511.02222},
	publisher = {{arXiv}},
	author = {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
	urldate = {2024-05-27},
	date = {2015-11-06},
	eprinttype = {arxiv},
	eprint = {1511.02222 [cs, stat]},
	keywords = {gaussian processes, neural networks},
}

@misc{andrychowicz_deep_2023,
	title = {Deep Learning for Day Forecasts from Sparse Observations},
	url = {http://arxiv.org/abs/2306.06079},
	doi = {10.48550/arXiv.2306.06079},
	abstract = {Deep neural networks offer an alternative paradigm for modeling weather conditions. The ability of neural models to make a prediction in less than a second once the data is available and to do so with very high temporal and spatial resolution, and the ability to learn directly from atmospheric observations, are just some of these models' unique advantages. Neural models trained using atmospheric observations, the highest fidelity and lowest latency data, have to date achieved good performance only up to twelve hours of lead time when compared with state-of-the-art probabilistic Numerical Weather Prediction models and only for the sole variable of precipitation. In this paper, we present {MetNet}-3 that extends significantly both the lead time range and the variables that an observation based neural model can predict well. {MetNet}-3 learns from both dense and sparse data sensors and makes predictions up to 24 hours ahead for precipitation, wind, temperature and dew point. {MetNet}-3 introduces a key densification technique that implicitly captures data assimilation and produces spatially dense forecasts in spite of the network training on extremely sparse targets. {MetNet}-3 has a high temporal and spatial resolution of, respectively, up to 2 minutes and 1 km as well as a low operational latency. We find that {MetNet}-3 is able to outperform the best single- and multi-member {NWPs} such as {HRRR} and {ENS} over the {CONUS} region for up to 24 hours ahead setting a new performance milestone for observation based neural models. {MetNet}-3 is operational and its forecasts are served in Google Search in conjunction with other models.},
	number = {{arXiv}:2306.06079},
	publisher = {{arXiv}},
	author = {Andrychowicz, Marcin and Espeholt, Lasse and Li, Di and Merchant, Samier and Merose, Alexander and Zyda, Fred and Agrawal, Shreya and Kalchbrenner, Nal},
	urldate = {2024-05-27},
	date = {2023-07-06},
	eprinttype = {arxiv},
	eprint = {2306.06079 [physics]},
	keywords = {data-driven weather prediction},
}

@article{gronquist_deep_2021,
	title = {Deep learning for post-processing ensemble weather forecasts},
	volume = {379},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0092},
	doi = {10.1098/rsta.2020.0092},
	abstract = {Quantifying uncertainty in weather forecasts is critical, especially for predicting extreme weather events. This is typically accomplished with ensemble prediction systems, which consist of many perturbed numerical weather simulations, or trajectories, run in parallel. These systems are associated with a high computational cost and often involve statistical post-processing steps to inexpensively improve their raw prediction qualities. We propose a mixed model that uses only a subset of the original weather trajectories combined with a post-processing step using deep neural networks. These enable the model to account for non-linear relationships that are not captured by current numerical models or post-processing methods. Applied to the global data, our mixed models achieve a relative improvement in ensemble forecast skill ({CRPS}) of over 14\%. Furthermore, we demonstrate that the improvement is larger for extreme weather events on select case studies. We also show that our post-processing can use fewer trajectories to achieve comparable results to the full ensemble. By using fewer trajectories, the computational costs of an ensemble prediction system can be reduced, allowing it to run at higher resolution and produce more accurate forecasts.
            This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	pages = {20200092},
	number = {2194},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Phil. Trans. R. Soc. A.},
	author = {Grönquist, Peter and Yao, Chengyuan and Ben-Nun, Tal and Dryden, Nikoli and Dueben, Peter and Li, Shigang and Hoefler, Torsten},
	urldate = {2022-05-09},
	date = {2021-04-05},
	langid = {english},
	keywords = {deep learning, extreme weather events},
}

@article{gronquist_deep_2021-1,
	title = {Deep learning for post-processing ensemble weather forecasts},
	volume = {379},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0092},
	doi = {10.1098/rsta.2020.0092},
	abstract = {Quantifying uncertainty in weather forecasts is critical, especially for predicting extreme weather events. This is typically accomplished with ensemble prediction systems, which consist of many perturbed numerical weather simulations, or trajectories, run in parallel. These systems are associated with a high computational cost and often involve statistical post-processing steps to inexpensively improve their raw prediction qualities. We propose a mixed model that uses only a subset of the original weather trajectories combined with a post-processing step using deep neural networks. These enable the model to account for non-linear relationships that are not captured by current numerical models or post-processing methods. Applied to the global data, our mixed models achieve a relative improvement in ensemble forecast skill ({CRPS}) of over 14\%. Furthermore, we demonstrate that the improvement is larger for extreme weather events on select case studies. We also show that our post-processing can use fewer trajectories to achieve comparable results to the full ensemble. By using fewer trajectories, the computational costs of an ensemble prediction system can be reduced, allowing it to run at higher resolution and produce more accurate forecasts. 
            This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	pages = {20200092},
	number = {2194},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Phil. Trans. R. Soc. A.},
	author = {Grönquist, Peter and Yao, Chengyuan and Ben-Nun, Tal and Dryden, Nikoli and Dueben, Peter and Li, Shigang and Hoefler, Torsten},
	urldate = {2024-06-20},
	date = {2021-04-05},
	langid = {english},
	keywords = {convolutional neural network, post-processing},
}

@article{horat_deep_2024,
	title = {Deep Learning for Postprocessing Global Probabilistic Forecasts on Subseasonal Time Scales},
	volume = {152},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/152/3/MWR-D-23-0150.1.xml},
	doi = {10.1175/MWR-D-23-0150.1},
	abstract = {Abstract Subseasonal weather forecasts are becoming increasingly important for a range of socioeconomic activities. However, the predictive ability of physical weather models is very limited on these time scales. We propose four postprocessing methods based on convolutional neural networks to improve subseasonal forecasts by correcting systematic errors of numerical weather prediction models. Our postprocessing models operate directly on spatial input fields and are therefore able to retain spatial relationships and to generate spatially homogeneous predictions. They produce global probabilistic tercile forecasts for biweekly aggregates of temperature and precipitation for weeks 3–4 and 5–6. In a case study based on a public forecasting challenge organized by the World Meteorological Organization, our postprocessing models outperform the bias-corrected forecasts from the European Centre for Medium-Range Weather Forecasts ({ECMWF}), and achieve improvements over climatological forecasts for all considered variables and lead times. We compare several model architectures and training modes and demonstrate that all approaches lead to skillful and well-calibrated probabilistic forecasts. The good calibration of the postprocessed forecasts emphasizes that our postprocessing models reliably quantify the forecast uncertainty based on deterministic input information in the form of {ECMWF} ensemble mean forecast fields only.},
	pages = {667--687},
	number = {3},
	journaltitle = {Monthly Weather Review},
	author = {Horat, Nina and Lerch, Sebastian},
	urldate = {2024-05-22},
	date = {2024-02-19},
}

@article{ralph_defining_2018,
	title = {Defining “Atmospheric River”: How the Glossary of Meteorology Helped Resolve a Debate},
	volume = {99},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/99/4/bams-d-17-0157.1.xml},
	doi = {10.1175/BAMS-D-17-0157.1},
	shorttitle = {Defining “Atmospheric River”},
	abstract = {"Defining “Atmospheric River”: How the Glossary of Meteorology Helped Resolve a Debate" published on Apr 2018 by American Meteorological Society.},
	pages = {837--839},
	number = {4},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Ralph, F. Martin and Dettinger, Michael D. and Cairns, Mary M. and Galarneau, Thomas J. and Eylander, John},
	urldate = {2022-10-31},
	date = {2018-04-01},
}

@article{sun_deterministic_2024,
	title = {Deterministic Forecasting and Probabilistic Post‐Processing of Short‐Term Wind Speed Using Statistical Methods},
	volume = {129},
	issn = {2169-897X, 2169-8996},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2023JD040134},
	doi = {10.1029/2023JD040134},
	abstract = {Abstract 
            There is a great need for an accurate short‐term wind speed forecast, and statistical forecasts have gained increased popularity for their computational efficiency and satisfactory skill. However, there has been no systematic research to fully explore the capabilities of statistical approaches and evaluate the applicability of probabilistic information from statistical ensemble. This study first compares the skills of different statistical methods, based on linear regression, machine learning ({ML}), and deep learning ({DL}), using three strategies (i.e., direct, recursive, and multi‐output) against the three operational numerical models and their bias‐corrections, for short‐term wind speed forecast over Pearl River Estuary during 2018–2021. Inter‐comparison between statistical forecasts reveals the dominant superiority of direct strategy. On this basis, Random Forest ({RF}) and Support Vector Machines ({SVM}) perform best compared to other statistical forecasts and bias correction of numerical forecasts throughout 48 hr lead time, while the performance of methods with simplified (linear) or more complex ({DL}) model structures degrades significantly. Moreover, the top 10 forecasts are utilized to account for forecast uncertainties but present a substantial under‐dispersed prediction. Two traditional methods and three modern methods are implemented to perform probabilistic post‐processing. Modern methods based on {ML} or {DL} present worse skills, while traditional methods, particularly for ensemble model output statistics, show added value in discriminating binary events due to limited enhancements in calibration. Overall, {RF} and {SVM} using direct strategy are highly recommended for short‐term wind speed forecasts, and efforts are ongoing to address the issues of strong wind prediction and ensemble calibration. 
          ,  
            Plain Language Summary 
            Accurate short‐term wind speed forecasts are of urgent need for various facets of production‐living‐ecology. Numerical models are widely implemented for providing a single prediction (i.e., deterministic) or a suite of predictions (i.e., ensemble). However, they are computationally expensive and suffer from multi‐source uncertainties. On the contrary, statistical forecasts have gained increased popularity for their computational efficiency and satisfactory performance. However, there has been no systematic research to fully explore the capabilities of deterministic statistical methods and evaluate the applicability of probabilistic information from statistical ensemble, which motivates this study. Intercomparison between statistical forecasts reveals the importance of using direct strategy, which allows for the development of a distinct model for each time step of the forecast. Random Forest and Support Vector Machines using direct strategy are superior to other statistical forecasts and bias‐correction of numerical forecasts within 48 hr lead time. In addition, five probabilistic post‐processing methods are implemented on the statistical ensemble, which is underdispersed due to a lack of diversity. The traditional ensemble model output statistics shows improvements in capturing binary events, while modern methods even have the opposite effect. Overall, this study improves the understanding and performance of the statistical wind speed forecasting. 
          ,  
            Key Points 
             
               
                 
                  Inter‐comparison between statistical forecasts reveals the dominant superiority of direct strategy in short‐term wind speed forecasting 
                 
                 
                  Random Forest and Support Vector Machines utilizing the direct strategy are more skilled than other statistical forecasts and bias‐correction of numerical forecasts 
                 
                 
                  The statistical ensemble shows a substantial under‐dispersed prediction, which is sort of mitigated using traditional ensemble model output statistics post‐processing},
	pages = {e2023JD040134},
	number = {7},
	journaltitle = {Journal of Geophysical Research: Atmospheres},
	shortjournal = {{JGR} Atmospheres},
	author = {Sun, Lei and Lan, Yufeng and Sun, Xian and Liang, Xiuji and Wang, Jing and Su, Yekang and He, Yunping and Xia, Dong},
	urldate = {2024-05-22},
	date = {2024-04-16},
	langid = {english},
}

@article{lorenz_deterministic_1963,
	title = {Deterministic Nonperiodic Flow},
	volume = {20},
	issn = {0022-4928, 1520-0469},
	url = {https://journals.ametsoc.org/view/journals/atsc/20/2/1520-0469_1963_020_0130_dnf_2_0_co_2.xml},
	doi = {10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2},
	abstract = {Abstract Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space. For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into considerably different states. Systems with bounded solutions are shown to possess bounded numerical solutions. A simple system representing cellular convection is solved numerically. All of the solutions are found to be unstable, and almost all of them are nonperiodic. The feasibility of very-long-range weather prediction is examined in the light of these results.},
	pages = {130--141},
	number = {2},
	journaltitle = {Journal of the Atmospheric Sciences},
	author = {Lorenz, Edward N.},
	urldate = {2024-07-08},
	date = {1963-03-01},
}

@misc{swisstopo_dhm25_2023,
	title = {{DHM}25},
	author = {Swisstopo, Federal Office of Topography},
	date = {2023},
}

@article{murphy_diagnostic_1992,
	title = {Diagnostic verification of probability forecasts},
	volume = {7},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/0169207092900288},
	doi = {10.1016/0169-2070(92)90028-8},
	abstract = {Verification of probability forecasts traditionally consists largely of the computation of a few overall performance measures. This paper outlines a diagnostic approach to the evaluation of probability forecasts. The basic elements of this approach are the joint distribution of forecasts and observations and the conditional and marginal distributions associated with factorizations of the joint distribution. These distributions and their summary measures, together with selected performance measures and their decompositions, provide potentially insightful and useful information concerning the fundamental characteristics of the forecasts of interest, the corresponding observations, and their relationship. This approach and the associated methodology are illustrated by presenting some results of an analysis of U.S. National Weather Service probability of precipitation ({PoP}) forecasts. The diagnostic analysis of {PoP} forecasts consists of graphical displays and quantitative measures describing various aspects (or attributes) of forecast quality, including calibration (or reliability), refinement, resolution, discrimination, accuracy, bias, and skill. In general, the samples of {PoP} forecasts examined here are relatively well-calibrated, unbiased, and skillful, but lacking to some degree in accuracy, refinement, resolution, and discrimination. Some differences in these characteristics as a function of forecast type (modelbased/subjective), season (cool/warm), and lead time are noted. Diagnostic verification of probability forecasts has obvious benefits to modelers and forecasters in terms of providing detailed feedback and suggesting ways in which forecasts might be improved.},
	pages = {435--455},
	number = {4},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Murphy, Allan H. and Winkler, Robert L.},
	urldate = {2024-07-20},
	date = {1992-03-01},
	keywords = {probabilistic forecasting, verification},
}

@misc{huang_diffda_2024,
	title = {{DiffDA}: a Diffusion model for weather-scale Data Assimilation},
	url = {http://arxiv.org/abs/2401.05932},
	doi = {10.48550/arXiv.2401.05932},
	shorttitle = {{DiffDA}},
	abstract = {The generation of initial conditions via accurate data assimilation is crucial for weather forecasting and climate modeling. We propose {DiffDA} as a denoising diffusion model capable of assimilating atmospheric variables using predicted states and sparse observations. Acknowledging the similarity between a weather forecast model and a denoising diffusion model dedicated to weather applications, we adapt the pretrained {GraphCast} neural network as the backbone of the diffusion model. Through experiments based on simulated observations from the {ERA}5 reanalysis dataset, our method can produce assimilated global atmospheric data consistent with observations at 0.25 deg ({\textasciitilde}30km) resolution globally. This marks the highest resolution achieved by {ML} data assimilation models. The experiments also show that the initial conditions assimilated from sparse observations (less than 0.77\% of gridded data) and 48-hour forecast can be used for forecast models with a loss of lead time of at most 24 hours compared to initial conditions from state-of-the-art data assimilation in {ERA}5. This enables the application of the method to real-world applications, such as creating reanalysis datasets with autoregressive data assimilation.},
	number = {{arXiv}:2401.05932},
	publisher = {{arXiv}},
	author = {Huang, Langwen and Gianinazzi, Lukas and Yu, Yuejiang and Dueben, Peter D. and Hoefler, Torsten},
	urldate = {2024-06-05},
	date = {2024-03-05},
	eprinttype = {arxiv},
	eprint = {2401.05932 [cs]},
	keywords = {data-driven weather prediction},
}

@article{schlosser_distributional_2019,
	title = {Distributional Regression Forests for Probabilistic Precipitation Forecasting in Complex Terrain},
	volume = {13},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/1804.02921},
	doi = {10.1214/19-AOAS1247},
	abstract = {To obtain a probabilistic model for a dependent variable based on some set of explanatory variables, a distributional approach is often adopted where the parameters of the distribution are linked to regressors. In many classical models this only captures the location of the distribution but over the last decade there has been increasing interest in distributional regression approaches modeling all parameters including location, scale, and shape. Notably, so-called non-homogeneous Gaussian regression ({NGR}) models both mean and variance of a Gaussian response and is particularly popular in weather forecasting. Moreover, generalized additive models for location, scale, and shape ({GAMLSS}) provide a framework where each distribution parameter is modeled separately capturing smooth linear or nonlinear effects. However, when variable selection is required and/or there are non-smooth dependencies or interactions (especially unknown or of high-order), it is challenging to establish a good {GAMLSS}. A natural alternative in these situations would be the application of regression trees or random forests but, so far, no general distributional framework is available for these. Therefore, a framework for distributional regression trees and forests is proposed that blends regression trees and random forests with classical distributions from the {GAMLSS} framework as well as their censored or truncated counterparts. To illustrate these novel approaches in practice, they are employed to obtain probabilistic precipitation forecasts at numerous sites in a mountainous region based on a large number of numerical weather prediction quantities. It is shown that the novel distributional regression forests automatically select variables and interactions, performing on par or often even better than {GAMLSS} specified either through prior meteorological knowledge or a computationally more demanding boosting approach.},
	number = {3},
	journaltitle = {The Annals of Applied Statistics},
	shortjournal = {Ann. Appl. Stat.},
	author = {Schlosser, Lisa and Hothorn, Torsten and Stauffer, Reto and Zeileis, Achim},
	urldate = {2024-05-22},
	date = {2019-09-01},
	eprinttype = {arxiv},
	eprint = {1804.02921 [stat]},
	keywords = {complex terrain, precipitation},
}

@article{charlton-perez_ai_2024,
	title = {Do {AI} models produce better weather forecasts than physics-based models? A quantitative evaluation case study of Storm Ciarán},
	volume = {7},
	rights = {2024 The Author(s)},
	issn = {2397-3722},
	url = {https://www.nature.com/articles/s41612-024-00638-w},
	doi = {10.1038/s41612-024-00638-w},
	shorttitle = {Do {AI} models produce better weather forecasts than physics-based models?},
	abstract = {There has been huge recent interest in the potential of making operational weather forecasts using machine learning techniques. As they become a part of the weather forecasting toolbox, there is a pressing need to understand how well current machine learning models can simulate high-impact weather events. We compare short to medium-range forecasts of Storm Ciarán, a European windstorm that caused sixteen deaths and extensive damage in Northern Europe, made by machine learning and numerical weather prediction models. The four machine learning models considered ({FourCastNet}, Pangu-Weather, {GraphCast} and {FourCastNet}-v2) produce forecasts that accurately capture the synoptic-scale structure of the cyclone including the position of the cloud head, shape of the warm sector and location of the warm conveyor belt jet, and the large-scale dynamical drivers important for the rapid storm development such as the position of the storm relative to the upper-level jet exit. However, their ability to resolve the more detailed structures important for issuing weather warnings is more mixed. All of the machine learning models underestimate the peak amplitude of winds associated with the storm, only some machine learning models resolve the warm core seclusion and none of the machine learning models capture the sharp bent-back warm frontal gradient. Our study shows there is a great deal about the performance and properties of machine learning weather forecasts that can be derived from case studies of high-impact weather events such as Storm Ciarán.},
	pages = {1--11},
	number = {1},
	journaltitle = {npj Climate and Atmospheric Science},
	shortjournal = {npj Clim Atmos Sci},
	author = {Charlton-Perez, Andrew J. and Dacre, Helen F. and Driscoll, Simon and Gray, Suzanne L. and Harvey, Ben and Harvey, Natalie J. and Hunt, Kieran M. R. and Lee, Robert W. and Swaminathan, Ranjini and Vandaele, Remy and Volonté, Ambrogio},
	urldate = {2024-06-06},
	date = {2024-04-22},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@article{dupuy_downscaling_2023,
	title = {Downscaling of surface wind forecasts using convolutional neural networks},
	volume = {30},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/30/553/2023/},
	doi = {10.5194/npg-30-553-2023},
	abstract = {Near-surface winds over complex terrain generally feature a large variability at the local scale. Forecasting these winds requires high-resolution numerical weather prediction ({NWP}) models, which drastically increase the duration of simulations and hinder them in running on a routine basis. Nevertheless, downscaling methods can help in forecasting such wind flows at limited numerical cost. In this study, we present a statistical downscaling of {WRF} (Weather Research and Forecasting) wind forecasts over southeastern France (including the southwestern part of the Alps) from its original 9 km resolution onto a 1 km resolution grid (1 km {NWP} model outputs are used to fit our statistical models). Downscaling is performed using convolutional neural networks ({CNNs}), which are the most powerful machine learning tool for processing images or any kind of gridded data, as demonstrated by recent studies dealing with wind forecast downscaling. The previous studies mostly focused on testing new model architectures. In this study, we aimed to extend these works by exploring different output variables and their associated loss function. We found that there is no one approach that outperforms the others in terms of both the direction and the speed at the same time. Finally, the best overall performance is obtained by combining two {CNNs}, one dedicated to the direction forecast based on the calculation of the normalized wind components using a customized mean squared error ({MSE}) loss function and the other dedicated to the speed forecast based on the calculation of the wind components and using another customized {MSE} loss function. Local-scale, topography-related wind features, which were poorly forecast at 9 km, are now well reproduced, both for speed (e.g., acceleration on the ridge, leeward deceleration, sheltering in valleys) and direction (deflection, valley channeling). There is a general improvement in the forecast, especially during the nighttime stable stratification period, which is the most difficult period to forecast. The result is that, after downscaling, the wind speed bias is reduced from −0.55 to −0.01 m s−1, the wind speed {MAE} is reduced from 1.02 to 0.69 m s−1 (32 \% reduction) and the wind direction {MAE} is reduced from 25.9 to 15.5∘ (40 \% reduction) in comparison with the 9 km resolution forecast.},
	pages = {553--570},
	number = {4},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Dupuy, Florian and Durand, Pierre and Hedde, Thierry},
	urldate = {2024-05-22},
	date = {2023-11-29},
	keywords = {convolutional neural network, wind},
}

@article{matsueda_early_2015,
	title = {Early warning products for severe weather events derived from operational medium-range ensemble forecasts},
	volume = {22},
	issn = {13504827},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/met.1444},
	doi = {10.1002/met.1444},
	pages = {213--222},
	number = {2},
	journaltitle = {Meteorological Applications},
	shortjournal = {Met. Apps},
	author = {Matsueda, Mio and Nakazawa, Tetsuo},
	urldate = {2024-03-29},
	date = {2015-04},
	langid = {english},
}

@article{owens_ecmwf_2018,
	title = {{ECMWF} Forecast User Guide},
	url = {https://www.ecmwf.int/node/16559},
	doi = {10.21957/M1CS7H},
	author = {Owens, R and Hewson, Tim},
	urldate = {2024-05-25},
	date = {2018},
	note = {Publisher: {ECMWF}},
}

@article{frei_economic_2010,
	title = {Economic and social benefits of meteorology and climatology in Switzerland},
	volume = {17},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.156},
	doi = {10.1002/met.156},
	abstract = {Abstract 
            National Meteorological Services provide meteorological data, information, forecasts and various related products, which are important for the smooth functioning of many aspects in economy, administration and society. The merit of meteorological services cannot be deduced directly from the consumption of services. Rather, it emerges from the improvement of decisions by economic stakeholders thanks to weather and climate information. These services are purchased by users in order to be able to offer optimally or demand a certain service or, with respect to security, these services aim at helping to prevent damage from extreme events. 
            A rough estimate for a number of selected sectors shows that benefits from weather services in Switzerland are in the region of hundreds of millions Swiss Francs (1 Swiss Franc ∼ €0.66, {US}\$0.83 as at 2008). 
            This pilot study shows that it is not possible to estimate one single figure representing the overall benefit from weather services in a country. Concerning the economic sector, a benefit analysis should therefore concentrate on those sub‐sectors where weather services are particularly relevant, i.e. agriculture, construction, energy, insurance, telecommunication, tourism, transport, logistics and water availability. Analysis of benefits from climate data is of particular interest to {MeteoSwiss} since the Federal Office is the main source for climate data in Switzerland. Climate data form the basis on which climate change and possible climate threats can be detected. 
            This study estimates for the first time the socio‐economic benefits of meteorological and climatic information in Switzerland as a small developed European country and gives an outlook of how a further study might be designed. Copyright © 2009 Royal Meteorological Society},
	pages = {39--44},
	number = {1},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Frei, Thomas},
	urldate = {2024-03-29},
	date = {2010-03},
	langid = {english},
	keywords = {economic value, weather and climate services},
}

@article{frei_economic_2014,
	title = {Economic benefit of meteorology in the Swiss road transportation sector: Economic benefit of meteorology in Switzerland},
	volume = {21},
	issn = {13504827},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/met.1329},
	doi = {10.1002/met.1329},
	shorttitle = {Economic benefit of meteorology in the Swiss road transportation sector},
	pages = {294--300},
	number = {2},
	journaltitle = {Meteorological Applications},
	shortjournal = {Met. Apps},
	author = {Frei, Thomas and Von Grünigen, Stefan and Willemse, Saskia},
	urldate = {2024-03-29},
	date = {2014-04},
	langid = {english},
	keywords = {economic value, weather and climate services},
}

@article{sol_economic_1994,
	title = {Economic impact of weather forecasts for forest fires},
	volume = {1},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.5060010210},
	doi = {10.1002/met.5060010210},
	abstract = {Abstract 
             
              In order to help in fighting forest fires, South‐cast Météo‐France has, for the past 20 years, been issuing forecasts for small zones about 900 km 
              2 
              in size. These zones have been defined by taking into account relief, vegetation and micro‐climate. The main beneficiary of this, assistance is the Civil Security Force. This article describes the meteorological assistance that is given and the way this has developed, and makes an attempt to measure the economic impact of this assistance. It is relatively easy to estimate the direct costs of supplying the forecast services, the costs of the fire prevention implemented as a consequence of these forecasts, and the cost of fire fighting and replanting. Savings made to the prevention system and the area of forest due to the forecasts arc more difficult to evaluate. Nevertheless, estimates of these amounts are given.},
	pages = {155--158},
	number = {2},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Sol, Bernard},
	urldate = {2024-03-29},
	date = {1994-06},
	langid = {english},
	keywords = {economic value},
}

@article{muller_effects_2011,
	title = {Effects of Model Resolution and Statistical Postprocessing on Shelter Temperature and Wind Forecasts},
	volume = {50},
	issn = {1558-8424, 1558-8432},
	url = {https://journals.ametsoc.org/view/journals/apme/50/8/2011jamc2615.1.xml},
	doi = {10.1175/2011JAMC2615.1},
	abstract = {Abstract Shelter temperature and wind forecasts from numerical weather prediction models are subject to large systematic errors. Kalman filtering and model output statistics ({MOS}) are commonly used postprocessing methods, but how effective are they in comparison with steadily increasing resolution of the forecast model? Observations from over 1100 stations in central Europe are used to compare the different postprocessing methods and the influence of model resolution in complex and simple terrain, respectively. A 1-yr period with hourly, or at least 3-hourly, data is used to achieve statistically meaningful results. Furthermore, the importance of real-time observations as {MOS} predictors and the effects of daily training of the {MOS} equations are studied.},
	pages = {1627--1636},
	number = {8},
	journaltitle = {Journal of Applied Meteorology and Climatology},
	author = {Müller, M. D.},
	urldate = {2024-05-16},
	date = {2011-08-01},
	keywords = {post-processing, temperature, wind},
}

@article{yu_efficient_2004,
	title = {Efficient Feature Selection via Analysis of Relevance and Redundancy},
	volume = {5},
	issn = {{ISSN} 1533-7928},
	url = {https://www.jmlr.org/papers/v5/yu04a.html},
	abstract = {Feature selection is applied to reduce the number of
features in many applications where data has hundreds or thousands
of features. Existing feature selection methods mainly focus on
finding relevant features. In this paper, we show that feature
relevance alone is insufficient for efficient feature selection of
high-dimensional data. We define feature redundancy and propose to
perform explicit redundancy analysis in feature selection. A new
framework is introduced that decouples relevance analysis and
redundancy analysis. We develop a correlation-based method for
relevance and redundancy analysis, and conduct an empirical study
of its efficiency and effectiveness comparing with representative
methods.},
	pages = {1205--1224},
	issue = {Oct},
	journaltitle = {Journal of Machine Learning Research},
	author = {Yu, Lei and Liu, Huan},
	urldate = {2024-07-16},
	date = {2004},
}

@article{nti_electricity_2020,
	title = {Electricity load forecasting: a systematic review},
	volume = {7},
	issn = {2314-7172},
	url = {https://doi.org/10.1186/s43067-020-00021-8},
	doi = {10.1186/s43067-020-00021-8},
	shorttitle = {Electricity load forecasting},
	abstract = {The economic growth of every nation is highly related to its electricity infrastructure, network, and availability since electricity has become the central part of everyday life in this modern world. Hence, the global demand for electricity for residential and commercial purposes has seen an incredible increase. On the other side, electricity prices keep fluctuating over the past years and not mentioning the inadequacy in electricity generation to meet global demand. As a solution to this, numerous studies aimed at estimating future electrical energy demand for residential and commercial purposes to enable electricity generators, distributors, and suppliers to plan effectively ahead and promote energy conservation among the users. Notwithstanding, load forecasting is one of the major problems facing the power industry since the inception of electric power. The current study tried to undertake a systematic and critical review of about seventy-seven (77) relevant previous works reported in academic journals over nine years (2010–2020) in electricity demand forecasting. Specifically, attention was given to the following themes: (i) The forecasting algorithms used and their fitting ability in this field, (ii) the theories and factors affecting electricity consumption and the origin of research work, (iii) the relevant accuracy and error metrics applied in electricity load forecasting, and (iv) the forecasting period. The results revealed that 90\% out of the top nine models used in electricity forecasting was artificial intelligence based, with artificial neural network ({ANN}) representing 28\%. In this scope, {ANN} models were primarily used for short-term electricity forecasting where electrical energy consumption patterns are complicated. Concerning the accuracy metrics used, it was observed that root-mean-square error ({RMSE}) (38\%) was the most used error metric among electricity forecasters, followed by mean absolute percentage error {MAPE} (35\%). The study further revealed that 50\% of electricity demand forecasting was based on weather and economic parameters, 8.33\% on household lifestyle, 38.33\% on historical energy consumption, and 3.33\% on stock indices. Finally, we recap the challenges and opportunities for further research in electricity load forecasting locally and globally.},
	pages = {13},
	number = {1},
	journaltitle = {Journal of Electrical Systems and Information Technology},
	shortjournal = {Journal of Electrical Systems and Inf Technol},
	author = {Nti, Isaac Kofi and Teimeh, Moses and Nyarko-Boateng, Owusu and Adekoya, Adebayo Felix},
	urldate = {2024-03-29},
	date = {2020-09-09},
	langid = {english},
	keywords = {energy meteorology, weather and climate services},
}

@article{toumelin_emulating_2023,
	title = {Emulating the Adaptation of Wind Fields to Complex Terrain with Deep Learning},
	volume = {2},
	issn = {2769-7525},
	url = {https://journals.ametsoc.org/view/journals/aies/2/1/AIES-D-22-0034.1.xml},
	doi = {10.1175/AIES-D-22-0034.1},
	abstract = {Abstract Estimating the impact of wind-driven snow transport requires modeling wind fields with a lower grid spacing than the spacing on the order of 1 or a few kilometers used in the current numerical weather prediction ({NWP}) systems. In this context, we introduce a new strategy to downscale wind fields from {NWP} systems to decametric scales, using high-resolution (30 m) topographic information. Our method (named “{DEVINE}”) is leveraged on a convolutional neural network ({CNN}), trained to replicate the behavior of the complex atmospheric model {ARPS}, and was previously run on a large number (7279) of synthetic Gaussian topographies under controlled weather conditions. A 10-fold cross validation reveals that our {CNN} is able to accurately emulate the behavior of {ARPS} (mean absolute error for wind speed = 0.16 m s−1). We then apply {DEVINE} to real cases in the Alps, that is, downscaling wind fields forecast by the {AROME} {NWP} system using information from real alpine topographies. {DEVINE} proved able to reproduce main features of wind fields in complex terrain (acceleration on ridges, leeward deceleration, and deviations around obstacles). Furthermore, an evaluation on quality-checked observations acquired at 61 sites in the French Alps reveals improved behavior of the downscaled winds ({AROME} wind speed mean bias is reduced by 27\% with {DEVINE}), especially at the most elevated and exposed stations. Wind direction is, however, only slightly modified. Hence, despite some current limitations inherited from the {ARPS} simulations setup, {DEVINE} appears to be an efficient downscaling tool whose minimalist architecture, low input data requirements ({NWP} wind fields and high-resolution topography), and competitive computing times may be attractive for operational applications. Significance Statement Wind largely influences the spatial distribution of snow in mountains, with direct consequences on hydrology and avalanche hazard. Most operational models predicting wind in complex terrain use a grid spacing on the order of several kilometers, too coarse to represent the real patterns of mountain winds. We introduce a novel method based on deep learning to increase this spatial resolution while maintaining acceptable computational costs. Our method mimics the behavior of a complex model that is able to represent part of the complexity of mountain winds by using topographic information only. We compared our results with observations collected in complex terrain and showed that our model improves the representation of winds, notably at the most elevated and exposed observation stations.},
	number = {1},
	journaltitle = {Artificial Intelligence for the Earth Systems},
	author = {Toumelin, Louis Le and Gouttevin, Isabelle and Helbig, Nora and Galiez, Clovis and Roux, Mathis and Karbou, Fatima},
	urldate = {2024-07-23},
	date = {2023-03-06},
	keywords = {patches, post-processing},
}

@article{beucler_enforcing_2021,
	title = {Enforcing Analytic Constraints in Neural Networks Emulating Physical Systems},
	volume = {126},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.126.098302},
	doi = {10.1103/PhysRevLett.126.098302},
	abstract = {Neural networks can emulate nonlinear physical systems with high accuracy, yet they may produce physically inconsistent results when violating fundamental constraints. Here, we introduce a systematic way of enforcing nonlinear analytic constraints in neural networks via constraints in the architecture or the loss function. Applied to convective processes for climate modeling, architectural constraints enforce conservation laws to within machine precision without degrading performance. Enforcing constraints also reduces errors in the subsets of the outputs most impacted by the constraints.},
	pages = {098302},
	number = {9},
	journaltitle = {Physical Review Letters},
	shortjournal = {Phys. Rev. Lett.},
	author = {Beucler, Tom and Pritchard, Michael and Rasp, Stephan and Ott, Jordan and Baldi, Pierre and Gentine, Pierre},
	urldate = {2021-09-09},
	date = {2021-03-04},
	note = {Publisher: American Physical Society},
}

@misc{shen_engression_2024,
	title = {Engression: Extrapolation through the Lens of Distributional Regression},
	url = {http://arxiv.org/abs/2307.00835},
	doi = {10.48550/arXiv.2307.00835},
	shorttitle = {Engression},
	abstract = {Distributional regression aims to estimate the full conditional distribution of a target variable, given covariates. Popular methods include linear and tree-ensemble based quantile regression. We propose a neural network-based distributional regression methodology called `engression'. An engression model is generative in the sense that we can sample from the fitted conditional distribution and is also suitable for high-dimensional outcomes. Furthermore, we find that modelling the conditional distribution on training data can constrain the fitted function outside of the training support, which offers a new perspective to the challenging extrapolation problem in nonlinear regression. In particular, for `pre-additive noise' models, where noise is added to the covariates before applying a nonlinear transformation, we show that engression can successfully perform extrapolation under some assumptions such as monotonicity, whereas traditional regression approaches such as least-squares or quantile regression fall short under the same assumptions. Our empirical results, from both simulated and real data, validate the effectiveness of the engression method and indicate that the pre-additive noise model is typically suitable for many real-world scenarios. The software implementations of engression are available in both R and Python.},
	number = {{arXiv}:2307.00835},
	publisher = {{arXiv}},
	author = {Shen, Xinwei and Meinshausen, Nicolai},
	urldate = {2024-07-22},
	date = {2024-07-05},
	eprinttype = {arxiv},
	eprint = {2307.00835 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
}

@article{schefzik_ensemble_2017,
	title = {Ensemble calibration with preserved correlations: unifying and comparing ensemble copula coupling and member‐by‐member postprocessing},
	volume = {143},
	issn = {0035-9009, 1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qj.2984},
	doi = {10.1002/qj.2984},
	shorttitle = {Ensemble calibration with preserved correlations},
	pages = {999--1008},
	number = {703},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Q.J.R. Meteorol. Soc.},
	author = {Schefzik, Roman},
	urldate = {2022-10-18},
	date = {2017-01},
	langid = {english},
}

@article{cloke_ensemble_2009,
	title = {Ensemble flood forecasting: A review},
	volume = {375},
	issn = {0022-1694},
	url = {https://www.sciencedirect.com/science/article/pii/S0022169409003291},
	doi = {10.1016/j.jhydrol.2009.06.005},
	shorttitle = {Ensemble flood forecasting},
	abstract = {Operational medium range flood forecasting systems are increasingly moving towards the adoption of ensembles of numerical weather predictions ({NWP}), known as ensemble prediction systems ({EPS}), to drive their predictions. We review the scientific drivers of this shift towards such ‘ensemble flood forecasting’ and discuss several of the questions surrounding best practice in using {EPS} in flood forecasting systems. We also review the literature evidence of the ‘added value’ of flood forecasts based on {EPS} and point to remaining key challenges in using {EPS} successfully.},
	pages = {613--626},
	number = {3},
	journaltitle = {Journal of Hydrology},
	shortjournal = {Journal of Hydrology},
	author = {Cloke, H. L. and Pappenberger, F.},
	urldate = {2022-10-18},
	date = {2009-09-15},
	langid = {english},
}

@article{leutbecher_ensemble_2008,
	title = {Ensemble forecasting},
	volume = {227},
	issn = {0021-9991},
	url = {https://doi.org/10.1016/j.jcp.2007.02.014},
	doi = {10.1016/j.jcp.2007.02.014},
	abstract = {Numerical weather prediction models as well as the atmosphere itself can be viewed as nonlinear dynamical systems in which the evolution depends sensitively on the initial conditions. The fact that estimates of the current state are inaccurate and that numerical models have inadequacies, leads to forecast errors that grow with increasing forecast lead time. The growth of errors depends on the flow itself. Ensemble forecasting aims at quantifying this flow-dependent forecast uncertainty. The sources of uncertainty in weather forecasting are discussed. Then, an overview is given on evaluating probabilistic forecasts and their usefulness compared with single forecasts. Thereafter, the representation of uncertainties in ensemble forecasts is reviewed with an emphasis on the initial condition perturbations. The review is complemented by a detailed description of the methodology to generate initial condition perturbations of the Ensemble Prediction System ({EPS}) of the European Centre for Medium-Range Weather Forecasts ({ECMWF}). These perturbations are based on the leading part of the singular value decomposition of the operator describing the linearised dynamics over a finite time interval. The perturbations are flow-dependent as the linearisation is performed with respect to a solution of the nonlinear forecast model. The extent to which the current {ECMWF} ensemble prediction system is capable of predicting flow-dependent variations in uncertainty is assessed for the large-scale flow in mid-latitudes.},
	pages = {3515--3539},
	number = {7},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {J. Comput. Phys.},
	author = {Leutbecher, M. and Palmer, T. N.},
	urldate = {2024-05-10},
	date = {2008-03-01},
	keywords = {numerical weather prediction, predictability, uncertainty},
}

@article{bremnes_ensemble_2020,
	title = {Ensemble Postprocessing Using Quantile Function Regression Based on Neural Networks and Bernstein Polynomials},
	volume = {148},
	issn = {0027-0644, 1520-0493},
	url = {http://journals.ametsoc.org/doi/10.1175/MWR-D-19-0227.1},
	doi = {10.1175/MWR-D-19-0227.1},
	abstract = {Abstract The value of ensemble forecasts is well documented. However, postprocessing by statistical methods is usually required to make forecasts reliable in a probabilistic sense. In this work a flexible statistical method for making probabilistic forecasts in terms of quantile functions is proposed. The quantile functions are specified by linear combinations of Bernstein basis polynomials, and their coefficients are assumed to be related to ensemble forecasts by means of a highly adaptable neural network. This leads to many parameters to estimate, but a recent learning algorithm often applied to deep-learning problems makes this feasible and provides robust estimates. The method is applied to {\textbackslash}textasciitilde2 yr of ensemble wind speed forecasting data at 125 Norwegian stations for lead time +60 h. An intercomparison with two quantile regression methods shows improvements in quantile skill score of nearly 1\%. The most appealing feature of the method is arguably its versatility.},
	pages = {403--414},
	number = {1},
	journaltitle = {Monthly Weather Review},
	author = {Bremnes, John Bjørnar},
	urldate = {2023-08-29},
	date = {2020-01},
	langid = {english},
	keywords = {post-processing},
}

@misc{mlakar_ensemble_2023,
	title = {Ensemble weather forecast post-processing with a flexible probabilistic neural network approach},
	url = {http://arxiv.org/abs/2303.17610},
	doi = {10.48550/arXiv.2303.17610},
	abstract = {Ensemble forecast post-processing is a necessary step in producing accurate probabilistic forecasts. Conventional post-processing methods operate by estimating the parameters of a parametric distribution, frequently on a per-location or per-lead-time basis. We propose a novel, neural network-based method, which produces forecasts for all locations and lead times, jointly. To relax the distributional assumption of many post-processing methods, our approach incorporates normalizing flows as flexible parametric distribution estimators. This enables us to model varying forecast distributions in a mathematically exact way. We demonstrate the effectiveness of our method in the context of the {EUPPBench} benchmark, where we conduct temperature forecast post-processing for stations in a sub-region of western Europe. We show that our novel method exhibits state-of-the-art performance on the benchmark, outclassing our previous, well-performing entry. Additionally, by providing a detailed comparison of three variants of our novel post-processing method, we elucidate the reasons why our method outperforms per-lead-time-based approaches and approaches with distributional assumptions.},
	number = {{arXiv}:2303.17610},
	publisher = {{arXiv}},
	author = {Mlakar, Peter and Merše, Janko and Pucer, Jana Faganeli},
	urldate = {2024-05-22},
	date = {2023-04-27},
	eprinttype = {arxiv},
	eprint = {2303.17610 [physics]},
	keywords = {ensemble prediction, neural networks, post-processing},
}

@article{mlakar_ensemble_2024,
	title = {Ensemble weather forecast post‐processing with a flexible probabilistic neural network approach},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4809},
	doi = {10.1002/qj.4809},
	abstract = {Abstract 
            Ensemble forecast post‐processing is a necessary step in producing accurate probabilistic forecasts. Many post‐processing methods operate by estimating the parameters of a predetermined probability distribution; others operate on a per‐lead‐time or per‐station basis. All of the aforementioned factors either limit the expressive power of the methods in question or require additional models, one for each lead time and station. We propose a novel, neural network‐based method that produces forecasts for all lead times jointly and requires a single model for all stations. We incorporate normalizing spline flows as flexible parametric distribution estimators, which enables us to model complex forecast distributions. Furthermore, we demonstrate the effectiveness of our method in the context of the {EUPPBench} benchmark, where we conduct 2‐m temperature forecast post‐processing for stations in a subregion of Europe. We show that our novel method exhibits state‐of‐the‐art performance on the benchmark, improving upon other well‐performing entries. Additionally, by providing a detailed comparison of three variants of our novel post‐processing method, we elucidate the reasons why our method outperforms per‐lead‐time‐based approaches and approaches with distributional assumptions.},
	pages = {qj.4809},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Mlakar, Peter and Merše, Janko and Faganeli Pucer, Jana},
	urldate = {2024-07-24},
	date = {2024-07-22},
	langid = {english},
	keywords = {post-processing},
}

@misc{andersson_environmental_2023,
	title = {Environmental Sensor Placement with Convolutional Gaussian Neural Processes},
	url = {http://arxiv.org/abs/2211.10381},
	doi = {10.48550/arXiv.2211.10381},
	abstract = {Environmental sensors are crucial for monitoring weather conditions and the impacts of climate change. However, it is challenging to place sensors in a way that maximises the informativeness of their measurements, particularly in remote regions like Antarctica. Probabilistic machine learning models can suggest informative sensor placements by finding sites that maximally reduce prediction uncertainty. Gaussian process ({GP}) models are widely used for this purpose, but they struggle with capturing complex non-stationary behaviour and scaling to large datasets. This paper proposes using a convolutional Gaussian neural process ({ConvGNP}) to address these issues. A {ConvGNP} uses neural networks to parameterise a joint Gaussian distribution at arbitrary target locations, enabling flexibility and scalability. Using simulated surface air temperature anomaly over Antarctica as training data, the {ConvGNP} learns spatial and seasonal non-stationarities, outperforming a non-stationary {GP} baseline. In a simulated sensor placement experiment, the {ConvGNP} better predicts the performance boost obtained from new observations than {GP} baselines, leading to more informative sensor placements. We contrast our approach with physics-based sensor placement methods and propose future steps towards an operational sensor placement recommendation system. Our work could help to realise environmental digital twins that actively direct measurement sampling to improve the digital representation of reality.},
	number = {{arXiv}:2211.10381},
	publisher = {{arXiv}},
	author = {Andersson, Tom R. and Bruinsma, Wessel P. and Markou, Stratis and Requeima, James and Coca-Castro, Alejandro and Vaughan, Anna and Ellis, Anna-Louise and Lazzara, Matthew A. and Jones, Dani and Hosking, J. Scott and Turner, Richard E.},
	urldate = {2024-05-27},
	date = {2023-05-15},
	eprinttype = {arxiv},
	eprint = {2211.10381 [cs, stat]},
	keywords = {geostatistics, neural processes},
}

@article{simmons_error_1995,
	title = {Error growth and estimates of predictability from the {ECMWF} forecasting system},
	volume = {121},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.49712152711},
	doi = {10.1002/qj.49712152711},
	abstract = {Abstract 
            Examination has been made of the skill of {ECMWF} forecasts of the 500 {hPa} height field produced daily out to ten days ahead, verifying in the period from 1 December 1980 to 31 May 1994. Over this time accuracy has been improved substantially over the first half of the forecast range. the systematic (seasonal‐mean) component of the error has been greatly reduced at all forecast times, but there has been little reduction in the non‐systematic (transient) component later in the range. 
            The simple model proposed by Lorenz for the intrinsic growth of forecast error has been applied to the evolution of differences between consecutive forecasts. the implied growth‐rates of small forecast errors have increased significantly since 1981. They do not show much variation with season, and are a little lower in the southern than in the northern hemisphere. the most recent error‐doubling times are around 1.5 days for the northern hemisphere and 1.7 days for the southern hemisphere. Error saturation levels are at present similar to or greater than those of the 1981 version of the model, having been significantly lower in intermediate years. the accuracy of recent short‐ and early medium‐range forecasts and realism of the climatology of the forecast model support the view that estimates of intrinsic error‐growth parameters from the current forecasting system are more reliable than those obtained earlier. Forecast accuracy later in the medium range may thus not have benefited fully from improvements earlier in the range because of the faster error‐growth associated with a more active, though more realistic, forecast model. Overprediction of variance may nevertheless detrimentally affect present levels of skill and estimates of predictability in all seasons other than summer. 
            The error‐growth model currently indicates that it is possible, in principle, to make deterministic mediumrange forecasts for the extratropical 500 {hPa} height field of the northern hemisphere that are as accurate five days ahead as present forecasts are three days ahead, provided the one‐day forecast error can be reduced by the same factor in the future as has actually been achieved in the years since 1981. the level of error currently reached at day seven would then be reached at around day ten. the scope for improvement of forecasts for the southern hemisphere appears to be rather larger. Improvements seem to be possible throughout the spectral range studied, up to total wave‐number 40. This is found also for the rotational and divergent wind components at 850 and 200 {hPa}. For these components, particularly the divergent component, there is a quite pronounced error in the representation of the largest scales.},
	pages = {1739--1771},
	number = {527},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Simmons, A. J. and Mureau, R. and Petroliagis, T.},
	urldate = {2024-05-22},
	date = {1995-10},
	langid = {english},
}

@article{zamo_estimation_2018,
	title = {Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts},
	volume = {50},
	issn = {1874-8953},
	url = {https://doi.org/10.1007/s11004-017-9709-7},
	doi = {10.1007/s11004-017-9709-7},
	abstract = {The continuous ranked probability score ({CRPS}) is a much used measure of performance for probabilistic forecasts of a scalar observation. It is a quadratic measure of the difference between the forecast cumulative distribution function ({CDF}) and the empirical {CDF} of the observation. Analytic formulations of the {CRPS} can be derived for most classical parametric distributions, and be used to assess the efficiency of different {CRPS} estimators. When the true forecast {CDF} is not fully known, but represented as an ensemble of values, the {CRPS} is estimated with some error. Thus, using the {CRPS} to compare parametric probabilistic forecasts with ensemble forecasts may be misleading due to the unknown error of the estimated {CRPS} for the ensemble. With simulated data, the impact of the type of the verified ensemble (a random sample or a set of quantiles) on the {CRPS} estimation is studied. Based on these simulations, recommendations are issued to choose the most accurate {CRPS} estimator according to the type of ensemble. The interest of these recommendations is illustrated with real ensemble weather forecasts. Also, relationships between several estimators of the {CRPS} are demonstrated and used to explain the differences of accuracy between the estimators.},
	pages = {209--234},
	number = {2},
	journaltitle = {Mathematical Geosciences},
	shortjournal = {Math Geosci},
	author = {Zamo, Michaël and Naveau, Philippe},
	urldate = {2024-07-19},
	date = {2018-02-01},
	langid = {english},
	keywords = {scoring rules, verification},
}

@article{jordan_evaluating_2019,
	title = {Evaluating Probabilistic Forecasts with {scoringRules}},
	volume = {90},
	rights = {Copyright (c) 2019 Alexander Jordan, Fabian Krüger, Sebastian Lerch},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v090.i12},
	doi = {10.18637/jss.v090.i12},
	abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The {scoringRules} package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
	pages = {1--37},
	journaltitle = {Journal of Statistical Software},
	author = {Jordan, Alexander and Krüger, Fabian and Lerch, Sebastian},
	urldate = {2024-05-27},
	date = {2019-08-21},
	langid = {english},
	keywords = {scoring rules, software, verification},
}

@article{jordan_evaluating_2019-1,
	title = {Evaluating Probabilistic Forecasts with {scoringRules}},
	volume = {90},
	rights = {Copyright (c) 2019 Alexander Jordan, Fabian Krüger, Sebastian Lerch},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v090.i12},
	doi = {10.18637/jss.v090.i12},
	abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The {scoringRules} package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
	pages = {1--37},
	journaltitle = {Journal of Statistical Software},
	author = {Jordan, Alexander and Krüger, Fabian and Lerch, Sebastian},
	urldate = {2024-07-19},
	date = {2019-08-21},
	langid = {english},
	keywords = {R, comparative evaluation, ensemble forecasts, out-of-sample evaluation, predictive distributions, proper scoring rules, score computation},
}

@article{palmer_extended-range_1993,
	title = {Extended-Range Atmospheric Prediction and the Lorenz Model},
	volume = {74},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/74/1/1520-0477_1993_074_0049_erapat_2_0_co_2.xml},
	doi = {10.1175/1520-0477(1993)074<0049:ERAPAT>2.0.CO;2},
	abstract = {The physical basis for extended-range prediction is explored using the famous three-component Lorenz convection model, taken as a conceptual representation of the chaotic extratropical circulation, and extended by coupling to a linear oscillator to represent large-scale tropical–extratropical interactions. The model is used to analyze the roles of time averaging and ensemble forecasting, and, in extended form, the impact of both anomalous tropical sea surface temperature and anomalous extratropical sea surface temperature. The conceptual paradigms and analytic calculations presented are used to interpret results from numerical weather prediction and general circulation model experiments. Some remarks on the relevance of predictability studies for the climate change problem are given.},
	pages = {49--66},
	number = {1},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Palmer, T. N.},
	urldate = {2024-05-16},
	date = {1993-01-01},
	langid = {english},
}

@article{cao_extrapolation_2023,
	title = {Extrapolation and {AI} transparency: Why machine learning models should reveal when they make decisions beyond their training},
	volume = {10},
	issn = {2053-9517, 2053-9517},
	url = {http://journals.sagepub.com/doi/10.1177/20539517231169731},
	doi = {10.1177/20539517231169731},
	shorttitle = {Extrapolation and {AI} transparency},
	abstract = {The right to artificial intelligence ({AI}) explainability has consolidated as a consensus in the research community and policy-making. However, a key component of explainability has been missing: extrapolation, which can reveal whether a model is making inferences beyond the boundaries of its training. We report that {AI} models extrapolate outside their range of familiar data, frequently and without notifying the users and stakeholders. Knowing whether a model has extrapolated or not is a fundamental insight that should be included in explaining {AI} models in favor of transparency, accountability, and fairness. Instead of dwelling on the negatives, we offer ways to clear the roadblocks in promoting {AI} transparency. Our commentary accompanies practical clauses useful to include in {AI} regulations such as the {AI} Bill of Rights, the National {AI} Initiative Act in the United States, and the {AI} Act by the European Commission.},
	pages = {205395172311697},
	number = {1},
	journaltitle = {Big Data \& Society},
	shortjournal = {Big Data \& Society},
	author = {Cao, Xuenan and Yousefzadeh, Roozbeh},
	urldate = {2024-07-22},
	date = {2023-01},
	langid = {english},
	keywords = {extrapolation},
}

@article{jia_feature_2022,
	title = {Feature dimensionality reduction: a review},
	volume = {8},
	issn = {2198-6053},
	url = {https://doi.org/10.1007/s40747-021-00637-x},
	doi = {10.1007/s40747-021-00637-x},
	shorttitle = {Feature dimensionality reduction},
	abstract = {As basic research, it has also received increasing attention from people that the “curse of dimensionality” will lead to increase the cost of data storage and computing; it also influences the efficiency and accuracy of dealing with problems. Feature dimensionality reduction as a key link in the process of pattern recognition has become one hot and difficulty spot in the field of pattern recognition, machine learning and data mining. It is one of the most challenging research fields, which has been favored by most of the scholars’ attention. How to implement “low loss” in the process of feature dimension reduction, keep the nature of the original data, find out the best mapping and get the optimal low dimensional data are the keys aims of the research. In this paper, two-dimensionality reduction methods, feature selection and feature extraction, are introduced; the current mainstream dimensionality reduction algorithms are analyzed, including the method for small sample and method based on deep learning. For each algorithm, examples of their application are given and the advantages and disadvantages of these methods are evaluated.},
	pages = {2663--2693},
	number = {3},
	journaltitle = {Complex \& Intelligent Systems},
	shortjournal = {Complex Intell. Syst.},
	author = {Jia, Weikuan and Sun, Meili and Lian, Jian and Hou, Sujuan},
	urldate = {2024-07-22},
	date = {2022-06-01},
	langid = {english},
	keywords = {Curse of dimensionality, Dimension reduction, Feature extraction, Feature selection},
}

@article{cai_feature_2018,
	title = {Feature selection in machine learning: A new perspective},
	volume = {300},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231218302911},
	doi = {10.1016/j.neucom.2017.11.077},
	shorttitle = {Feature selection in machine learning},
	abstract = {High-dimensional data analysis is a challenge for researchers and engineers in the fields of machine learning and data mining. Feature selection provides an effective way to solve this problem by removing irrelevant and redundant data, which can reduce computation time, improve learning accuracy, and facilitate a better understanding for the learning model or data. In this study, we discuss several frequently-used evaluation measures for feature selection, and then survey supervised, unsupervised, and semi-supervised feature selection methods, which are widely applied in machine learning problems, such as classification and clustering. Lastly, future challenges about feature selection are discussed.},
	pages = {70--79},
	journaltitle = {Neurocomputing},
	shortjournal = {Neurocomputing},
	author = {Cai, Jie and Luo, Jiawei and Wang, Shulin and Yang, Sheng},
	urldate = {2024-07-16},
	date = {2018-07-26},
}

@article{stephenson_forecast_2005,
	title = {Forecast assimilation: a unified framework for the combination of multi-model weather and climate predictions},
	volume = {57},
	issn = {1600-0870},
	url = {https://a.tellusjournals.se/article/10.3402/tellusa.v57i3.14664/},
	doi = {10.3402/tellusa.v57i3.14664},
	shorttitle = {Forecast assimilation},
	pages = {253},
	number = {3},
	journaltitle = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Stephenson, D. B. and Coelho, C. A. S. and Doblas-Reyes, F. J. and Balmaseda, M.},
	urldate = {2024-05-22},
	date = {2005-01-01},
}

@incollection{murphy_forecast_1997,
	location = {Cambridge},
	title = {Forecast value: prototype decision-making models},
	isbn = {9780521434201},
	url = {https://www.cambridge.org/core/books/economic-value-of-weather-and-climate-forecasts/forecast-value-prototype-decisionmaking-models/5A8DA1E4D0ADA7F7423AD620926CD180},
	shorttitle = {Forecast value},
	abstract = {{IntroductionIn} this chapter, theoretical relationships between the scientific quality and economic value of imperfect weather forecasts are considered. Prototype decision-making models are treated that, while relatively simple in structure, still capture some of the essential features (e.g., the “dynamics”) of real-world situations. The emphasis is on analytical results that can be obtained concerning the structure of the optimal policy and the shape of the “quality/value curve.” It is anticipated that knowledge of such theoretical properties for prototype models will provide insight into analogous properties for real-world decision-making problems that are inherently much more complex.The prospects for increases in the quality of weather forecasts in the future have been discussed in Chapter 1 of this volume, thereby providing a partial justification for the hypothetical increases in forecast quality that are assumed in the present chapter. Various aspects of forecast quality (e.g., bias and accuracy) have been described in Chapter 2. A simplified form of weather information is treated here in which a one-dimensional measure of quality can be defined that is synonymous with the concept of sufficiency (also described in Chapter 2). The Bayesian decision-theoretic approach to assessing the economic value of imperfect information is adopted, an approach that has been introduced in Chapter 3. Analytical results obtained for prototype decision-making models are compared with those for real-world case studies that have also employed this prescriptive approach to real-world decision-making problems (reviewed in Chapter 4). Reasons for the underutilization (or nonoptimal use) of existing weather forecasts have been outlined in Chapter 5, and some explanations for such behavior based on theoretical considerations are presented here.},
	pages = {183--218},
	booktitle = {Economic Value of Weather and Climate Forecasts},
	publisher = {Cambridge University Press},
	author = {Katz, Richard W. and Murphy, Allan H.},
	editor = {Murphy, Allan H. and Katz, Richard W.},
	urldate = {2024-06-26},
	date = {1997},
	doi = {10.1017/CBO9780511608278.007},
	keywords = {weather and climate services},
}

@book{jolliffe_forecast_2011,
	edition = {1},
	title = {Forecast Verification: A Practitioner's Guide in Atmospheric Science},
	rights = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	isbn = {9780470660713 9781119960003},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119960003},
	shorttitle = {Forecast Verification},
	publisher = {Wiley},
	author = {Jolliffe, Ian T. and Stephenson, David B.},
	urldate = {2024-06-07},
	date = {2011-12-16},
	langid = {english},
	doi = {10.1002/9781119960003},
	keywords = {verification},
}

@misc{keisler_forecasting_2022,
	title = {Forecasting Global Weather with Graph Neural Networks},
	url = {http://arxiv.org/abs/2202.07575},
	doi = {10.48550/arXiv.2202.07575},
	abstract = {We present a data-driven approach for forecasting global weather using graph neural networks. The system learns to step forward the current 3D atmospheric state by six hours, and multiple steps are chained together to produce skillful forecasts going out several days into the future. The underlying model is trained on reanalysis data from {ERA}5 or forecast data from {GFS}. Test performance on metrics such as Z500 (geopotential height) and T850 (temperature) improves upon previous data-driven approaches and is comparable to operational, full-resolution, physical models from {GFS} and {ECMWF}, at least when evaluated on 1-degree scales and when using reanalysis initial conditions. We also show results from connecting this data-driven model to live, operational forecasts from {GFS}.},
	number = {{arXiv}:2202.07575},
	publisher = {{arXiv}},
	author = {Keisler, Ryan},
	urldate = {2024-05-29},
	date = {2022-02-15},
	eprinttype = {arxiv},
	eprint = {2202.07575 [physics]},
	keywords = {data-driven weather prediction, deterministic prediction},
}

@article{petropoulos_forecasting_2022,
	title = {Forecasting: theory and practice},
	volume = {38},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207021001758},
	doi = {10.1016/j.ijforecast.2021.11.001},
	shorttitle = {Forecasting},
	abstract = {Forecasting has always been at the forefront of decision making and planning. The uncertainty that surrounds the future is both exciting and challenging, with individuals and organisations seeking to minimise risks and maximise utilities. The large number of forecasting applications calls for a diverse set of forecasting methods to tackle real-life challenges. This article provides a non-systematic review of the theory and the practice of forecasting. We provide an overview of a wide range of theoretical, state-of-the-art models, methods, principles, and approaches to prepare, produce, organise, and evaluate forecasts. We then demonstrate how such theoretical concepts are applied in a variety of real-life contexts. We do not claim that this review is an exhaustive list of methods and applications. However, we wish that our encyclopedic presentation will offer a point of reference for the rich work that has been undertaken over the last decades, with some key insights for the future of forecasting theory and practice. Given its encyclopedic nature, the intended mode of reading is non-linear. We offer cross-references to allow the readers to navigate through the various topics. We complement the theoretical concepts and applications covered by large lists of free or open-source software implementations and publicly-available databases.},
	pages = {705--871},
	number = {3},
	journaltitle = {International Journal of Forecasting},
	shortjournal = {International Journal of Forecasting},
	author = {Petropoulos, Fotios and Apiletti, Daniele and Assimakopoulos, Vassilios and Babai, Mohamed Zied and Barrow, Devon K. and Ben Taieb, Souhaib and Bergmeir, Christoph and Bessa, Ricardo J. and Bijak, Jakub and Boylan, John E. and Browell, Jethro and Carnevale, Claudio and Castle, Jennifer L. and Cirillo, Pasquale and Clements, Michael P. and Cordeiro, Clara and Cyrino Oliveira, Fernando Luiz and De Baets, Shari and Dokumentov, Alexander and Ellison, Joanne and Fiszeder, Piotr and Franses, Philip Hans and Frazier, David T. and Gilliland, Michael and Gönül, M. Sinan and Goodwin, Paul and Grossi, Luigi and Grushka-Cockayne, Yael and Guidolin, Mariangela and Guidolin, Massimo and Gunter, Ulrich and Guo, Xiaojia and Guseo, Renato and Harvey, Nigel and Hendry, David F. and Hollyman, Ross and Januschowski, Tim and Jeon, Jooyoung and Jose, Victor Richmond R. and Kang, Yanfei and Koehler, Anne B. and Kolassa, Stephan and Kourentzes, Nikolaos and Leva, Sonia and Li, Feng and Litsiou, Konstantia and Makridakis, Spyros and Martin, Gael M. and Martinez, Andrew B. and Meeran, Sheik and Modis, Theodore and Nikolopoulos, Konstantinos and Önkal, Dilek and Paccagnini, Alessia and Panagiotelis, Anastasios and Panapakidis, Ioannis and Pavía, Jose M. and Pedio, Manuela and Pedregal, Diego J. and Pinson, Pierre and Ramos, Patrícia and Rapach, David E. and Reade, J. James and Rostami-Tabar, Bahman and Rubaszek, Michał and Sermpinis, Georgios and Shang, Han Lin and Spiliotis, Evangelos and Syntetos, Aris A. and Talagala, Priyanga Dilini and Talagala, Thiyanga S. and Tashman, Len and Thomakos, Dimitrios and Thorarinsdottir, Thordis and Todini, Ezio and Trapero Arenas, Juan Ramón and Wang, Xiaoqian and Winkler, Robert L. and Yusupova, Alisa and Ziel, Florian},
	urldate = {2024-06-11},
	date = {2022-07-01},
}

@misc{pathak_fourcastnet_2022,
	title = {{FourCastNet}: A Global Data-driven High-resolution Weather Model using Adaptive Fourier Neural Operators},
	url = {http://arxiv.org/abs/2202.11214},
	doi = {10.48550/arXiv.2202.11214},
	shorttitle = {{FourCastNet}},
	abstract = {{FourCastNet}, short for Fourier Forecasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium-range global predictions at \$0.25{\textasciicircum}\{{\textbackslash}circ\}\$ resolution. {FourCastNet} accurately forecasts high-resolution, fast-timescale variables such as the surface wind speed, precipitation, and atmospheric water vapor. It has important implications for planning wind energy resources, predicting extreme weather events such as tropical cyclones, extra-tropical cyclones, and atmospheric rivers. {FourCastNet} matches the forecasting accuracy of the {ECMWF} Integrated Forecasting System ({IFS}), a state-of-the-art Numerical Weather Prediction ({NWP}) model, at short lead times for large-scale variables, while outperforming {IFS} for variables with complex fine-scale structure, including precipitation. {FourCastNet} generates a week-long forecast in less than 2 seconds, orders of magnitude faster than {IFS}. The speed of {FourCastNet} enables the creation of rapid and inexpensive large-ensemble forecasts with thousands of ensemble-members for improving probabilistic forecasting. We discuss how data-driven deep learning models such as {FourCastNet} are a valuable addition to the meteorology toolkit to aid and augment {NWP} models.},
	number = {{arXiv}:2202.11214},
	publisher = {{arXiv}},
	author = {Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},
	urldate = {2024-06-05},
	date = {2022-02-22},
	eprinttype = {arxiv},
	eprint = {2202.11214 [physics]},
	keywords = {data-driven weather prediction},
}

@article{taillardat_research_2020,
	title = {From research to applications – examples of operational ensemble post-processing in France using machine learning},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/329/2020/},
	doi = {10.5194/npg-27-329-2020},
	abstract = {Statistical post-processing of ensemble forecasts, from simple linear regressions to more sophisticated techniques, is now a well-known procedure for correcting biased and poorly dispersed ensemble weather predictions. However, practical applications in national weather services are still in their infancy compared to deterministic post-processing. This paper presents two different applications of ensemble post-processing using machine learning at an industrial scale. The first is a station-based post-processing of surface temperature and subsequent interpolation to a grid in a medium-resolution ensemble system. The second is a gridded post-processing of hourly rainfall amounts in a high-resolution ensemble prediction system. The techniques used rely on quantile regression forests ({QRFs}) and ensemble copula coupling ({ECC}), chosen for their robustness and simplicity of training regardless of the variable subject to calibration.

 Moreover, some variants of classical techniques used, such as {QRF} and {ECC}, were developed in order to adjust to operational constraints. A forecast anomaly-based {QRF} is used for temperature for a better prediction of cold and heat waves. A variant of {ECC} for hourly rainfall was built, accounting for more realistic longer rainfall accumulations. We show that both forecast quality and forecast value are improved compared to the raw ensemble. Finally, comments about model size and computation time are made.},
	pages = {329--347},
	number = {2},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Taillardat, Maxime and Mestre, Olivier},
	urldate = {2024-07-08},
	date = {2020-05-29},
}

@book{coiffier_fundamentals_2011,
	location = {Cambridge},
	title = {Fundamentals of Numerical Weather Prediction},
	isbn = {978-1-107-00103-9},
	url = {https://www.cambridge.org/core/books/fundamentals-of-numerical-weather-prediction/9113980F4309886F58C0E8C64853E130},
	abstract = {Numerical models have become essential tools in environmental science, particularly in weather forecasting and climate prediction. This book provides a comprehensive overview of the techniques used in these fields, with emphasis on the design of the most recent numerical models of the atmosphere. It presents a short history of numerical weather prediction and its evolution, before describing the various model equations and how to solve them numerically. It outlines the main elements of a meteorological forecast suite, and the theory is illustrated throughout with practical examples of operational models and parameterizations of physical processes. This book is founded on the author's many years of experience, as a scientist at Météo-France and teaching university-level courses. It is a practical and accessible textbook for graduate courses and a handy resource for researchers and professionals in atmospheric physics, meteorology and climatology, as well as the related disciplines of fluid dynamics, hydrology and oceanography.},
	publisher = {Cambridge University Press},
	author = {Coiffier, Jean},
	urldate = {2024-05-25},
	date = {2011},
	doi = {10.1017/CBO9780511734458},
}

@article{chen_fuxi_2023,
	title = {{FuXi}: a cascade machine learning forecasting system for 15-day global weather forecast},
	volume = {6},
	rights = {2023 The Author(s)},
	issn = {2397-3722},
	url = {https://www.nature.com/articles/s41612-023-00512-1},
	doi = {10.1038/s41612-023-00512-1},
	shorttitle = {{FuXi}},
	abstract = {Over the past few years, the rapid development of machine learning ({ML}) models for weather forecasting has led to state-of-the-art {ML} models that have superior performance compared to the European Centre for Medium-Range Weather Forecasts ({ECMWF})’s high-resolution forecast ({HRES}), which is widely considered as the world’s best physics-based weather forecasting system. Specifically, {ML} models have outperformed {HRES} in 10-day forecasts with a spatial resolution of 0.25∘. However, the challenge remains in mitigating the accumulation of forecast errors for longer effective forecasts, such as achieving comparable performance to the {ECMWF} ensemble in 15-day forecasts. Despite various efforts to reduce accumulation errors, such as implementing autoregressive multi-time step loss, relying on a single model has been found to be insufficient for achieving optimal performance in both short and long lead times. Therefore, we present {FuXi}, a cascaded {ML} weather forecasting system that provides 15-day global forecasts at a temporal resolution of 6 hours and a spatial resolution of 0.25∘. {FuXi} is developed using 39 years of the {ECMWF} {ERA}5 reanalysis dataset. The performance evaluation demonstrates that {FuXi} has forecast performance comparable to {ECMWF} ensemble mean ({EM}) in 15-day forecasts. {FuXi} surpasses the skillful forecast lead time achieved by {ECMWF} {HRES} by extending the lead time for Z500 from 9.25 to 10.5 days and for T2M from 10 to 14.5 days. Moreover, the {FuXi} ensemble is created by perturbing initial conditions and model parameters, enabling it to provide forecast uncertainty and demonstrating promising results when compared to the {ECMWF} ensemble.},
	pages = {1--11},
	number = {1},
	journaltitle = {npj Climate and Atmospheric Science},
	shortjournal = {npj Clim Atmos Sci},
	author = {Chen, Lei and Zhong, Xiaohui and Zhang, Feng and Cheng, Yuan and Xu, Yinghui and Qi, Yuan and Li, Hao},
	urldate = {2024-06-05},
	date = {2023-11-16},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@book{rasmussen_gaussian_2006,
	title = {Gaussian processes for machine learning},
	volume = {2},
	publisher = {{MIT} press Cambridge, {MA}},
	author = {Rasmussen, Carl Edward and Williams, Christopher {KI}},
	date = {2006},
}

@misc{price_gencast_2024,
	title = {{GenCast}: Diffusion-based ensemble forecasting for medium-range weather},
	url = {http://arxiv.org/abs/2312.15796},
	doi = {10.48550/arXiv.2312.15796},
	shorttitle = {{GenCast}},
	abstract = {Weather forecasts are fundamentally uncertain, so predicting the range of probable weather scenarios is crucial for important decisions, from warning the public about hazardous weather, to planning renewable energy use. Here, we introduce {GenCast}, a probabilistic weather model with greater skill and speed than the top operational medium-range weather forecast in the world, the European Centre for Medium-Range Forecasts ({ECMWF})'s ensemble forecast, {ENS}. Unlike traditional approaches, which are based on numerical weather prediction ({NWP}), {GenCast} is a machine learning weather prediction ({MLWP}) method, trained on decades of reanalysis data. {GenCast} generates an ensemble of stochastic 15-day global forecasts, at 12-hour steps and 0.25 degree latitude-longitude resolution, for over 80 surface and atmospheric variables, in 8 minutes. It has greater skill than {ENS} on 97.4\% of 1320 targets we evaluated, and better predicts extreme weather, tropical cyclones, and wind power production. This work helps open the next chapter in operational weather forecasting, where critical weather-dependent decisions are made with greater accuracy and efficiency.},
	number = {{arXiv}:2312.15796},
	publisher = {{arXiv}},
	author = {Price, Ilan and Sanchez-Gonzalez, Alvaro and Alet, Ferran and Andersson, Tom R. and El-Kadi, Andrew and Masters, Dominic and Ewalds, Timo and Stott, Jacklynn and Mohamed, Shakir and Battaglia, Peter and Lam, Remi and Willson, Matthew},
	urldate = {2024-06-05},
	date = {2024-05-01},
	eprinttype = {arxiv},
	eprint = {2312.15796 [physics]},
	keywords = {data-driven weather prediction},
}

@article{chen_generative_2024,
	title = {Generative machine learning methods for multivariate ensemble postprocessing},
	volume = {18},
	issn = {1932-6157, 1941-7330},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-18/issue-1/Generative-machine-learning-methods-for-multivariate-ensemble-postprocessing/10.1214/23-AOAS1784.full},
	doi = {10.1214/23-AOAS1784},
	abstract = {Ensemble weather forecasts based on multiple runs of numerical weather prediction models typically show systematic errors and require postprocessing to obtain reliable forecasts. Accurately modeling multivariate dependencies is crucial in many practical applications, and various approaches to multivariate postprocessing have been proposed where ensemble predictions are first postprocessed separately in each margin and multivariate dependencies are then restored via copulas. These two-step methods share common key limitations, in particular, the difficulty to include additional predictors in modeling the dependencies. We propose a novel multivariate postprocessing method based on generative machine learning to address these challenges. In this new class of nonparametric data-driven distributional regression models, samples from the multivariate forecast distribution are directly obtained as output of a generative neural network. The generative model is trained by optimizing a proper scoring rule, which measures the discrepancy between the generated and observed data, conditional on exogenous input variables. Our method does not require parametric assumptions on univariate distributions or multivariate dependencies and allows for incorporating arbitrary predictors. In two case studies on multivariate temperature and wind speed forecasting at weather stations over Germany, our generative model shows significant improvements over state-of-the-art methods and particularly improves the representation of spatial dependencies.},
	pages = {159--183},
	number = {1},
	journaltitle = {The Annals of Applied Statistics},
	author = {Chen, Jieyu and Janke, Tim and Steinke, Florian and Lerch, Sebastian},
	urldate = {2024-05-22},
	date = {2024-03},
	keywords = {generative, multivariate prediction, probabilistic forecasting},
}

@article{matthews_gpflow_2017,
	title = {{GPflow}: A Gaussian Process Library using {TensorFlow}},
	volume = {18},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v18/16-537.html},
	shorttitle = {{GPflow}},
	abstract = {{GPflow} is a Gaussian process library that uses {TensorFlow} for its core computations and Python for its front end. The distinguishing features of {GPflow} are that it uses variational inference as the primary approximation method, provides concise code through the use of automatic differentiation, has been engineered with a particular emphasis on software testing and is able to exploit {GPU} hardware.},
	pages = {1--6},
	number = {40},
	journaltitle = {Journal of Machine Learning Research},
	author = {Matthews, Alexander G. de G. and Wilk, Mark van der and Nickson, Tom and Fujii, Keisuke and Boukouvalas, Alexis and Le{\textbackslash}\{\{{\textbackslash}textbackslash\}'o{\textbackslash}\}n-Villagr{\textbackslash}\{\{{\textbackslash}textbackslash\}'a{\textbackslash}\}, Pablo and Ghahramani, Zoubin and Hensman, James},
	urldate = {2024-05-17},
	date = {2017},
}

@article{pinder_gpjax_2022,
	title = {{GPJax}: A Gaussian Process Framework in {JAX}},
	volume = {7},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.04455},
	doi = {10.21105/joss.04455},
	shorttitle = {{GPJax}},
	abstract = {Pinder et al., (2022). {GPJax}: A Gaussian Process Framework in {JAX}. Journal of Open Source Software, 7(75), 4455, https://doi.org/10.21105/joss.04455},
	pages = {4455},
	number = {75},
	journaltitle = {Journal of Open Source Software},
	author = {Pinder, Thomas and Dodd, Daniel},
	urldate = {2024-05-27},
	date = {2022-07-26},
	langid = {english},
}

@misc{gardner_gpytorch_2021,
	title = {{GPyTorch}: Blackbox Matrix-Matrix Gaussian Process Inference with {GPU} Acceleration},
	url = {http://arxiv.org/abs/1809.11165},
	doi = {10.48550/arXiv.1809.11165},
	shorttitle = {{GPyTorch}},
	abstract = {Despite advances in scalable models, the inference tools used for Gaussian processes ({GPs}) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to {GP} inference based on Blackbox Matrix-Matrix multiplication ({BBMM}). {BBMM} inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. {BBMM} reduces the asymptotic complexity of exact {GP} inference from \$O(n{\textasciicircum}3)\$ to \$O(n{\textasciicircum}2)\$. Adapting this algorithm to scalable approximations and complex {GP} models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, {BBMM} uses a specialized preconditioner to substantially speed up convergence. In experiments we show that {BBMM} effectively uses {GPU} hardware to dramatically accelerate both exact {GP} inference and scalable approximations. Additionally, we provide {GPyTorch}, a software platform for scalable {GP} inference via {BBMM}, built on {PyTorch}.},
	number = {{arXiv}:1809.11165},
	publisher = {{arXiv}},
	author = {Gardner, Jacob R. and Pleiss, Geoff and Bindel, David and Weinberger, Kilian Q. and Wilson, Andrew Gordon},
	urldate = {2024-05-17},
	date = {2021-06-29},
	eprinttype = {arxiv},
	eprint = {1809.11165 [cs, stat]},
	keywords = {gaussian processes, machine learning, software},
}

@misc{oskarsson_graph-based_2023,
	title = {Graph-based Neural Weather Prediction for Limited Area Modeling},
	url = {http://arxiv.org/abs/2309.17370},
	doi = {10.48550/arXiv.2309.17370},
	abstract = {The rise of accurate machine learning methods for weather forecasting is creating radical new possibilities for modeling the atmosphere. In the time of climate change, having access to high-resolution forecasts from models like these is also becoming increasingly vital. While most existing Neural Weather Prediction ({NeurWP}) methods focus on global forecasting, an important question is how these techniques can be applied to limited area modeling. In this work we adapt the graph-based {NeurWP} approach to the limited area setting and propose a multi-scale hierarchical model extension. Our approach is validated by experiments with a local model for the Nordic region.},
	number = {{arXiv}:2309.17370},
	publisher = {{arXiv}},
	author = {Oskarsson, Joel and Landelius, Tomas and Lindsten, Fredrik},
	urldate = {2024-06-06},
	date = {2023-11-14},
	eprinttype = {arxiv},
	eprint = {2309.17370 [cs, stat]},
	keywords = {data-driven weather prediction},
}

@incollection{coiffier_half_2011,
	location = {Cambridge},
	title = {Half a century of numerical weather prediction},
	isbn = {978-1-107-00103-9},
	url = {https://www.cambridge.org/core/books/fundamentals-of-numerical-weather-prediction/half-a-century-of-numerical-weather-prediction/CD776FD50FAD1F67678DF89BB10303ED},
	abstract = {{IntroductionNumerical} weather prediction ({NWP}) is a very young discipline that developed essentially in the second half of the twentieth century with the continual benefit of advances in computing. The techniques implemented are used to solve equations describing the behaviour of the atmosphere, that is, to numerically compute future values of the atmosphere’s characteristic parameters from initial values that are known from meteorological observations.The equations used are the general equations of fluid mechanics that were already well established by the early twentieth century and to which certain simplifications are applied. Those simplifications are justified by the orders of magnitude of the various terms in the specific instance of the Earth’s atmosphere and by the scales to be described. Computers are essential for solving these systems of nonlinear equations, which, in the general case, cannot be solved analytically.},
	pages = {1--14},
	booktitle = {Fundamentals of Numerical Weather Prediction},
	publisher = {Cambridge University Press},
	editor = {Coiffier, Jean},
	urldate = {2024-05-25},
	date = {2011},
	doi = {10.1017/CBO9780511734458.005},
}

@article{zamo_improved_2016,
	title = {Improved Gridded Wind Speed Forecasts by Statistical Postprocessing of Numerical Models with Block Regression},
	volume = {31},
	issn = {0882-8156},
	url = {https://journals.ametsoc.org/waf/article/31/6/1929/40063/Improved-Gridded-Wind-Speed-Forecasts-by},
	doi = {10.1175/WAF-D-16-0052.1},
	pages = {1929--1945},
	number = {6},
	journaltitle = {Weather and Forecasting},
	shortjournal = {Wea. Forecasting},
	author = {Zamo, Michaël and Bel, Liliane and Mestre, Olivier and Stein, Joël},
	urldate = {2020-08-04},
	date = {2016-12-01},
	langid = {english},
	keywords = {gridded, interpolation, regression, wind},
}

@article{roberts_improver_2023,
	title = {{IMPROVER}: the new probabilistic post processing system at the {UK} Met Office},
	volume = {-1},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/aop/BAMS-D-21-0273.1/BAMS-D-21-0273.1.xml},
	doi = {10.1175/BAMS-D-21-0273.1},
	shorttitle = {{IMPROVER}},
	abstract = {Abstract The Met Office in the {UK} has developed a completely new probabilistic post-processing system called {IMPROVER} to operate on outputs from its operational Numerical Weather Prediction ({NWP}) forecasts and precipitation nowcasts. The aim is to improve weather forecast information to the public and other stakeholders whilst better exploiting the current and future generations of underpinning kilometer-scale {NWP} ensembles. We wish to provide seamless forecasts from nowcasting to medium range, provide consistency between gridded and site-specific forecasts and be able to verify every stage of the processing. The software is written in a modern modular framework that is easy to maintain, develop and share. {IMPROVER} allows forecast information to be provided with greater spatial and temporal detail and a faster update frequency than previous post-processing. Independent probabilistic processing chains are constructed for each meteorological variable consisting of a series of processing stages that operate on pre-defined grids and blend outputs from several {NWP} inputs to give a frequently updated, probabilistic forecast solution. Probabilistic information is produced as standard, with the option of extracting a most likely or yes/no outcome if required. Verification can be performed at all stages, although it is only currently switched on for the most significant stages when run in real time. {IMPROVER} has been producing real-time output since March 2021 and became operational in Spring 2022.},
	issue = {aop},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Roberts, Nigel and Ayliffe, Benjamin and Evans, Gavin and Moseley, Stephen and Rust, Fiona and Sandford, Caroline and Trzeciak, Tomasz and Abernethy, Paul and Beard, Laurence and Crosswaite, Neil and Fitzpatrick, Ben and Flowerdew, Jonathan and Gale, Tom and Holly, Leigh and Hopkinson, Aaron and Hurst, Katharine and Jackson, Simon and Jones, Caroline and Mylne, Ken and Sampson, Christopher and Sharpe, Michael and Wright, Bruce and Backhouse, Simon and Baker, Mark and Brierley, Daniel and Booton, Anna and Bysouth, Clare and Coulson, Robert and Coultas, Sean and Crocker, Ric and Harbord, Roger and Howard, Kathryn and Hughes, Teressa and Mittermaier, Marion and Petch, Jon and Pillinger, Tim and Smart, Victoria and Smith, Eleanor and Worsfold, Mark},
	urldate = {2023-02-02},
	date = {2023-01},
	keywords = {operational, post-processing, software},
}

@article{chapman_improving_2019,
	title = {Improving Atmospheric River Forecasts With Machine Learning},
	volume = {46},
	issn = {0094-8276, 1944-8007},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2019GL083662},
	doi = {10.1029/2019GL083662},
	abstract = {Abstract 
            This study tests the utility of convolutional neural networks as a postprocessing framework for improving the National Center for Environmental Prediction's Global Forecast System's integrated vapor transport forecast field in the Eastern Pacific and western United States. Integrated vapor transport is the characteristic field of atmospheric rivers, which provide over 65\% of yearly precipitation at some western U.S. locations. The method reduces full‐field root‐mean‐square error ({RMSE}) at forecast leads from 3 hr to seven days (9–17\% reduction), while increasing correlation between observations and predictions (0.5–12\% increase). This represents an approximately one‐ to two‐day lead time improvement in {RMSE}. Decomposing {RMSE} shows that random error and conditional biases are predominantly reduced. Systematic error is reduced up to five‐day forecast lead, but accounts for a smaller portion of {RMSE}. This work demonstrates convolutional neural networks potential to improve forecast skill out to seven days for precipitation events affecting the western United States. 
          ,  
            Plain Language Summary 
            Machine learning methods are data‐driven algorithms that improve by examining massive amounts of existing data. We explore the utility of a computer‐vision machine learning technique to reduce error in numerical weather forecasts of the characteristic field for atmospheric rivers ({ARs}). {ARs} are long narrow corridors of anomalous vapor transport capable of providing both beneficial and hazardous precipitation. Therefore, accurately forecasting {AR} events is extremely important from a water supply and flood protection standpoint. We show significant forecast improvements by applying machine learning postprocessing for lead times ranging from 3 hr to seven days, making the predictions more valuable to stakeholders affected by {AR} events. 
          ,  
            Key Points 
             
               
                 
                  The {GFS} forecast field of integrated vapor transport is used for a convolutional neural network‐based forecast postprocessing method 
                 
                 
                  The machine learning algorithm reduces the full‐field root‐mean‐square error and improves the correlation with ground truth 
                 
                 
                  An error deconstruction shows that the dominant improvements come from the reduction of random error and conditional biases},
	pages = {10627--10635},
	number = {17},
	journaltitle = {Geophysical Research Letters},
	shortjournal = {Geophysical Research Letters},
	author = {Chapman, W. E. and Subramanian, A. C. and Delle Monache, L. and Xie, S. P. and Ralph, F. M.},
	urldate = {2024-06-25},
	date = {2019-09},
	langid = {english},
	keywords = {convolutional neural network, post-processing},
}

@article{weyn_improving_2020,
	title = {Improving Data‐Driven Global Weather Prediction Using Deep Convolutional Neural Networks on a Cubed Sphere},
	volume = {12},
	issn = {1942-2466, 1942-2466},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020MS002109},
	doi = {10.1029/2020MS002109},
	abstract = {Abstract 
            We present a significantly improved data‐driven global weather forecasting framework using a deep convolutional neural network ({CNN}) to forecast several basic atmospheric variables on a global grid. New developments in this framework include an off‐line volume‐conservative mapping to a cubed‐sphere grid, improvements to the {CNN} architecture and the minimization of the loss function over multiple steps in a prediction sequence. The cubed‐sphere remapping minimizes the distortion on the cube faces on which convolution operations are performed and provides natural boundary conditions for padding in the {CNN}. Our improved model produces weather forecasts that are indefinitely stable and produce realistic weather patterns at lead times of several weeks and longer. For short‐ to medium‐range forecasting, our model significantly outperforms persistence, climatology, and a coarse‐resolution dynamical numerical weather prediction ({NWP}) model. Unsurprisingly, our forecasts are worse than those from a high‐resolution state‐of‐the‐art operational {NWP} system. Our data‐driven model is able to learn to forecast complex surface temperature patterns from few input atmospheric state variables. On annual time scales, our model produces a realistic seasonal cycle driven solely by the prescribed variation in top‐of‐atmosphere solar forcing. Although it currently does not compete with operational weather forecasting models, our data‐driven {CNN} executes much faster than those models, suggesting that machine learning could prove to be a valuable tool for large‐ensemble forecasting. 
          ,  
            Plain Language Summary 
            Recent work has begun to explore building global weather prediction models using only machine learning techniques trained on large amounts of atmospheric data. We develop a vastly improved machine learning algorithm capable of operating like traditional weather models and predicting several fundamental atmospheric variables, including near‐surface temperature. While our model does not yet compete with the state‐of‐the‐art in numerical weather prediction, it computes realistic forecasts that perform well and execute extremely quickly, offering a potential avenue for future developments in probabilistic weather forecasting. 
          ,  
            Key Points 
             
               
                 
                  A convolutional neural net ({CNN}) is developed for global weather forecasts on the cubed sphere 
                 
                 
                  Our {CNN} produces skillful global forecasts of key atmospheric variables at lead times up to 7 days 
                 
                 
                  Our {CNN} computes stable 1‐year simulations of realistic atmospheric states in 3 seconds},
	pages = {e2020MS002109},
	number = {9},
	journaltitle = {Journal of Advances in Modeling Earth Systems},
	shortjournal = {J Adv Model Earth Syst},
	author = {Weyn, Jonathan A. and Durran, Dale R. and Caruana, Rich},
	urldate = {2024-06-06},
	date = {2020-09},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@article{badrinath_improving_2023,
	title = {Improving Precipitation Forecasts with Convolutional Neural Networks},
	volume = {38},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/38/2/WAF-D-22-0002.1.xml},
	doi = {10.1175/WAF-D-22-0002.1},
	abstract = {Abstract A machine learning method based on spatial convolution to capture complex spatial precipitation patterns is proposed to identify and reduce biases affecting predictions of a dynamical model. The method is based on a combination of a classification and dual-regression model approach using modified U-Net convolutional neural networks ({CNN}) to postprocess daily accumulated precipitation over the U.S. West Coast. In this study, we leverage 34 years of high-resolution deterministic Western Weather Research and Forecasting (West-{WRF}) precipitation reforecasts as training data for the U-Net {CNN}. The data are split such that the test set contains 4 water years of data that encompass characteristic West Coast precipitation regimes: El Niño, La Niña, and dry and wet El Niño–Southern Oscillation ({ENSO} neutral) water years. On the unseen 4-yr dataset, the trained {CNN} yields a 12.9\%–15.9\% reduction in root-mean-square error ({RMSE}) and 2.7\%–3.4\% improvement in Pearson correlation ({PC}) over West-{WRF} for lead times of 1–4 days. Compared to an adapted model output statistics correction, the {CNN} reduces {RMSE} by 7.4\%–8.9\% and improves {PC} by 3.3\%–4.2\% across all events. Effectively, the {CNN} adds more than a day of predictive skill when compared to West-{WRF}. The {CNN} outperforms the other methods also for the prediction of extreme events, which we define as the top 10\% of events with the greatest average daily accumulated precipitation. The improvement over West-{WRF}’s {RMSE} ({PC}) for these events is 19.8\%–21.0\% (4.9\%–5.5\%) and {MOS}’s {RMSE} ({PC}) is 8.8\%–9.7\% (4.2\%–4.7\%). Hence, the proposed U-Net {CNN} shows significantly improved forecast skill over existing methods, highlighting a promising path forward for improving precipitation forecasts. Significance Statement Extreme precipitation events and atmospheric rivers, which contain narrow bands of water vapor transport, can cause millions of dollars in damages. We demonstrate the utility of a computer vision-based machine learning technique for improving precipitation forecasts. We show that there is a significant increase in predictive accuracy for daily accumulated precipitation using these machine learning methods, over a 4-yr period of unseen cases, including those corresponding to the extreme precipitation associated with atmospheric rivers.},
	pages = {291--306},
	number = {2},
	journaltitle = {Weather and Forecasting},
	author = {Badrinath, Anirudhan and Monache, Luca Delle and Hayatbini, Negin and Chapman, Will and Cannon, Forest and Ralph, Marty},
	urldate = {2024-05-22},
	date = {2023-02-10},
	keywords = {precipitation},
}

@article{rust_improving_2023,
	title = {Improving the blend of multiple weather forecast sources by Reliability Calibration},
	volume = {30},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.2142},
	doi = {10.1002/met.2142},
	abstract = {Abstract 
            Creating a forecast that is seamless across time yet is optimal at each forecast validity time is often achieved by blending forecasts from multiple Numerical Weather Prediction models (or using other forecast sources, such as an extrapolation nowcast). With the increasing usage of convection‐permitting ensemble models at shorter lead times, the blending of these forecasts with longer‐range ensemble models with parameterized convection can lead to a clear transition from one forecast source to another. This is particularly noticeable when visualizing the evolution of the gridded forecast. Calibrating the forecast sources with a common truth prior to blending provides a method of improving forecast skill whilst also unifying the characteristics of the forecasts to create a smoother blend throughout the evolution of the forecast. In this work, a non‐parametric method for calibrating the reliability of the forecast without degrading the forecast resolution is assessed for its usability for gridded precipitation rate and total cloud amount forecasts. Reliability is markedly improved resulting in a similar skill between forecast sources during the blending period. Further refinements to the technique removed artefacts in the gridded forecasts. Caveats, including a reduction in sharpness following calibration, are also presented.},
	pages = {e2142},
	number = {4},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Rust, Fiona M. and Evans, Gavin R. and Ayliffe, Benjamin A.},
	urldate = {2024-05-22},
	date = {2023-07},
	langid = {english},
}

@article{silini_improving_2022,
	title = {Improving the prediction of the Madden–Julian Oscillation of the {ECMWF} model by post-processing},
	volume = {13},
	issn = {2190-4979},
	url = {https://esd.copernicus.org/articles/13/1157/2022/},
	doi = {10.5194/esd-13-1157-2022},
	abstract = {The Madden–Julian Oscillation ({MJO}) is a major source of predictability on the sub-seasonal (10 to 90 d) timescale. An improved forecast of the {MJO} may have important socioeconomic impacts due to the influence of {MJO} on both tropical and extratropical weather extremes. Although in the last decades state-of-the-art climate models have proved their capability for forecasting the {MJO} exceeding the 5-week prediction skill, there is still room for improving the prediction. In this study we use multiple linear regression ({MLR}) and a machine learning ({ML}) algorithm as post-processing methods to improve the forecast of the model that currently holds the best {MJO} forecasting performance, the European Centre for Medium-Range Weather Forecasts ({ECMWF}) model. We find that both {MLR} and {ML} improve the {MJO} prediction and that {ML} outperforms {MLR}. The largest improvement is in the prediction of the {MJO} geographical location and intensity.},
	pages = {1157--1165},
	number = {3},
	journaltitle = {Earth System Dynamics},
	author = {Silini, Riccardo and Lerch, Sebastian and Mastrantonas, Nikolaos and Kantz, Holger and Barreiro, Marcelo and Masoller, Cristina},
	urldate = {2024-05-22},
	date = {2022-08-23},
}

@article{brocker_increasing_2007,
	title = {Increasing the Reliability of Reliability Diagrams},
	volume = {22},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/22/3/waf993_1.xml},
	doi = {10.1175/WAF993.1},
	abstract = {Abstract The reliability diagram is a common diagnostic graph used to summarize and evaluate probabilistic forecasts. Its strengths lie in the ease with which it is produced and the transparency of its definition. While visually appealing, major long-noted shortcomings lie in the difficulty of interpreting the graph visually; for the most part, ambiguities arise from variations in the distributions of forecast probabilities and from various binning procedures. A resampling method for assigning consistency bars to the observed frequencies is introduced that allows for immediate visual evaluation as to just how likely the observed relative frequencies are under the assumption that the predicted probabilities are reliable. Further, an alternative presentation of the same information on probability paper eases quantitative evaluation and comparison. Both presentations can easily be employed for any method of binning.},
	pages = {651--661},
	number = {3},
	journaltitle = {Weather and Forecasting},
	author = {Bröcker, Jochen and Smith, Leonard A.},
	urldate = {2024-06-25},
	date = {2007-06-01},
	keywords = {verification},
}

@article{willard_integrating_2022,
	title = {Integrating Scientific Knowledge with Machine Learning for Engineering and Environmental Systems},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3514228},
	doi = {10.1145/3514228},
	abstract = {There is a growing consensus that solutions to complex science and engineering problems require novel methodologies that are able to integrate traditional physics-based modeling approaches with state-of-the-art machine learning ({ML}) techniques. This paper provides a structured overview of such techniques. Application-centric objective areas for which these approaches have been applied are summarized, and then classes of methodologies used to construct physics-guided {ML} models and hybrid physics-{ML} frameworks are described. We then provide a taxonomy of these existing techniques, which uncovers knowledge gaps and potential crossovers of methods between disciplines that can serve as ideas for future research.},
	pages = {3514228},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Willard, Jared and Jia, Xiaowei and Xu, Shaoming and Steinbach, Michael and Kumar, Vipin},
	urldate = {2022-10-13},
	date = {2022-03-25},
	langid = {english},
}

@misc{willard_integrating_2022-1,
	title = {Integrating Scientific Knowledge with Machine Learning for Engineering and Environmental Systems},
	url = {http://arxiv.org/abs/2003.04919},
	doi = {10.48550/arXiv.2003.04919},
	abstract = {There is a growing consensus that solutions to complex science and engineering problems require novel methodologies that are able to integrate traditional physics-based modeling approaches with state-of-the-art machine learning ({ML}) techniques. This paper provides a structured overview of such techniques. Application-centric objective areas for which these approaches have been applied are summarized, and then classes of methodologies used to construct physics-guided {ML} models and hybrid physics-{ML} frameworks are described. We then provide a taxonomy of these existing techniques, which uncovers knowledge gaps and potential crossovers of methods between disciplines that can serve as ideas for future research.},
	number = {{arXiv}:2003.04919},
	publisher = {{arXiv}},
	author = {Willard, Jared and Jia, Xiaowei and Xu, Shaoming and Steinbach, Michael and Kumar, Vipin},
	urldate = {2024-07-13},
	date = {2022-03-13},
	eprinttype = {arxiv},
	eprint = {2003.04919 [physics, stat]},
}

@article{hamill_interpretation_2001,
	title = {Interpretation of Rank Histograms for Verifying Ensemble Forecasts},
	volume = {129},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/129/3/1520-0493_2001_129_0550_iorhfv_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2001)129<0550:IORHFV>2.0.CO;2},
	abstract = {Abstract Rank histograms are a tool for evaluating ensemble forecasts. They are useful for determining the reliability of ensemble forecasts and for diagnosing errors in its mean and spread. Rank histograms are generated by repeatedly tallying the rank of the verification (usually an observation) relative to values from an ensemble sorted from lowest to highest. However, an uncritical use of the rank histogram can lead to misinterpretations of the qualities of that ensemble. For example, a flat rank histogram, usually taken as a sign of reliability, can still be generated from unreliable ensembles. Similarly, a U-shaped rank histogram, commonly understood as indicating a lack of variability in the ensemble, can also be a sign of conditional bias. It is also shown that flat rank histograms can be generated for some model variables if the variance of the ensemble is correctly specified, yet if covariances between model grid points are improperly specified, rank histograms for combinations of model variables may not be flat. Further, if imperfect observations are used for verification, the observational errors should be accounted for, otherwise the shape of the rank histogram may mislead the user about the characteristics of the ensemble. If a statistical hypothesis test is to be performed to determine whether the differences from uniformity of rank are statistically significant, then samples used to populate the rank histogram must be located far enough away from each other in time and space to be considered independent.},
	pages = {550--560},
	number = {3},
	journaltitle = {Monthly Weather Review},
	author = {Hamill, Thomas M.},
	urldate = {2024-06-07},
	date = {2001-03-01},
	keywords = {verification},
}

@book{alpaydin_introduction_2020,
	location = {Cambridge, Massachusetts},
	edition = {Fourth edition},
	title = {Introduction to machine learning},
	isbn = {9780262043793},
	series = {Adaptive computation and machine learning series},
	abstract = {"Since the third edition of this text appeared in 2014, most recent advances in machine learning, both in theory and application, are related to neural networks and deep learning. In this new edition, the author has extended the discussion of multilayer perceptrons. He has also added a new chapter on deep learning including training deep neural networks, regularizing them so they learn better, structuring them to improve learning, e.g., through convolutional layers, and their recurrent extensions with short-term memory necessary for learning sequences. There is a new section on generative adversarial networks that have found an impressive array of applications in recent years. Alpaydin has also extended the chapter on reinforcement learning to discuss the use of deep networks in reinforcement learning. There is a new section on the policy gradient method that has been used frequently in recent years with neural networks, and two additional sections on two examples of deep reinforcement learning, which both made headlines when they were announced in 2015 and 2016 respectively. One is a network that learns to play arcade video games, and the other one learns to play Go. There are also revisions in other chapters reflecting new approaches, such as embedding methods for dimensionality reduction, and multi-label classification. In response to requests from instructors, this new edition contains two new appendices on linear algebra and optimization, to remind the reader of the basics of those topics that find use in machine learning"--},
	pagetotal = {682},
	publisher = {The {MIT} Press},
	author = {Alpaydin, Ethem},
	date = {2020},
	keywords = {Machine learning},
}

@software{bradbury_jax_2018,
	title = {{JAX}: composable transformations of Python+{NumPy} programs},
	url = {http://github.com/google/jax},
	version = {0.3.13},
	author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and {VanderPlas}, Jake and Wanderman-Milne, Skye and Zhang, Qiao},
	date = {2018},
	keywords = {software},
}

@thesis{foresti_kernel-based_2011,
	title = {Kernel-based mapping of meteorological fields in complex orography},
	institution = {Université de Lausanne},
	type = {phdthesis},
	author = {Foresti, Loris},
	date = {2011},
}

@article{schraff_kilometrescale_2016,
	title = {Kilometre‐scale ensemble data assimilation for the {COSMO} model ({KENDA})},
	volume = {142},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.2748},
	doi = {10.1002/qj.2748},
	abstract = {An ensemble Kalman filter for convective‐scale data assimilation ({KENDA}) has been developed for the {COnsortium} for Small‐scale {MOdelling} ({COSMO}) model. The {KENDA} system comprises a local ensemble transform Kalman filter ({LETKF}) and a deterministic analysis based on the Kalman gain for the analysis ensemble mean. The {KENDA} software suite includes tools for adaptive localization, multiplicative covariance inflation, relaxation to prior perturbations and adaptive observation errors. In the version introduced here, conventional data (radiosonde, aircraft, wind profiler, surface station data) are assimilated. Latent heat nudging of radar precipitation has also been added to the {KENDA} system to be applied to the deterministic analysis only or additionally to all ensemble members. The performance of different system components is investigated in a quasi‐operational setting using a basic cycling environment ({BACY}) for a period of six days with 24 h forecasts. For this period and an additional 28 day period, deterministic {KENDA} forecasts are compared with forecasts based on the observation nudging data assimilation scheme, which is currently operational at the German Weather Service (Deutscher Wetterdienst, {DWD}). For our experiments, lateral boundary conditions for the regional model are given by a global ensemble Kalman filter for the {ICOsahedral} Nonhydrostatic ({ICON}) model. The performance of the {KENDA} system proves overall to be superior to the forecast quality of the operational nudging scheme, in particular with regard to precipitation. Latent heat nudging improves precipitation forecasts in both systems and has slightly more benefit in combination with the {LETKF} than with observation nudging.},
	pages = {1453--1472},
	number = {696},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Schraff, C. and Reich, H. and Rhodin, A. and Schomburg, A. and Stephan, K. and Periáñez, A. and Potthast, R.},
	urldate = {2024-05-27},
	date = {2016-04},
	langid = {english},
}

@misc{leinonen_latent_2023,
	title = {Latent diffusion models for generative precipitation nowcasting with accurate uncertainty quantification},
	url = {http://arxiv.org/abs/2304.12891},
	doi = {10.48550/arXiv.2304.12891},
	abstract = {Diffusion models have been widely adopted in image generation, producing higher-quality and more diverse samples than generative adversarial networks ({GANs}). We introduce a latent diffusion model ({LDM}) for precipitation nowcasting - short-term forecasting based on the latest observational data. The {LDM} is more stable and requires less computation to train than {GANs}, albeit with more computationally expensive generation. We benchmark it against the {GAN}-based Deep Generative Models of Rainfall ({DGMR}) and a statistical model, {PySTEPS}. The {LDM} produces more accurate precipitation predictions, while the comparisons are more mixed when predicting whether the precipitation exceeds predefined thresholds. The clearest advantage of the {LDM} is that it generates more diverse predictions than {DGMR} or {PySTEPS}. Rank distribution tests indicate that the distribution of samples from the {LDM} accurately reflects the uncertainty of the predictions. Thus, {LDMs} are promising for any applications where uncertainty quantification is important, such as weather and climate.},
	number = {{arXiv}:2304.12891},
	publisher = {{arXiv}},
	author = {Leinonen, Jussi and Hamann, Ulrich and Nerini, Daniele and Germann, Urs and Franch, Gabriele},
	urldate = {2024-07-21},
	date = {2023-04-25},
	eprinttype = {arxiv},
	eprint = {2304.12891 [physics]},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, I.2.10, J.2, Physics - Atmospheric and Oceanic Physics},
}

@article{wessel_leadtimecontinuous_2024,
	title = {Lead‐time‐continuous statistical postprocessing of ensemble weather forecasts},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4701},
	doi = {10.1002/qj.4701},
	abstract = {Abstract 
             
              Numerical weather prediction ({NWP}) ensembles often exhibit biases and errors in dispersion, so they need some form of postprocessing to yield sharp and well‐calibrated probabilistic predictions. The output of {NWP} models is usually at a multiplicity of different lead times and, even though information is often required on this range of lead times, many postprocessing methods in the literature are applied either at a fixed lead time or by fitting individual models for each lead time. However, this is (1) computationally expensive because it requires the training of multiple models if users are interested in information at multiple lead times and (2) prohibitive because it restricts the data used for training postprocessing models and the usability of fitted models. This article investigates the lead‐time dependence of postprocessing methods in the idealized Lorenz'96 system as well as temperature and wind‐speed forecast data from the Met Office Global and Regional Ensemble Prediction System ({MOGREPS}‐G). The results indicate that there is substantial regularity between the models fitted for different lead times and that one can fit models that are 
              lead‐time‐continuous 
              that work for multiple lead times simultaneously by including lead time as a covariate. These models achieve similar and, in small data situations, even improved performance compared with the classical 
              lead‐time‐separated 
              models, whilst saving substantial computation time.},
	pages = {qj.4701},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Wessel, Jakob Benjamin and Ferro, Christopher A. T. and Kwasniok, Frank},
	urldate = {2024-05-22},
	date = {2024-04},
	langid = {english},
}

@article{lam_learning_2023,
	title = {Learning skillful medium-range global weather forecasting},
	volume = {382},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.adi2336},
	doi = {10.1126/science.adi2336},
	abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce {GraphCast}, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. {GraphCast} significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. {GraphCast} is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. 
          ,  
            Editor’s summary 
             
              The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam 
              et al 
              . introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90\% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith 
             
          ,  
            Machine learning leads to better, faster, and cheaper weather forecasting.},
	pages = {1416--1421},
	number = {6677},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Vinyals, Oriol and Stott, Jacklynn and Pritzel, Alexander and Mohamed, Shakir and Battaglia, Peter},
	urldate = {2024-05-29},
	date = {2023-12-22},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@misc{pacchiardi_likelihood-free_2022,
	title = {Likelihood-Free Inference with Generative Neural Networks via Scoring Rule Minimization},
	url = {http://arxiv.org/abs/2205.15784},
	doi = {10.48550/arXiv.2205.15784},
	abstract = {Bayesian Likelihood-Free Inference methods yield posterior approximations for simulator models with intractable likelihood. Recently, many works trained neural networks to approximate either the intractable likelihood or the posterior directly. Most proposals use normalizing flows, namely neural networks parametrizing invertible maps used to transform samples from an underlying base measure; the probability density of the transformed samples is then accessible and the normalizing flow can be trained via maximum likelihood on simulated parameter-observation pairs. A recent work [Ramesh et al., 2022] approximated instead the posterior with generative networks, which drop the invertibility requirement and are thus a more flexible class of distributions scaling to high-dimensional and structured data. However, generative networks only allow sampling from the parametrized distribution; for this reason, Ramesh et al. [2022] follows the common solution of adversarial training, where the generative network plays a min-max game against a "critic" network. This procedure is unstable and can lead to a learned distribution underestimating the uncertainty - in extreme cases collapsing to a single point. Here, we propose to approximate the posterior with generative networks trained by Scoring Rule minimization, an overlooked adversarial-free method enabling smooth training and better uncertainty quantification. In simulation studies, the Scoring Rule approach yields better performances with shorter training time with respect to the adversarial framework.},
	number = {{arXiv}:2205.15784},
	publisher = {{arXiv}},
	author = {Pacchiardi, Lorenzo and Dutta, Ritabrata},
	urldate = {2024-05-31},
	date = {2022-05-31},
	eprinttype = {arxiv},
	eprint = {2205.15784 [cs, stat]},
	keywords = {generative, multivariate prediction, neural networks, scoring rules},
}

@article{casaioli_linear_2003,
	title = {Linear and nonlinear post-processing of numerically forecasted surface temperature},
	volume = {10},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/10/373/2003/},
	doi = {10.5194/npg-10-373-2003},
	abstract = {In this paper we test different approaches to the statistical post-processing of gridded numerical surface air temperatures (provided by the European Centre for Medium-Range Weather Forecasts) onto the temperature measured at surface weather stations located in the Italian region of Puglia. We consider simple post-processing techniques, like correction for altitude, linear regression from different input parameters and Kalman filtering, as well as a neural network training procedure, stabilised (i.e. driven into the absolute minimum of the error function over the learning set) by means of a Simulated Annealing method. A comparative analysis of the results shows that the performance with neural networks is the best. It is encouraging for systematic use in meteorological forecast-analysis service operations.},
	pages = {373--383},
	number = {4},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Casaioli, M. and Mantovani, R. and Proietti Scorzoni, F. and Puca, S. and Speranza, A. and Tirozzi, B.},
	urldate = {2024-07-12},
	date = {2003-10-31},
	keywords = {post-processing},
}

@article{waclawczyk_local_2024,
	title = {Local Similarity Theory as the Invariant Solution of the Governing Equations},
	volume = {190},
	issn = {1573-1472},
	url = {https://doi.org/10.1007/s10546-024-00867-9},
	doi = {10.1007/s10546-024-00867-9},
	abstract = {The present paper shows that local similarity theories, proposed for the strongly-stratified boundary layers, can be derived as invariant solutions defined under the Lie-group theory. A system truncated to the mean momentum and buoyancy equations is considered for this purpose. The study further suggests how similarity functions for the mean profiles are determined from the vertical fluxes, with a potential dependence on a measure of the anisotropy of the system. A time scale that is likely to characterize the transiency of a system is also identified as a non-dimensionalization factor.},
	pages = {23},
	number = {5},
	journaltitle = {Boundary-Layer Meteorology},
	shortjournal = {Boundary-Layer Meteorol},
	author = {Wacławczyk, Marta and Yano, Jun-Ichi and Florczyk, Grzegorz M.},
	urldate = {2024-07-22},
	date = {2024-04-30},
	langid = {english},
	keywords = {Invariants, Lie symmetries, Local similarity theory, Stably-stratified turbulence},
}

@book{mitchell_machine_1997,
	location = {New York},
	title = {Machine Learning},
	isbn = {9780070428072},
	series = {{McGraw}-Hill series in computer science},
	pagetotal = {414},
	publisher = {{McGraw}-Hill},
	author = {Mitchell, Tom M.},
	date = {1997},
}

@article{stachura_machine_2024,
	title = {Machine learning based post‐processing of model‐derived near‐surface air temperature – A multimodel approach},
	volume = {150},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4613},
	doi = {10.1002/qj.4613},
	abstract = {Abstract 
            In this article, a machine‐learning‐based tool for calibrating numerical forecasts of near‐surface air temperature is proposed. The study area covers Poland representing a temperate type of climate with transitional features and highly variable weather. The direct output of numerical weather prediction ({NWP}) models is often biased and needs to be adjusted to observed values. Forecasters have to reconcile forecasts from several {NWP} models during their operational work. As the proposed method is based on deterministic forecasts from three short‐range limited‐area models ({ALARO}, {AROME} and {COSMO}), it can support them in their decision‐making process. Predictors include forecasts of weather elements produced by the {NWP} models at synoptic weather stations across Poland and station‐embedded data on ambient orography. The Random Forests algorithm ({RF}) has been used to produce bias‐corrected forecasts on a test set spanning one year. Its performance was evaluated against the {NWP} models, a linear combination of all predictors (multiple linear regression, {MLR}) as well as a basic Artificial Neural Network ({ANN}). Detailed evaluation was done to identify potential strengths and weaknesses of the model at the temporal and spatial scale. The value of {RMSE} of a forecast obtained by the {RF} model was 11\% and 27\% lower compared to the {MLR} model and the best‐performing {NWP} model respectively. The {ANN} model turned out to be even superior, outperforming {RF} by around 2.5\%. The greatest improvement occurred for warm bias during the nighttime from July to September. The largest difference in forecast accuracy between {RF} and {ANN} appeared for temperature drops {inApril} nights. Poor performance of {RF} for extreme temperature ranges may be suppressed by training the model on forecast error instead of observed values of the variable.},
	pages = {618--631},
	number = {759},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Stachura, Gabriel and Ustrnul, Zbigniew and Sekuła, Piotr and Bochenek, Bogdan and Kolonko, Marcin and Szczęch‐Gajewska, Małgorzata},
	urldate = {2024-05-22},
	date = {2024-01},
	langid = {english},
}

@article{stachura_machine_2024-1,
	title = {Machine learning based post‐processing of model‐derived near‐surface air temperature – A multimodel approach},
	volume = {150},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4613},
	doi = {10.1002/qj.4613},
	abstract = {Abstract 
            In this article, a machine‐learning‐based tool for calibrating numerical forecasts of near‐surface air temperature is proposed. The study area covers Poland representing a temperate type of climate with transitional features and highly variable weather. The direct output of numerical weather prediction ({NWP}) models is often biased and needs to be adjusted to observed values. Forecasters have to reconcile forecasts from several {NWP} models during their operational work. As the proposed method is based on deterministic forecasts from three short‐range limited‐area models ({ALARO}, {AROME} and {COSMO}), it can support them in their decision‐making process. Predictors include forecasts of weather elements produced by the {NWP} models at synoptic weather stations across Poland and station‐embedded data on ambient orography. The Random Forests algorithm ({RF}) has been used to produce bias‐corrected forecasts on a test set spanning one year. Its performance was evaluated against the {NWP} models, a linear combination of all predictors (multiple linear regression, {MLR}) as well as a basic Artificial Neural Network ({ANN}). Detailed evaluation was done to identify potential strengths and weaknesses of the model at the temporal and spatial scale. The value of {RMSE} of a forecast obtained by the {RF} model was 11\% and 27\% lower compared to the {MLR} model and the best‐performing {NWP} model respectively. The {ANN} model turned out to be even superior, outperforming {RF} by around 2.5\%. The greatest improvement occurred for warm bias during the nighttime from July to September. The largest difference in forecast accuracy between {RF} and {ANN} appeared for temperature drops {inApril} nights. Poor performance of {RF} for extreme temperature ranges may be suppressed by training the model on forecast error instead of observed values of the variable.},
	pages = {618--631},
	number = {759},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Stachura, Gabriel and Ustrnul, Zbigniew and Sekuła, Piotr and Bochenek, Bogdan and Kolonko, Marcin and Szczęch‐Gajewska, Małgorzata},
	urldate = {2024-07-24},
	date = {2024-01},
	langid = {english},
	keywords = {post-processing, temperature},
}

@article{schulz_machine_2021,
	title = {Machine learning methods for postprocessing ensemble forecasts of wind gusts: A systematic comparison},
	volume = {-1},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/aop/MWR-D-21-0150.1/MWR-D-21-0150.1.xml},
	doi = {10.1175/MWR-D-21-0150.1},
	shorttitle = {Machine learning methods for postprocessing ensemble forecasts of wind gusts},
	abstract = {{\textbackslash}textlesssection class="abstract"{\textbackslash}textgreater{\textbackslash}textlessh2 class="{abstractTitle} text-title my-1" id="d168975566e69"{\textbackslash}{textgreaterAbstract}{\textbackslash}textless/h2{\textbackslash}textgreater{\textbackslash}textlessp{\textbackslash}{textgreaterPostprocessing} ensemble weather predictions to correct systematic errors has become a standard practice in research and operations. However, only few recent studies have focused on ensemble postprocessing of wind gust forecasts, despite its importance for severe weather warnings. Here, we provide a comprehensive review and systematic comparison of eight statistical and machine learning methods for probabilistic wind gust forecasting via ensemble postprocessing, that can be divided in three groups: State of the art postprocessing techniques from statistics (ensemble model output statistics ({EMOS}), member-by-member postprocessing, isotonic distributional regression), established machine learning methods (gradient-boosting extended {EMOS}, quantile regression forests) and neural network-based approaches (distributional regression network, Bernstein quantile network, histogram estimation network). The methods are systematically compared using six years of data from a high-resolution, convection-permitting ensemble prediction system that was run operationally at the German weather service, and hourly observations at 175 surface weather stations in Germany. While all postprocessing methods yield calibrated forecasts and are able to correct the systematic errors of the raw ensemble predictions, incorporating information from additional meteorological predictor variables beyond wind gusts leads to significant improvements in forecast skill. In particular, we propose a flexible framework of locally adaptive neural networks with different probabilistic forecast types as output, which not only significantly outperform all benchmark postprocessing methods but also learn physically consistent relations associated with the diurnal cycle, especially the evening transition of the planetary boundary layer.{\textbackslash}textless/p{\textbackslash}textgreater{\textbackslash}textless/section{\textbackslash}textgreater},
	issue = {aop},
	journaltitle = {Monthly Weather Review},
	author = {Schulz, Benedikt and Lerch, Sebastian},
	urldate = {2021-10-30},
	date = {2021-10},
}

@article{schulz_machine_2022,
	title = {Machine Learning Methods for Postprocessing Ensemble Forecasts of Wind Gusts: A Systematic Comparison},
	volume = {150},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/150/1/MWR-D-21-0150.1.xml},
	doi = {10.1175/MWR-D-21-0150.1},
	shorttitle = {Machine Learning Methods for Postprocessing Ensemble Forecasts of Wind Gusts},
	abstract = {Abstract Postprocessing ensemble weather predictions to correct systematic errors has become a standard practice in research and operations. However, only a few recent studies have focused on ensemble postprocessing of wind gust forecasts, despite its importance for severe weather warnings. Here, we provide a comprehensive review and systematic comparison of eight statistical and machine learning methods for probabilistic wind gust forecasting via ensemble postprocessing that can be divided in three groups: state-of-the-art postprocessing techniques from statistics [ensemble model output statistics ({EMOS}), member-by-member postprocessing, isotonic distributional regression], established machine learning methods (gradient-boosting extended {EMOS}, quantile regression forests), and neural network–based approaches (distributional regression network, Bernstein quantile network, histogram estimation network). The methods are systematically compared using 6 years of data from a high-resolution, convection-permitting ensemble prediction system that was run operationally at the German weather service, and hourly observations at 175 surface weather stations in Germany. While all postprocessing methods yield calibrated forecasts and are able to correct the systematic errors of the raw ensemble predictions, incorporating information from additional meteorological predictor variables beyond wind gusts leads to significant improvements in forecast skill. In particular, we propose a flexible framework of locally adaptive neural networks with different probabilistic forecast types as output, which not only significantly outperform all benchmark postprocessing methods but also learn physically consistent relations associated with the diurnal cycle, especially the evening transition of the planetary boundary layer.},
	pages = {235--257},
	number = {1},
	journaltitle = {Monthly Weather Review},
	author = {Schulz, Benedikt and Lerch, Sebastian},
	urldate = {2024-07-13},
	date = {2022-02-02},
	keywords = {post-processing, wind},
}

@article{ling_machine_2016,
	title = {Machine learning strategies for systems with invariance properties},
	volume = {318},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999116301309},
	doi = {10.1016/j.jcp.2016.05.003},
	abstract = {In many scientific fields, empirical models are employed to facilitate computational simulations of engineering systems. For example, in fluid mechanics, empirical Reynolds stress closures enable computationally-efficient Reynolds Averaged Navier Stokes simulations. Likewise, in solid mechanics, constitutive relations between the stress and strain in a material are required in deformation analysis. Traditional methods for developing and tuning empirical models usually combine physical intuition with simple regression techniques on limited data sets. The rise of high performance computing has led to a growing availability of high fidelity simulation data. These data open up the possibility of using machine learning algorithms, such as random forests or neural networks, to develop more accurate and general empirical models. A key question when using data-driven algorithms to develop these empirical models is how domain knowledge should be incorporated into the machine learning process. This paper will specifically address physical systems that possess symmetry or invariance properties. Two different methods for teaching a machine learning model an invariance property are compared. In the first method, a basis of invariant inputs is constructed, and the machine learning model is trained upon this basis, thereby embedding the invariance into the model. In the second method, the algorithm is trained on multiple transformations of the raw input data until the model learns invariance to that transformation. Results are discussed for two case studies: one in turbulence modeling and one in crystal elasticity. It is shown that in both cases embedding the invariance property into the input features yields higher performance at significantly reduced computational training costs.},
	pages = {22--35},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Ling, Julia and Jones, Reese and Templeton, Jeremy},
	urldate = {2024-07-22},
	date = {2016-08-01},
	keywords = {Constitutive models, Machine learning, Tensor invariants, Turbulence models},
}

@article{hamill_measuring_2006,
	title = {Measuring forecast skill: is it real skill or is it the varying climatology?},
	volume = {132},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1256/qj.06.25},
	doi = {10.1256/qj.06.25},
	shorttitle = {Measuring forecast skill},
	abstract = {Abstract 
            It is common practice to summarize the skill of weather forecasts from an accumulation of samples spanning many locations and dates. In calculating many of these scores, there is an implicit assumption that the climatological frequency of event occurrence is approximately invariant over all samples. If the event frequency actually varies among the samples, the metrics may report a skill that is different from that expected. Many common deterministic verification metrics, such as threat scores, are prone to mis‐reporting skill, and probabilistic forecast metrics such as the Brier skill score and relative operating characteristic skill score can also be affected. 
            Three examples are provided that demonstrate unexpected skill, two from synthetic data and one with actual forecast data. In the first example, positive skill was reported in a situation where metrics were calculated from a composite of forecasts that were comprised of random draws from the climatology of two distinct locations. As the difference in climatological event frequency between the two locations was increased, the reported skill also increased. A second example demonstrates that when the climatological event frequency varies among samples, the metrics may excessively weight samples with the greatest observational uncertainty. A final example demonstrates unexpectedly large skill in the equitable threat score of deterministic precipitation forecasts. 
            Guidelines are suggested for how to adjust skill computations to minimize these effects. Copyright © 2006 Royal Meteorological Society},
	pages = {2905--2923},
	number = {621},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Hamill, Thomas M. and Juras, Josip},
	urldate = {2024-06-17},
	date = {2006-10},
	langid = {english},
	keywords = {verification},
}

@article{mott_meteorological_2010,
	title = {Meteorological Modeling of Very High-Resolution Wind Fields and Snow Deposition for Mountains},
	volume = {11},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/11/4/2010jhm1216_1.xml},
	doi = {10.1175/2010JHM1216.1},
	abstract = {Abstract The inhomogeneous snow distribution found in alpine terrain is the result of wind and precipitation interacting with the snow surface. During major snowfall events, preferential deposition of snow and transport of previously deposited snow often takes place simultaneously. Both processes, however, are driven by the local wind field, which is influenced by the local topography. In this study, the meteorological model Advanced Regional Prediction System ({ARPS}) was used to compute mean flow fields of 50-m, 25-m-, 10-m-, and 5-m grid spacing to investigate snow deposition patterns resulting from two snowfall events on a mountain ridge in the Swiss Alps. Only the initial adaptation of the flow field to the topography is calculated with artificial boundary conditions. The flow fields then drive the snow deposition and transport module of Alpine3D, a model of mountain surface processes. The authors compare the simulations with partly new measurements of snow deposition on the Gaudergrat ridge. On the basis of these four grid resolutions, it was possible to investigate the effects of numerical resolution in the calculation of wind fields and in the calculation of the associated snow deposition. The most realistic wind field and deposition patterns were obtained with the highest resolution of 5 m. These high-resolution simulations confirm the earlier hypothesis that preferential deposition is active at the ridge scale and true redistribution—mainly via saltation—forms smaller-scale deposition patterns, such as dunes and cornices.},
	pages = {934--949},
	number = {4},
	journaltitle = {Journal of Hydrometeorology},
	author = {Mott, Rebecca and Lehning, Michael},
	urldate = {2024-05-27},
	date = {2010-08-01},
	keywords = {complex terrain, wind},
}

@article{baran_mixture_2016,
	title = {Mixture {EMOS} model for calibrating ensemble forecasts of wind speed},
	volume = {27},
	issn = {1180-4009, 1099-095X},
	url = {http://arxiv.org/abs/1507.06517},
	doi = {10.1002/env.2380},
	abstract = {Ensemble model output statistics ({EMOS}) is a statistical tool for post-processing forecast ensembles of weather variables obtained from multiple runs of numerical weather prediction models in order to produce calibrated predictive probability density functions ({PDFs}). The {EMOS} predictive {PDF} is given by a parametric distribution with parameters depending on the ensemble forecasts. We propose an {EMOS} model for calibrating wind speed forecasts based on weighted mixtures of truncated normal ({TN}) and log-normal ({LN}) distributions where model parameters and component weights are estimated by optimizing the values of proper scoring rules over a rolling training period. The new model is tested on wind speed forecasts of the 50 member European Centre for Medium-Range Weather Forecasts ensemble, the 11 member Aire Limit{\textbackslash}'ee Adaptation dynamique D{\textbackslash}'eveloppement International-Hungary Ensemble Prediction System ensemble of the Hungarian Meteorological Service and the eight-member University of Washington mesoscale ensemble, and its predictive performance is compared to that of various benchmark {EMOS} models based on single parametric families and combinations thereof. The results indicate improved calibration of probabilistic and accuracy of point forecasts in comparison with the raw ensemble and climatological forecasts. The mixture {EMOS} model significantly outperforms the {TN} and {LN} {EMOS} methods, moreover, it provides better calibrated forecasts than the {TN}-{LN} combination model and offers an increased flexibility while avoiding covariate selection problems.},
	pages = {116--130},
	number = {2},
	journaltitle = {Environmetrics},
	shortjournal = {Environmetrics},
	author = {Baran, Sándor and Lerch, Sebastian},
	urldate = {2020-12-21},
	date = {2016-03},
	eprinttype = {arxiv},
	eprint = {1507.06517},
	keywords = {ensemble prediction, post-processing, wind},
}

@article{lemcke_model_1988,
	title = {Model Output Statistics Forecasts: Three Years of Operational Experience in the Netherlands},
	volume = {116},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/116/5/1520-0493_1988_116_1077_mosfty_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1988)116<1077:MOSFTY>2.0.CO;2},
	shorttitle = {Model Output Statistics Forecasts},
	abstract = {Abstract In the Netherlands, one to five day Model Output Statistics ({MOS}) forecasts have been used operationally since November 1983. The weather elements predicted are the probability of precipitation, the conditional probability of frozen precipitation, the probability of thunderstorms, the sunshine, maximum and minimum temperature and the maximum wind speed. For the development of the guidance system, two year of {ECMWF} data (December 1980–November 1982) were used, while a third year was available as a test period. The period December 1983–November 1986 has been used for verification. Operational forecasters have used the {MOS} forecast for the preparation of their final forecasts. The results of the {MOS} forecasts and of subjective forecasts are presented and intercompared in this paper. From this comparison it appears that the forecasters have higher skill scores only for Days 1 and 2; for Days 3, 4 and 5 the differences are, in general, small.},
	pages = {1077--1090},
	number = {5},
	journaltitle = {Monthly Weather Review},
	author = {Lemcke, C. and Kruizinga, S.},
	urldate = {2024-05-22},
	date = {1988-05-01},
}

@misc{kendall_multi-task_2018,
	title = {Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},
	url = {http://arxiv.org/abs/1705.07115},
	doi = {10.48550/arXiv.1705.07115},
	abstract = {Numerous deep learning applications benefit from multi-task learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task's loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.},
	number = {{arXiv}:1705.07115},
	publisher = {{arXiv}},
	author = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
	urldate = {2024-07-13},
	date = {2018-04-24},
	eprinttype = {arxiv},
	eprint = {1705.07115 [cs]},
}

@misc{crawshaw_multi-task_2020,
	title = {Multi-Task Learning with Deep Neural Networks: A Survey},
	url = {http://arxiv.org/abs/2009.09796},
	doi = {10.48550/arXiv.2009.09796},
	shorttitle = {Multi-Task Learning with Deep Neural Networks},
	abstract = {Multi-task learning ({MTL}) is a subfield of machine learning in which multiple tasks are simultaneously learned by a shared model. Such approaches offer advantages like improved data efficiency, reduced overfitting through shared representations, and fast learning by leveraging auxiliary information. However, the simultaneous learning of multiple tasks presents new design and optimization challenges, and choosing which tasks should be learned jointly is in itself a non-trivial problem. In this survey, we give an overview of multi-task learning methods for deep neural networks, with the aim of summarizing both the well-established and most recent directions within the field. Our discussion is structured according to a partition of the existing deep {MTL} techniques into three groups: architectures, optimization methods, and task relationship learning. We also provide a summary of common multi-task benchmarks.},
	number = {{arXiv}:2009.09796},
	publisher = {{arXiv}},
	author = {Crawshaw, Michael},
	urldate = {2024-07-13},
	date = {2020-09-10},
	eprinttype = {arxiv},
	eprint = {2009.09796 [cs, stat]},
}

@article{wilks_multivariate_2015,
	title = {Multivariate ensemble Model Output Statistics using empirical copulas},
	volume = {141},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.2414},
	doi = {10.1002/qj.2414},
	abstract = {Statistical post‐processing of ensemble forecasts usually is carried out independently for individual, scalar predictands. However, in some applications multivariate joint forecast distributions, which capture both the univariate marginal distributions of their constituent scalar predictands as well as the dependence structure among them, may be required. Copulas are functions that link multivariate distribution functions to their constituent univariate marginal distributions. Empirical copulas are non‐parametric copula functions that are easy to implement. This article compares recently proposed variants of empirical copula coupling ({ECC}‐Q and {ECC}‐R), which take their dependence structures from raw forecast ensembles, and the Schaake shuffle, which is based on unconditional random samples from the historical climatology, in a four‐dimensional multivariate ensemble post‐processing setting. These alternatives were compared for probability forecasts of multi‐day ‘heat waves’, based on the 11‐member National Oceanic and Atmospheric Administration ({NOAA}) reforecast ensembles. Best forecast accuracy was achieved using the unconditional climatological dependence structures sampled by the Schaake shuffle, implying that any forecast improvements due to flow‐specific dependencies that might be captured by the ensemble‐based copulas are not sufficient to overcome errors in the ensemble's representation of those dependencies.},
	pages = {945--952},
	number = {688},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Wilks, Daniel S.},
	urldate = {2024-05-16},
	date = {2015-04},
	langid = {english},
}

@article{crippen_nasadem_2016,
	title = {{NASADEM} {GLOBAL} {ELEVATION} {MODEL}: {METHODS} {AND} {PROGRESS}},
	volume = {{XLI}-B4},
	issn = {1682-1750},
	url = {https://isprs-archives.copernicus.org/articles/XLI-B4/125/2016/},
	doi = {10.5194/isprs-archives-XLI-B4-125-2016},
	shorttitle = {{NASADEM} {GLOBAL} {ELEVATION} {MODEL}},
	abstract = {{NASADEM} is a near-global elevation model that is being produced primarily by completely reprocessing the Shuttle Radar Topography Mission ({SRTM}) radar data and then merging it with refined {ASTER} {GDEM} elevations. The new and improved {SRTM} elevations in {NASADEM} result from better vertical control of each {SRTM} data swath via reference to {ICESat} elevations and from {SRTM} void reductions using advanced interferometric unwrapping algorithms. Remnant voids will be filled primarily by {GDEM}3, but with reduction of {GDEM} glitches (mostly related to clouds) and therefore with only minor need for secondary sources of fill.},
	pages = {125--128},
	journaltitle = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	author = {Crippen, R. and Buckley, S. and Agram, P. and Belz, E. and Gurrola, E. and Hensley, S. and Kobrick, M. and Lavalle, M. and Martin, J. and Neumann, M. and Nguyen, Q. and Rosen, P. and Shimada, J. and Simard, M. and Tung, W.},
	urldate = {2024-07-26},
	date = {2016-06-13},
	keywords = {{ASTER}, {DEM}, Elevation, {GDEM}, {ICESat}, {NASADEM}, {SRTM}, Topography},
}

@misc{mirowski_neural_2024,
	title = {Neural Compression of Atmospheric States},
	url = {http://arxiv.org/abs/2407.11666},
	doi = {10.48550/arXiv.2407.11666},
	abstract = {Atmospheric states derived from reanalysis comprise a substantial portion of weather and climate simulation outputs. Many stakeholders -- such as researchers, policy makers, and insurers -- use this data to better understand the earth system and guide policy decisions. Atmospheric states have also received increased interest as machine learning approaches to weather prediction have shown promising results. A key issue for all audiences is that dense time series of these high-dimensional states comprise an enormous amount of data, precluding all but the most well resourced groups from accessing and using historical data and future projections. To address this problem, we propose a method for compressing atmospheric states using methods from the neural network literature, adapting spherical data to processing by conventional neural architectures through the use of the area-preserving {HEALPix} projection. We investigate two model classes for building neural compressors: the hyperprior model from the neural image compression literature and recent vector-quantised models. We show that both families of models satisfy the desiderata of small average error, a small number of high-error reconstructed pixels, faithful reproduction of extreme events such as hurricanes and heatwaves, preservation of the spectral power distribution across spatial scales. We demonstrate compression ratios in excess of 1000x, with compression and decompression at a rate of approximately one second per global atmospheric state.},
	number = {{arXiv}:2407.11666},
	publisher = {{arXiv}},
	author = {Mirowski, Piotr and Warde-Farley, David and Rosca, Mihaela and Grimes, Matthew Koichi and Hasson, Yana and Kim, Hyunjik and Rey, Mélanie and Osindero, Simon and Ravuri, Suman and Mohamed, Shakir},
	urldate = {2024-07-24},
	date = {2024-07-17},
	eprinttype = {arxiv},
	eprint = {2407.11666 [physics]},
}

@misc{gomes_neural_2024,
	title = {Neural Embedding Compression For Efficient Multi-Task Earth Observation Modelling},
	url = {http://arxiv.org/abs/2403.17886},
	doi = {10.48550/arXiv.2403.17886},
	abstract = {As repositories of large scale data in earth observation ({EO}) have grown, so have transfer and storage costs for model training and inference, expending significant resources. We introduce Neural Embedding Compression ({NEC}), based on the transfer of compressed embeddings to data consumers instead of raw data. We adapt foundation models ({FM}) through learned neural compression to generate multi-task embeddings while navigating the tradeoff between compression rate and embedding utility. We update only a small fraction of the {FM} parameters (10\%) for a short training period (1\% of the iterations of pre-training). We evaluate {NEC} on two {EO} tasks: scene classification and semantic segmentation. Compared with applying traditional compression to the raw data, {NEC} achieves similar accuracy with a 75\% to 90\% reduction in data. Even at 99.7\% compression, performance drops by only 5\% on the scene classification task. Overall, {NEC} is a data-efficient yet performant approach for multi-task {EO} modelling.},
	number = {{arXiv}:2403.17886},
	publisher = {{arXiv}},
	author = {Gomes, Carlos and Brunschwiler, Thomas},
	urldate = {2024-07-24},
	date = {2024-07-09},
	eprinttype = {arxiv},
	eprint = {2403.17886 [cs]},
	note = {version: 2},
}

@misc{kochkov_neural_2024,
	title = {Neural General Circulation Models for Weather and Climate},
	url = {http://arxiv.org/abs/2311.07222},
	doi = {10.48550/arXiv.2311.07222},
	abstract = {General circulation models ({GCMs}) are the foundation of weather and climate prediction. {GCMs} are physics-based simulators which combine a numerical solver for large-scale dynamics with tuned representations for small-scale processes such as cloud formation. Recently, machine learning ({ML}) models trained on reanalysis data achieved comparable or better skill than {GCMs} for deterministic weather forecasting. However, these models have not demonstrated improved ensemble forecasts, or shown sufficient stability for long-term weather and climate simulations. Here we present the first {GCM} that combines a differentiable solver for atmospheric dynamics with {ML} components, and show that it can generate forecasts of deterministic weather, ensemble weather and climate on par with the best {ML} and physics-based methods. {NeuralGCM} is competitive with {ML} models for 1-10 day forecasts, and with the European Centre for Medium-Range Weather Forecasts ensemble prediction for 1-15 day forecasts. With prescribed sea surface temperature, {NeuralGCM} can accurately track climate metrics such as global mean temperature for multiple decades, and climate forecasts with 140 km resolution exhibit emergent phenomena such as realistic frequency and trajectories of tropical cyclones. For both weather and climate, our approach offers orders of magnitude computational savings over conventional {GCMs}. Our results show that end-to-end deep learning is compatible with tasks performed by conventional {GCMs}, and can enhance the large-scale physical simulations that are essential for understanding and predicting the Earth system.},
	number = {{arXiv}:2311.07222},
	publisher = {{arXiv}},
	author = {Kochkov, Dmitrii and Yuval, Janni and Langmore, Ian and Norgaard, Peter and Smith, Jamie and Mooers, Griffin and Klöwer, Milan and Lottes, James and Rasp, Stephan and Düben, Peter and Hatfield, Sam and Battaglia, Peter and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Brenner, Michael P. and Hoyer, Stephan},
	urldate = {2024-05-29},
	date = {2024-03-07},
	eprinttype = {arxiv},
	eprint = {2311.07222 [physics]},
	keywords = {deterministic prediction, ensemble prediction, hybrid weather prediction},
}

@article{rasp_neural_2018,
	title = {Neural Networks for Postprocessing Ensemble Weather Forecasts},
	volume = {146},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/146/11/mwr-d-18-0187.1.xml},
	doi = {10.1175/MWR-D-18-0187.1},
	abstract = {Abstract Ensemble weather predictions require statistical postprocessing of systematic errors to obtain reliable and accurate probabilistic forecasts. Traditionally, this is accomplished with distributional regression models in which the parameters of a predictive distribution are estimated from a training period. We propose a flexible alternative based on neural networks that can incorporate nonlinear relationships between arbitrary predictor variables and forecast distribution parameters that are automatically learned in a data-driven way rather than requiring prespecified link functions. In a case study of 2-m temperature forecasts at surface stations in Germany, the neural network approach significantly outperforms benchmark postprocessing methods while being computationally more affordable. Key components to this improvement are the use of auxiliary predictor variables and station-specific information with the help of embeddings. Furthermore, the trained neural network can be used to gain insight into the importance of meteorological variables, thereby challenging the notion of neural networks as uninterpretable black boxes. Our approach can easily be extended to other statistical postprocessing and forecasting problems. We anticipate that recent advances in deep learning combined with the ever-increasing amounts of model and observation data will transform the postprocessing of numerical weather forecasts in the coming decade.},
	pages = {3885--3900},
	number = {11},
	journaltitle = {Monthly Weather Review},
	author = {Rasp, Stephan and Lerch, Sebastian},
	urldate = {2023-10-31},
	date = {2018-11},
	keywords = {post-processing, temperature},
}

@article{marzban_neural_2003,
	title = {Neural Networks for Postprocessing Model Output: {ARPS}},
	volume = {131},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/131/6/1520-0493_2003_131_1103_nnfpmo_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2003)131<1103:NNFPMO>2.0.CO;2},
	shorttitle = {Neural Networks for Postprocessing Model Output},
	abstract = {Abstract The temperature forecasts of the Advanced Regional Prediction System are postprocessed by a neural network. Specifically, 31 stations are considered, and for each a neural network is developed. The nine input variables to the neural network are forecast hour, model forecast temperature, relative humidity, wind direction and speed, mean sea level pressure, cloud cover, and precipitation rate and amount. The single dependent variable is observed temperature at a given station. It is shown that the model temperature forecasts are improved in terms of a variety of performance measures. An average of 40\% reduction in mean-squared error across all stations is accompanied by an average reduction in bias and variance of 70\% and 20\%, respectively.},
	pages = {1103--1111},
	number = {6},
	journaltitle = {Monthly Weather Review},
	author = {Marzban, Caren},
	urldate = {2024-05-22},
	date = {2003-06-01},
}

@article{song_non-crossing_2024,
	title = {Non-crossing Quantile Regression Neural Network as a Calibration Tool for Ensemble Weather Forecasts},
	issn = {1861-9533},
	url = {https://doi.org/10.1007/s00376-023-3184-5},
	doi = {10.1007/s00376-023-3184-5},
	abstract = {Despite the maturity of ensemble numerical weather prediction ({NWP}), the resulting forecasts are still, more often than not, under-dispersed. As such, forecast calibration tools have become popular. Among those tools, quantile regression ({QR}) is highly competitive in terms of both flexibility and predictive performance. Nevertheless, a long-standing problem of {QR} is quantile crossing, which greatly limits the interpretability of {QR}-calibrated forecasts. On this point, this study proposes a non-crossing quantile regression neural network ({NCQRNN}), for calibrating ensemble {NWP} forecasts into a set of reliable quantile forecasts without crossing. The overarching design principle of {NCQRNN} is to add on top of the conventional {QRNN} structure another hidden layer, which imposes a non-decreasing mapping between the combined output from nodes of the last hidden layer to the nodes of the output layer, through a triangular weight matrix with positive entries. The empirical part of the work considers a solar irradiance case study, in which four years of ensemble irradiance forecasts at seven locations, issued by the European Centre for Medium-Range Weather Forecasts, are calibrated via {NCQRNN}, as well as via an eclectic mix of benchmarking models, ranging from the naïve climatology to the state-of-the-art deep-learning and other non-crossing models. Formal and stringent forecast verification suggests that the forecasts post-processed via {NCQRNN} attain the maximum sharpness subject to calibration, amongst all competitors. Furthermore, the proposed conception to resolve quantile crossing is remarkably simple yet general, and thus has broad applicability as it can be integrated with many shallow- and deep-learning-based neural networks.},
	journaltitle = {Advances in Atmospheric Sciences},
	shortjournal = {Adv. Atmos. Sci.},
	author = {Song, Mengmeng and Yang, Dazhi and Lerch, Sebastian and Xia, Xiang’ao and Yagli, Gokhan Mert and Bright, Jamie M. and Shen, Yanbo and Liu, Bai and Liu, Xingli and Mayer, Martin János},
	urldate = {2024-05-22},
	date = {2024-03-01},
	langid = {english},
	keywords = {post-processing},
}

@article{chkeir_nowcasting_2023,
	title = {Nowcasting extreme rain and extreme wind speed with machine learning techniques applied to different input datasets},
	volume = {282},
	issn = {0169-8095},
	url = {https://www.sciencedirect.com/science/article/pii/S0169809522005348},
	doi = {10.1016/j.atmosres.2022.106548},
	abstract = {Predicting extreme weather events in a short time period and their developing in localized areas is a challenge. The nowcasting of severe and extreme weather events is an issue for air traffic management and control because it affects aviation safety, and determines delays and diversions. This work is part of a larger study devoted to nowcasting rain and wind speed in the area of Malpensa airport by merging different datasets. We use as reference the weather station of Novara to develop a nowcasting machine learning model which could be reusable in other locations. In this location we have the availability of ground-based weather sensors, a Global Navigation Satellite System ({GNSS}) receiver, a C-band radar and lightning detectors. Our analysis shows that the Long Short-Term Memory Encoder Decoder ({LSTM} E/D) approach is well suited for the nowcasting of meteorological variables. The predictions are based on 4 different datasets configurations providing rain and wind speed nowcast for 1 h with a time step of 10 min. The results are very promising with the extreme wind speed probability of detection higher than 90\%, the false alarms lower than 2\%, and a good performance in extreme rain detection for the first 30 min. The configuration using just weather stations and {GNSS} data in input provides excellent performances and should be preferred to the other ones, since it refers to the pre-convective environment, and thus can be adaptable to any weather conditions.},
	pages = {106548},
	journaltitle = {Atmospheric Research},
	shortjournal = {Atmospheric Research},
	author = {Chkeir, Sandy and Anesiadou, Aikaterini and Mascitelli, Alessandra and Biondi, Riccardo},
	urldate = {2024-07-21},
	date = {2023-02-01},
	keywords = {nowcasting, precipitation, wind},
}

@incollection{colman_numerical_2013,
	location = {Dordrecht},
	title = {Numerical Weather Prediction and Weather Forecasting in Complex Terrain},
	isbn = {9789400740983},
	url = {https://doi.org/10.1007/978-94-007-4098-3_11},
	abstract = {Numerical weather prediction ({NWP}) is the foundation for modern day weather forecasting. The focus of this chapter is on what {NWP} brings to the table when forecasting in areas of complex terrain – where it succeeds, where it fails, and how the forecaster can best use the guidance it provides. The role of the forecaster is highlighted throughout, together with reflections on alternative methods and forecasting approaches that can be used to optimize forecast quality.--{\textgreater} This chapter describes the advancement of numerical weather prediction ({NWP}) models and the role of the mountain weather forecaster in the forecast process. The chapter begins with a historical perspective of the roles {NWP} and the forecaster have played. This ranges from the time when models could only resolve the largest terrain features, to the present where models have shed light on processes and helped forecasters better understand features over complex terrain and improve their conceptual models. The issue of atmospheric predictability is addressed along with the inherent challenges facing the mountain weather forecaster. In some cases complex terrain actually extends predictability while for others predictability limits are relatively short and skillful forecasts are limited to hours rather than days. For each case the forecasters need to be able to recognize the salient processes and understand the differences in predictability. They must also understand the strengths and weaknesses of {NWP} and communicate appropriately the uncertainty of the forecast. As forecast interests expand to specific locations over a larger domain – especially in complex terrain – post processing of mesoscale {NWP} has become even more important. This is discussed together with a number of methodologies for downscaling {NWP}. Commensurate with this trend in {NWP} is the need for detailed observations that match current forecast resolutions. This is followed by a discussion of forecast tools and the role of the forecaster with respect to {NWP}. It is argued that the optimal forecast approach today is a blend of subjective techniques and statistical post-processing of {NWP} solutions, combined with local forecasting tools and cognitive experience. Finally, the role of the mountain weather forecaster in field programs (e.g., the Winter Olympics) gives a glimpse into the future for what may become routine. These programs shed insight into predictability limits and provide an opportunity to evaluate new observing systems, tools and approaches. The chapter ends with a vision for the future for the research and operational communities. Further exploration into mesoscale ensemble prediction and objective analysis in complex terrain, among other areas, is needed so researchers can improve mountain weather forecasting. Meanwhile, forecasters need to be open to these new advances and recognize that while their role will continue to evolve, it will also continue to be of value to society.},
	pages = {655--692},
	booktitle = {Mountain Weather Research and Forecasting: Recent Progress and Current Challenges},
	publisher = {Springer Netherlands},
	author = {Colman, Brad and Cook, Kirby and Snyder, Bradley J.},
	editor = {Chow, Fotini K. and De Wekker, Stephan F.J. and Snyder, Bradley J.},
	urldate = {2024-07-25},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-94-007-4098-3_11},
}

@article{simon_nwp-based_2019,
	title = {{NWP}-based lightning prediction using flexible count data regression},
	volume = {5},
	issn = {2364-3579},
	url = {https://ascmo.copernicus.org/articles/5/1/2019/},
	doi = {10.5194/ascmo-5-1-2019},
	abstract = {A method to predict lightning by postprocessing numerical weather prediction ({NWP}) output is developed for the region of the European Eastern Alps. Cloud-to-ground ({CG}) flashes – detected by the ground-based Austrian Lightning Detection \&amp; Information System ({ALDIS}) network – are counted on the 18×18\&thinsp;km2 grid of the 51-member {NWP} ensemble of the European Centre for Medium-Range Weather Forecasts ({ECMWF}). These counts serve as the target quantity in count data regression models for the occurrence of lightning events and flash counts of {CG}. The probability of lightning occurrence is modelled by a Bernoulli distribution. The flash counts are modelled with a hurdle approach where the Bernoulli distribution is combined with a zero-truncated negative binomial. In the statistical models the parameters of the distributions are described by additive predictors, which are assembled using potentially nonlinear functions of {NWP} covariates. Measures of location and spread of 100 direct and derived {NWP} covariates provide a pool of candidates for the nonlinear terms. A combination of stability selection and gradient boosting identifies the nine (three) most influential terms for the parameters of the Bernoulli (zero-truncated negative binomial) distribution, most of which turn out to be associated with either convective available potential energy ({CAPE}) or convective precipitation. Markov chain Monte Carlo ({MCMC}) sampling estimates the final model to provide credible inference of effects, scores, and predictions. The selection of terms and {MCMC} sampling are applied for data of the year 2016, and out-of-sample performance is evaluated for 2017. The occurrence model outperforms a reference climatology – based on 7 years of data – up to a forecast horizon of 5 days. The flash count model is calibrated and also outperforms climatology for exceedance probabilities, quantiles, and full predictive distributions.},
	pages = {1--16},
	number = {1},
	journaltitle = {Advances in Statistical Climatology, Meteorology and Oceanography},
	author = {Simon, Thorsten and Mayr, Georg J. and Umlauf, Nikolaus and Zeileis, Achim},
	urldate = {2024-05-22},
	date = {2019-02-04},
}

@article{heinrich_number_2021,
	title = {On the number of bins in a rank histogram},
	volume = {147},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3932},
	doi = {10.1002/qj.3932},
	abstract = {Abstract 
            Rank histograms are popular tools for assessing the reliability of meteorological ensemble forecast systems. A reliable forecast system leads to a uniform rank histogram, and deviations from uniformity can indicate miscalibrations. However, the ability to identify such deviations by visual inspection of rank histogram plots crucially depends on the number of bins chosen for the histogram. If too few bins are chosen, the rank histogram is likely to miss miscalibrations; if too many are chosen, even perfectly calibrated forecast systems can yield rank histograms that do not appear uniform. In this paper we address this trade‐off and propose a method for choosing the number of bins for a rank histogram. The goal of our method is to select a number of bins such that the intuitive decision whether a histogram is uniform or not is as close as possible to a formal statistical test. Our results indicate that it is often appropriate to choose fewer bins than the usual choice of ensemble size plus one, especially when the number of observations available for verification is small.},
	pages = {544--556},
	number = {734},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Heinrich, Claudio},
	urldate = {2024-07-21},
	date = {2021-01},
	langid = {english},
	keywords = {verification},
}

@online{liniger_operational_2021,
	title = {Operational aspects of machine learning in a met-service},
	url = {https://meetingorganizer.copernicus.org/EMS2021/EMS2021-181.html},
	abstract = {\&lt;p\&gt;Machine Learning has a big potential for various tasks along the whole value chain of a national Met-Service. Indeed, many research groups, private and national weather services have started to explore the possibilities and first real-time operational implementations are in place already. However, the building up of the expertise is difficult, large amounts of data have to be made available in an efficient way and the necessary tools have special and demanding requirements concerning infrastructure and maintenance. Also, the transition from research results towards operational tools being operated in realtime is a particular challenge. Not least, trust from end-users must be built, while trying to avoid falling into the short-term hype trap.\&lt;/p\&gt;\&lt;p\&gt;In this presentation, we want to present some examples of machine-learning at {MeteoSwiss} that are in operational use or soon to be. This includes the use in a measurement system to identify pollen species, the quality control of meteorological observations, the postprocessing of numerical weather forecasts and the condensation of weather forecast information for the meteorologists. These examples have different characteristics and cover a wide range of applications, but also share some common properties. We want to juxtapose these properties with the incentives and conditions how machine learning methods are developed and employed in a more research oriented context like in academia. It turns out that an operational setup of machine learning has very different requirements than machine learning in a research context. The identification of these differences, but also the similarities, could help to understand the challenge of bringing research results into operation and how to alleviate this challenge in the future.\&lt;/p\&gt;},
	author = {Liniger, Mark A. and Cattani, Daniel and Crouzy, Benoit and Nerini, Daniele and Moret, Lionel and Sigg, Christian},
	urldate = {2024-07-15},
	date = {2021-06-18},
	doi = {10.5194/ems2021-181},
}

@report{nerini_operational_2023,
	title = {Operational machine learning for the postprocessing of surface wind forecasts},
	url = {https://meetingorganizer.copernicus.org/EGU23/EGU23-14973.html},
	number = {{EGU}23-14973},
	institution = {Copernicus Meetings},
	author = {Nerini, Daniele and Zanetta, Francesco and Schaer, Mathieu and Bhend, Jonas and Spirig, Christoph and Moret, Lionel and Liniger, Mark A.},
	urldate = {2024-07-15},
	date = {2023-02-22},
	langid = {english},
	doi = {10.5194/egusphere-egu23-14973},
}

@article{schuhen_order_2020,
	title = {Order of operation for multi-stage post-processing of ensemble wind forecast trajectories},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/35/2020/},
	doi = {10.5194/npg-27-35-2020},
	abstract = {With numerical weather prediction ensembles unable to produce sufficiently calibrated forecasts, statistical post-processing is needed to correct deterministic and probabilistic biases. Over the past decades, a number of methods addressing this issue have been proposed, with ensemble model output statistics ({EMOS}) and Bayesian model averaging ({BMA}) among the most popular. They are able to produce skillful deterministic and probabilistic forecasts for a wide range of applications. These methods are usually applied to the newest model run as soon as it has finished, before the entire forecast trajectory is issued. {RAFT} (rapid adjustment of forecast trajectories), a recently proposed novel approach, aims to improve these forecasts even further, utilizing the error correlation patterns between lead times. As soon as the first forecasts are verified, we start updating the remainder of the trajectory based on the newly gathered error information. As {RAFT} works particularly well in conjunction with other post-processing methods like {EMOS} and techniques designed to reconstruct the multivariate dependency structure like ensemble copula coupling ({ECC}), we look to identify the optimal combination of these methods. In our study, we apply multi-stage post-processing to wind speed forecasts from the {UK} Met Office's convective-scale {MOGREPS}-{UK} ensemble and analyze results for short-range forecasts at a number of sites in the {UK} and the Republic of Ireland.},
	pages = {35--49},
	number = {1},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Schuhen, Nina},
	urldate = {2024-05-22},
	date = {2020-02-06},
}

@article{lundquist_our_2019,
	title = {Our Skill in Modeling Mountain Rain and Snow is Bypassing the Skill of Our Observational Networks},
	volume = {100},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/100/12/bams-d-19-0001.1.xml},
	doi = {10.1175/BAMS-D-19-0001.1},
	abstract = {Abstract In mountain terrain, well-configured high-resolution atmospheric models are able to simulate total annual rain and snowfall better than spatial estimates derived from in situ observational networks of precipitation gauges, and significantly better than radar or satellite-derived estimates. This conclusion is primarily based on comparisons with streamflow and snow in basins across the western United States and in Iceland, Europe, and Asia. Even though they outperform gridded datasets based on gauge networks, atmospheric models still disagree with each other on annual average precipitation and often disagree more on their representation of individual storms. Research to address these difficulties must make use of a wide range of observations (snow, streamflow, ecology, radar, satellite) and bring together scientists from different disciplines and a wide range of communities.},
	pages = {2473--2490},
	number = {12},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Lundquist, Jessica and Hughes, Mimi and Gutmann, Ethan and Kapnick, Sarah},
	urldate = {2024-05-27},
	date = {2019-12-01},
	keywords = {precipitation},
}

@book{stensrud_parameterization_2007,
	edition = {1},
	title = {Parameterization Schemes: Keys to Understanding Numerical Weather Prediction Models},
	rights = {https://www.cambridge.org/core/terms},
	isbn = {9780521865401 9780521126762 9780511812590},
	url = {https://www.cambridge.org/core/product/identifier/9780511812590/type/book},
	shorttitle = {Parameterization Schemes},
	abstract = {Numerical weather prediction models play an increasingly important role in meteorology, both in short- and medium-range forecasting and global climate change studies. The most important components of any numerical weather prediction model are the subgrid-scale parameterization schemes, and the analysis and understanding of these schemes is a key aspect of numerical weather prediction. This book provides in-depth explorations of the most commonly used types of parameterization schemes that influence both short-range weather forecasts and global climate models. Several parameterizations are summarised and compared, followed by a discussion of their limitations. Review questions at the end of each chapter enable readers to monitor their understanding of the topics covered, and solutions are available to instructors at www.cambridge.org/9780521865401. This will be an essential reference for academic researchers, meteorologists, weather forecasters, and graduate students interested in numerical weather prediction and its use in weather forecasting.},
	publisher = {Cambridge University Press},
	author = {Stensrud, David J.},
	urldate = {2024-07-08},
	date = {2007-05-03},
	doi = {10.1017/CBO9780511812590},
}

@article{szabo_parametric_2023,
	title = {Parametric Postprocessing of Dual-Resolution Precipitation Forecasts},
	volume = {38},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/38/8/WAF-D-23-0003.1.xml},
	doi = {10.1175/WAF-D-23-0003.1},
	abstract = {Abstract All major weather centers issue ensemble forecasts, which differ both in ensemble size and spatial resolution, even while covering the same domain. These parameters directly determine both the forecast skill of the prediction and the computation cost. In the past few years, the plans for upgrading the configuration of the Integrated Forecast System of the European Centre for Medium-Range Weather Forecasts ({ECMWF}) from a single forecast with 9-km resolution and a 51-member ensemble with 18-km resolution induced an extensive study of the forecast skill of both raw and postprocessed dual-resolution predictions comprising ensemble members of different horizontal resolutions. We investigate the predictive performance of the censored shifted gamma ({CSG}) ensemble model output statistic ({EMOS}) approach for statistical postprocessing with the help of dual-resolution, 24-h, precipitation accumulation ensemble forecasts over Europe with various forecast horizons. We consider the operational 50-member {ECMWF} ensemble as of high resolution and extend it with a low-resolution (29-km grid), 200-member experimental forecast. The investigated dual-resolution combinations consist of subsets of these two forecast ensembles with equal computational cost, which is equivalent to the cost of the operational ensemble. Our case study verifies that, compared with the raw ensemble combinations, {EMOS} postprocessing results in a significant improvement in forecast skill and that skill is statistically indistinguishable between any of the analyzed mixtures of dual-resolution combinations. Furthermore, the semilocally trained {CSG} {EMOS} provides an efficient alternative to the state-of-the-art quantile mapping without requiring additional historical data.},
	pages = {1313--1322},
	number = {8},
	journaltitle = {Weather and Forecasting},
	author = {Szabó, Marianna and Gascón, Estíbaliz and Baran, Sándor},
	urldate = {2024-05-22},
	date = {2023-07-28},
}

@article{wilson_pathwise_2021,
	title = {Pathwise Conditioning of Gaussian Processes},
	volume = {22},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v22/20-1260.html},
	abstract = {As Gaussian processes are used to answer increasingly complex questions, analytic solutions become scarcer and scarcer. Monte Carlo methods act as a convenient bridge for connecting intractable mathematical expressions with actionable estimates via sampling. Conventional approaches for simulating Gaussian process posteriors view samples as draws from marginal distributions of process values at finite sets of input locations. This distribution-centric characterization leads to generative strategies that scale cubically in the size of the desired random vector. These methods are prohibitively expensive in cases where we would, ideally, like to draw high-dimensional vectors or even continuous sample paths. In this work, we investigate a different line of reasoning: rather than focusing on distributions, we articulate Gaussian conditionals at the level of random variables. We show how this pathwise interpretation of conditioning gives rise to a general family of approximations that lend themselves to efficiently sampling Gaussian process posteriors. Starting from first principles, we derive these methods and analyze the approximation errors they introduce. We, then, ground these results by exploring the practical implications of pathwise conditioning in various applied settings, such as global optimization and reinforcement learning.},
	pages = {1--47},
	number = {105},
	journaltitle = {Journal of Machine Learning Research},
	author = {Wilson, James T. and Borovitskiy, Viacheslav and Terenin, Alexander and Mostowsky, Peter and Deisenroth, Marc Peter},
	urldate = {2024-05-27},
	date = {2021},
}

@article{zanetta_physics-constrained_2023,
	title = {Physics-Constrained Deep Learning Postprocessing of Temperature and Humidity},
	volume = {2},
	issn = {2769-7525},
	url = {https://journals.ametsoc.org/view/journals/aies/2/4/AIES-D-22-0089.1.xml},
	doi = {10.1175/AIES-D-22-0089.1},
	abstract = {Abstract Weather forecasting centers currently rely on statistical postprocessing methods to minimize forecast error. This improves skill but can lead to predictions that violate physical principles or disregard dependencies between variables, which can be problematic for downstream applications and for the trustworthiness of postprocessing models, especially when they are based on new machine learning approaches. Building on recent advances in physics-informed machine learning, we propose to achieve physical consistency in deep learning–based postprocessing models by integrating meteorological expertise in the form of analytic equations. Applied to the postprocessing of surface weather in Switzerland, we find that constraining a neural network to enforce thermodynamic state equations yields physically consistent predictions of temperature and humidity without compromising performance. Our approach is especially advantageous when data are scarce, and our findings suggest that incorporating domain expertise into postprocessing models allows the optimization of weather forecast information while satisfying application-specific requirements. Significance Statement Postprocessing is a widely used approach to reduce forecast error using statistics, but it may lead to physical inconsistencies. This outcome can be problematic for trustworthiness and downstream applications. We present the first machine learning–based postprocessing method intentionally designed to strictly enforce physical laws. Our framework improves physical consistency without sacrificing performance and suggests that human expertise can be incorporated into postprocessing models via analytic equations.},
	number = {4},
	journaltitle = {Artificial Intelligence for the Earth Systems},
	author = {Zanetta, Francesco and Nerini, Daniele and Beucler, Tom and Liniger, Mark A.},
	urldate = {2024-05-27},
	date = {2023-12-19},
	keywords = {neural networks, post-processing},
}

@article{daw_physics-guided_2021,
	title = {Physics-guided Neural Networks ({PGNN}): An Application in Lake Temperature Modeling},
	url = {http://arxiv.org/abs/1710.11431},
	shorttitle = {Physics-guided Neural Networks ({PGNN})},
	abstract = {This paper introduces a framework for combining scientific knowledge of physics-based models with neural networks to advance scientific discovery. This framework, termed physics-guided neural networks ({PGNN}), leverages the output of physics-based model simulations along with observational features in a hybrid modeling setup to generate predictions using a neural network architecture. Further, this framework uses physics-based loss functions in the learning objective of neural networks to ensure that the model predictions not only show lower errors on the training set but are also scientifically consistent with the known physics on the unlabeled set. We illustrate the effectiveness of {PGNN} for the problem of lake temperature modeling, where physical relationships between the temperature, density, and depth of water are used to design a physics-based loss function. By using scientific knowledge to guide the construction and learning of neural networks, we are able to show that the proposed framework ensures better generalizability as well as scientific consistency of results. All the code and datasets used in this study have been made available on this link {\textbackslash}url\{https://github.com/arkadaw9/{PGNN}\}.},
	journaltitle = {{arXiv}:1710.11431 [physics, stat]},
	author = {Daw, Arka and Karpatne, Anuj and Watkins, William and Read, Jordan and Kumar, Vipin},
	urldate = {2021-11-01},
	date = {2021-09-28},
	eprinttype = {arxiv},
	eprint = {1710.11431},
}

@article{kashinath_physics-informed_2021,
	title = {Physics-informed machine learning: case studies for weather and climate modelling},
	volume = {379},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0093},
	doi = {10.1098/rsta.2020.0093},
	shorttitle = {Physics-informed machine learning},
	abstract = {Machine learning ({ML}) provides novel and powerful ways of accurately and efficiently recognizing complex patterns, emulating nonlinear dynamics, and predicting the spatio-temporal evolution of weather and climate processes. Off-the-shelf {ML} models, however, do not necessarily obey the fundamental governing laws of physical systems, nor do they generalize well to scenarios on which they have not been trained. We survey systematic approaches to incorporating physics and domain knowledge into {ML} models and distill these approaches into broad categories. Through 10 case studies, we show how these approaches have been used successfully for emulating, downscaling, and forecasting weather and climate processes. The accomplishments of these studies include greater physical consistency, reduced training time, improved data efficiency, and better generalization. Finally, we synthesize the lessons learned and identify scientific, diagnostic, computational, and resource challenges for developing truly robust and reliable physics-informed {ML} models for weather and climate processes.This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	pages = {20200093},
	number = {2194},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Kashinath, K. and Mustafa, M. and Albert, A. and Wu, J-L. and Jiang, C. and Esmaeilzadeh, S. and Azizzadenesheli, K. and Wang, R. and Chattopadhyay, A. and Singh, A. and Manepalli, A. and Chirila, D. and Yu, R. and Walters, R. and White, B. and Xiao, H. and Tchelepi, H. A. and Marcus, P. and Anandkumar, A. and Hassanzadeh, P. and Prabhat, null},
	urldate = {2021-10-20},
	date = {2021-04-05},
	keywords = {neural networks, physical constraints, physics-informed machine learning, turbulent flows, weather and climate modeling},
}

@article{benacek_postprocessing_2022,
	title = {Postprocessing of Ensemble Weather Forecast Using Decision Tree–Based Probabilistic Forecasting Methods},
	volume = {38},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/38/1/WAF-D-22-0006.1.xml},
	doi = {10.1175/WAF-D-22-0006.1},
	abstract = {Abstract Producing an accurate and calibrated probabilistic forecast has high social and economic value. Systematic errors or biases in the ensemble weather forecast can be corrected by postprocessing models whose development is an urgent challenge. Traditionally, the bias correction is done by employing linear regression models that estimate the conditional probability distribution of the forecast. Although this model framework works well, it is restricted to a prespecified model form that often relies on a limited set of predictors only. Most machine learning ({ML}) methods can tackle these problems with a point prediction, but only a few of them can be applied effectively in a probabilistic manner. The tree-based {ML} techniques, namely, natural gradient boosting ({NGB}), quantile random forests ({QRF}), and distributional regression forests ({DRF}), are used to adjust hourly 2-m temperature ensemble prediction at lead times of 1–10 days. The ensemble model output statistics ({EMOS}) and its boosting version are used as benchmark models. The model forecast is based on the European Centre for Medium-Range Weather Forecasts ({ECMWF}) for the Czech Republic domain. Two training periods 2015–18 and 2018 only were used to learn the models, and their prediction skill was evaluated in 2019. The results show that the {QRF} and {NGB} methods provide the best performance for 1–2-day forecasts, while the {EMOS} method outperforms other methods for 8–10-day forecasts. Key components to improving short-term forecasting are additional atmospheric/surface state predictors and the 4-yr training sample size. Significance Statement Machine learning methods have great potential and are beginning to be widely applied in meteorology in recent years. A new technique called natural gradient boosting ({NGB}) has been released and used in this paper to refine the probabilistic forecast of surface temperature. It was found that the {NGB} has better prediction skills than the traditional ensemble model output statistics in forecasting 1 and 2 days in advance. The {NGB} has similar prediction skills with lower computational demands compared to other advanced machine learning methods such as the quantile random forests. We showed a path to employ the {NGB} method in this task, which can be followed for refining other and more challenging meteorological variables such as wind speed or precipitation.},
	pages = {69--82},
	number = {1},
	journaltitle = {Weather and Forecasting},
	author = {Benáček, Patrik and Farda, Aleš and Štěpánek, Petr},
	urldate = {2024-05-22},
	date = {2022-12-29},
}

@article{hohlein_postprocessing_2024,
	title = {Postprocessing of Ensemble Weather Forecasts Using Permutation-Invariant Neural Networks},
	volume = {3},
	issn = {2769-7525},
	url = {https://journals.ametsoc.org/view/journals/aies/3/1/AIES-D-23-0070.1.xml},
	doi = {10.1175/AIES-D-23-0070.1},
	abstract = {Abstract Statistical postprocessing is used to translate ensembles of raw numerical weather forecasts into reliable probabilistic forecast distributions. In this study, we examine the use of permutation-invariant neural networks for this task. In contrast to previous approaches, which often operate on ensemble summary statistics and dismiss details of the ensemble distribution, we propose networks that treat forecast ensembles as a set of unordered member forecasts and learn link functions that are by design invariant to permutations of the member ordering. We evaluate the quality of the obtained forecast distributions in terms of calibration and sharpness and compare the models against classical and neural network–based benchmark methods. In case studies addressing the postprocessing of surface temperature and wind gust forecasts, we demonstrate state-of-the-art prediction quality. To deepen the understanding of the learned inference process, we further propose a permutation-based importance analysis for ensemble-valued predictors, which highlights specific aspects of the ensemble forecast that are considered important by the trained postprocessing models. Our results suggest that most of the relevant information is contained in a few ensemble-internal degrees of freedom, which may impact the design of future ensemble forecasting and postprocessing systems.},
	number = {1},
	journaltitle = {Artificial Intelligence for the Earth Systems},
	author = {Höhlein, Kevin and Schulz, Benedikt and Westermann, Rüdiger and Lerch, Sebastian},
	urldate = {2024-05-22},
	date = {2024-01-22},
	keywords = {neural networks, post-processing},
}

@article{wilks_potential_1995,
	title = {Potential Economic Value of Ensemble-Based Surface Weather Forecasts},
	volume = {123},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/123/12/1520-0493_1995_123_3565_pevoeb_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1995)123<3565:PEVOEB>2.0.CO;2},
	abstract = {Abstract The possible economic value of the quantification of uncertainty in future ensemble-based surface weather forecasts is investigated using a formal, idealized decision model. Current, or baseline, weather forecasts are represented by probabilistic forecasts of moderate accuracy, as measured by the ranked probability score. Hypothetical ensemble-based forecasts are constructed by supplementing the baseline set of probabilistic forecasts with lower- and higher-skill forecasts. These are chosen in such a way that mixtures of the forecasts including the lower- and higher-skill subsets with equal frequency exhibit the same accuracy overall as the moderately accurate (conventional, baseline) forecasts. For both simple one-time decisions (static situation) and related sequences of decisions (dynamic situation), these hypothetical ensemble-based forecasts are found to lead to greater economic value in the idealized decision problem when protective actions are relatively inexpensive, corresponding to real-world problems. However, for some decision problems considered, the ensemble-based forecasts are slightly less valuable than the baseline forecasts. This result derives at least in part from the (probably unrealistic) assumption that the ensemble-based forecasts are no more skillful in aggregate than their conventional counterparts, but implies that positive economic value for ensemble forecasts with respect to this baseline will not be automatic. Rather, for ensemble-based forecasts to be at least as valuable for all decision problems, they will need to exhibit sufficiently higher skill in aggregate than the conventional forecasts that could have been produced in their place},
	pages = {3565--3575},
	number = {12},
	journaltitle = {Monthly Weather Review},
	author = {Wilks, Daniel S. and Hamill, Thomas M.},
	urldate = {2024-03-29},
	date = {1995-12-01},
	keywords = {economic value, weather and climate services},
}

@article{krishnamurthy_predictability_2019,
	title = {Predictability of Weather and Climate},
	volume = {6},
	issn = {2333-5084, 2333-5084},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2019EA000586},
	doi = {10.1029/2019EA000586},
	abstract = {Abstract 
            The past developments in the predictability of weather and climate are discussed from the point of view of nonlinear dynamical systems. The problems ahead for long‐range predictability extending into the climate time scale are also presented. The sensitive dependence of chaos on initial conditions and the imperfections in the models limit reliable predictability of the instantaneous state of the weather to less than 10 days in present‐day operational forecasts. The existence of slowly varying components such as the sea surface temperature, soil moisture, snow cover, and sea ice may provide basis for predicting certain aspects of climate at long range. The regularly varying nonlinear oscillations, such as the Madden‐Julian Oscillation, monsoon intraseasonal oscillations, and El Niño‐Southern Oscillation, are also possible sources of extended‐range predictability at the climate time scale. A prediction model based on phase space reconstruction has demonstrated that monsoon intraseasonal oscillation can be better predicted at long leads. 
          ,  
            Key Points 
             
               
                 
                  The predictability of weather forecast models is limited to less than 10 days because of the limit imposed by chaos and model imperfections 
                 
                 
                  The existence of slowly varying components of the climate system and regularly varying phenomena provide basis for climate predictability 
                 
                 
                  A prediction model of monsoon intraseasonal oscillation using phase space reconstruction shows that some aspects of climate can be predicted},
	pages = {1043--1056},
	number = {7},
	journaltitle = {Earth and Space Science},
	shortjournal = {Earth and Space Science},
	author = {Krishnamurthy, V.},
	urldate = {2024-07-08},
	date = {2019-07},
	langid = {english},
}

@article{eccel_prediction_2007,
	title = {Prediction of minimum temperatures in an alpine region by linear and non-linear post-processing of meteorological models},
	volume = {14},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/14/211/2007/},
	doi = {10.5194/npg-14-211-2007},
	abstract = {Model Output Statistics ({MOS}) refers to a method of post-processing the direct outputs of numerical weather prediction ({NWP}) models in order to reduce the biases introduced by a coarse horizontal resolution. This technique is especially useful in orographically complex regions, where large differences can be found between the {NWP} elevation model and the true orography. This study carries out a comparison of linear and non-linear {MOS} methods, aimed at the prediction of minimum temperatures in a fruit-growing region of the Italian Alps, based on the output of two different {NWPs} ({ECMWF} T511\&ndash;L60 and {LAMI}-3). Temperature, of course, is a particularly important {NWP} output; among other roles it drives the local frost forecast, which is of great interest to agriculture. The mechanisms of cold air drainage, a distinctive aspect of mountain environments, are often unsatisfactorily captured by global circulation models. The simplest post-processing technique applied in this work was a correction for the mean bias, assessed at individual model grid points. We also implemented a multivariate linear regression on the output at the grid points surrounding the target area, and two non-linear models based on machine learning techniques: Neural Networks and Random Forest. We compare the performance of all these techniques on four different {NWP} data sets. Downscaling the temperatures clearly improved the temperature forecasts with respect to the raw {NWP} output, and also with respect to the basic mean bias correction. Multivariate methods generally yielded better results, but the advantage of using non-linear algorithms was small if not negligible. {RF}, the best performing method, was implemented on {ECMWF} prognostic output at 06:00 {UTC} over the 9 grid points surrounding the target area. Mean absolute errors in the prediction of 2 m temperature at 06:00 {UTC} were approximately 1.2\&deg;C, close to the natural variability inside the area itself.},
	pages = {211--222},
	number = {3},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Eccel, E. and Ghielmi, L. and Granitto, P. and Barbiero, R. and Grazzini, F. and Cesari, D.},
	urldate = {2024-07-12},
	date = {2007-05-25},
}

@article{dawid_present_1984,
	title = {Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach},
	volume = {147},
	issn = {0035-9238},
	url = {https://www.jstor.org/stable/2981683},
	doi = {10.2307/2981683},
	shorttitle = {Present Position and Potential Developments},
	abstract = {The prequential approach is founded on the premises that the purpose of statistical inference is to make sequential probability forecasts for future observations, rather than to express information about parameters. Many traditional parametric concepts, such as consistency and efficiency, prove to have natural counterparts in this formulation, which sheds new light on these and suggests fruitful extensions.},
	pages = {278--292},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society. Series A (General)},
	author = {Dawid, A. P.},
	urldate = {2024-07-19},
	date = {1984},
}

@article{gneiting_probabilistic_2014,
	title = {Probabilistic Forecasting},
	volume = {1},
	issn = {2326-8298, 2326-831X},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-statistics-062713-085831},
	doi = {10.1146/annurev-statistics-062713-085831},
	abstract = {A probabilistic forecast takes the form of a predictive probability distribution over future quantities or events of interest. Probabilistic forecasting aims to maximize the sharpness of the predictive distributions, subject to calibration, on the basis of the available information set. We formalize and study notions of calibration in a prediction space setting. In practice, probabilistic calibration can be checked by examining probability integral transform ({PIT}) histograms. Proper scoring rules such as the logarithmic score and the continuous ranked probability score serve to assess calibration and sharpness simultaneously. As a special case, consistent scoring functions provide decision-theoretically coherent tools for evaluating point forecasts. We emphasize methodological links to parametric and nonparametric distributional regression techniques, which attempt to model and to estimate conditional distribution functions; we use the context of statistically postprocessed ensemble forecasts in numerical weather prediction as an example. Throughout, we illustrate concepts and methodologies in data examples.},
	pages = {125--151},
	number = {1},
	journaltitle = {Annual Review of Statistics and Its Application},
	shortjournal = {Annu. Rev. Stat. Appl.},
	author = {Gneiting, Tilmann and Katzfuss, Matthias},
	urldate = {2024-06-24},
	date = {2014-01-03},
	langid = {english},
	keywords = {probabilistic forecast, scoring rules, verification},
}

@article{pacchiardi_probabilistic_2024,
	title = {Probabilistic Forecasting with Generative Networks via Scoring Rule Minimization},
	volume = {25},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v25/23-0038.html},
	abstract = {Probabilistic forecasting relies on past observations to provide a probability distribution for a future outcome, which is often evaluated against the realization using a scoring rule. Here, we perform probabilistic forecasting with generative neural networks, which parametrize distributions on high-dimensional spaces by transforming draws from a latent variable. Generative networks are typically trained in an adversarial framework. In contrast, we propose to train generative networks to minimize a predictive-sequential (or prequential) scoring rule on a recorded temporal sequence of the phenomenon of interest, which is appealing as it corresponds to the way forecasting systems are routinely evaluated. Adversarial-free minimization is possible for some scoring rules; hence, our framework avoids the cumbersome hyperparameter tuning and uncertainty underestimation due to unstable adversarial training, thus unlocking reliable use of generative networks in probabilistic forecasting. Further, we prove consistency of the minimizer of our objective with dependent data, while adversarial training assumes independence. We perform simulation studies on two chaotic dynamical models and a benchmark data set of global weather observations; for this last example, we define scoring rules for spatial data by drawing from the relevant literature. Our method outperforms state-of-the-art adversarial approaches, especially in probabilistic calibration, while requiring less hyperparameter tuning.},
	pages = {1--64},
	number = {45},
	journaltitle = {Journal of Machine Learning Research},
	author = {Pacchiardi, Lorenzo and Adewoyin, Rilwan A. and Dueben, Peter and Dutta, Ritabrata},
	urldate = {2024-05-31},
	date = {2024},
	keywords = {generative, multivariate prediction, neural networks, scoring rules},
}

@article{gneiting_probabilistic_2007,
	title = {Probabilistic Forecasts, Calibration and Sharpness},
	volume = {69},
	issn = {1369-7412, 1467-9868},
	url = {https://academic.oup.com/jrsssb/article/69/2/243/7109375},
	doi = {10.1111/j.1467-9868.2007.00587.x},
	abstract = {Summary 
            Probabilistic forecasts of continuous variables take the form of predictive densities or predictive cumulative distribution functions. We propose a diagnostic approach to the evaluation of predictive performance that is based on the paradigm of maximizing the sharpness of the predictive distributions subject to calibration. Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. Sharpness refers to the concentration of the predictive distributions and is a property of the forecasts only. A simple theoretical framework allows us to distinguish between probabilistic calibration, exceedance calibration and marginal calibration. We propose and study tools for checking calibration and sharpness, among them the probability integral transform histogram, marginal calibration plots, the sharpness diagram and proper scoring rules. The diagnostic approach is illustrated by an assessment and ranking of probabilistic forecasts of wind speed at the Stateline wind energy centre in the {US} Pacific Northwest. In combination with cross-validation or in the time series context, our proposal provides very general, nonparametric alternatives to the use of information criteria for model diagnostics and model selection.},
	pages = {243--268},
	number = {2},
	journaltitle = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
	author = {Gneiting, Tilmann and Balabdaoui, Fadoua and Raftery, Adrian E.},
	urldate = {2023-10-26},
	date = {2007-04-01},
	langid = {english},
	keywords = {scoring rules, verification},
}

@book{murphy_probabilistic_2022,
	location = {Cambridge, Massachusetts},
	title = {Probabilistic machine learning: an introduction},
	isbn = {9780262046824},
	series = {Adaptive computation and machine learning series},
	shorttitle = {Probabilistic machine learning},
	abstract = {"This book provides a detailed and up-to-date coverage of machine learning. It is unique in that it unifies approaches based on deep learning with approaches based on probabilistic modeling and inference. It provides mathematical background (e.g. linear algebra, optimization), basic topics (e.g., linear and logistic regression, deep neural networks), as well as more advanced topics (e.g., Gaussian processes). It provides a perfect introduction for people who want to understand cutting edge work in top machine learning conferences such as {NeurIPS}, {ICML} and {ICLR}"--},
	pagetotal = {826},
	publisher = {The {MIT} Press},
	author = {Murphy, Kevin P.},
	date = {2022},
	keywords = {Machine learning, Probabilities},
}

@article{chapman_probabilistic_2022,
	title = {Probabilistic Predictions from Deterministic Atmospheric River Forecasts with Deep Learning},
	volume = {150},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/150/1/MWR-D-21-0106.1.xml},
	doi = {10.1175/MWR-D-21-0106.1},
	abstract = {Abstract Deep-learning ({DL}) postprocessing methods are examined to obtain reliable and accurate probabilistic forecasts from single-member numerical weather predictions of integrated vapor transport ({IVT}). Using a 34-yr reforecast, based on the Center for Western Weather and Water Extremes West-{WRF} mesoscale model of North American West Coast {IVT}, the dynamically/statistically derived 0–120-h probabilistic forecasts for {IVT} under atmospheric river ({AR}) conditions are tested. These predictions are compared with the Global Ensemble Forecast System ({GEFS}) dynamic model and the {GEFS} calibrated with a neural network. In addition, the {DL} methods are tested against an established, but more rigid, statistical–dynamical ensemble method (the analog ensemble). The findings show, using continuous ranked probability skill score and Brier skill score as verification metrics, that the {DL} methods compete with or outperform the calibrated {GEFS} system at lead times from 0 to 48 h and again from 72 to 120 h for {AR} vapor transport events. In addition, the {DL} methods generate reliable and skillful probabilistic forecasts. The implications of varying the length of the training dataset are examined, and the results show that the {DL} methods learn relatively quickly and ∼10 years of hindcast data are required to compete with the {GEFS} ensemble.},
	pages = {215--234},
	number = {1},
	journaltitle = {Monthly Weather Review},
	author = {Chapman, William E. and Monache, Luca Delle and Alessandrini, Stefano and Subramanian, Aneesh C. and Ralph, F. Martin and Xie, Shang-Ping and Lerch, Sebastian and Hayatbini, Negin},
	urldate = {2024-06-25},
	date = {2022-02-02},
	keywords = {convolutional neural network, post-processing},
}

@article{gneiting_probabilistic_2023,
	title = {Probabilistic solar forecasting: Benchmarks, post-processing, verification},
	volume = {252},
	issn = {0038-092X},
	url = {https://www.sciencedirect.com/science/article/pii/S0038092X22009343},
	doi = {10.1016/j.solener.2022.12.054},
	shorttitle = {Probabilistic solar forecasting},
	abstract = {Probabilistic solar forecasts may take the form of predictive probability distributions, ensembles, quantiles, or interval forecasts. State-of-the-art approaches build on input from numerical weather prediction ({NWP}) models and post-processing with statistical and machine learning methods. We propose a probabilistic benchmark based on a deterministic forecast of clear-sky irradiance, introduce new methods for post-processing that merge statistical techniques with modern neural networks, discuss methods for spatio-temporal scenario forecasts, and illustrate the assessment of predictive ability via proper scoring rules and calibration checks. We expect future solar forecasting efforts to be increasingly probabilistic, and encourage continuing close interaction with operational weather prediction, where innovations based on sophisticated neural networks supplement and challenge traditional approaches.},
	pages = {72--80},
	journaltitle = {Solar Energy},
	shortjournal = {Solar Energy},
	author = {Gneiting, Tilmann and Lerch, Sebastian and Schulz, Benedikt},
	urldate = {2024-05-22},
	date = {2023-03-01},
	keywords = {energy meteorology, post-processing},
}

@article{frei_publicprivate_2021,
	title = {Public–private engagement ( {\textless}span style="font-variant:small-caps;"{\textgreater}{PPE}{\textless}/span{\textgreater} ) in hydromet services and the role of the academic sector},
	volume = {28},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.2025},
	doi = {10.1002/met.2025},
	shorttitle = {Public–private engagement ( {\textless}span style="font-variant},
	abstract = {Abstract 
            National meteorological and hydrological services ({NMHSs}) play a key role in gathering data and in providing services like early warnings, basic weather forecasts or climate analysis. In most developing countries, {NMHSs} are public services facing hindering financial constraints and shortages of skilled personnel. Both the World Meteorological Organization ({WMO}) and academia play a long‐standing role in creating, innovating and fostering technology and services in meteorology and hydrology (hydromet services). At the same time, the role of the private sector in weather service provision is strongly growing all around the world. In order to maximize socio‐economic benefits from hydromet services, it is necessary that countries are considering how to strategically embrace the benefits that the private and academic sectors can offer without jeopardizing the provision of public services. A recent World Bank report suggests that public–private engagement ({PPE}) can create and sustain effective hydromet value chains. Moving towards {PPE} not only creates opportunities for the academic sector but in many instances critically depends on it for capacity building, to further develop trust relationships between the sectors, to provide spaces in which collaboration between the sectors can be tested and last but not least serve as a source and conduit for new technologies. This paper intends to stimulate discussion on {PPE} and the role that academics and academic institutions can take to foster sustainable hydromet value chains.},
	pages = {e2025},
	number = {5},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Frei, Thomas},
	urldate = {2024-03-29},
	date = {2021-09},
	langid = {english},
	keywords = {weather and climate services},
}

@misc{paszke_pytorch_2019,
	title = {{PyTorch}: An Imperative Style, High-Performance Deep Learning Library},
	url = {http://arxiv.org/abs/1912.01703},
	doi = {10.48550/arXiv.1912.01703},
	shorttitle = {{PyTorch}},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. {PyTorch} is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as {GPUs}. In this paper, we detail the principles that drove the implementation of {PyTorch} and how they are reflected in its architecture. We emphasize that every aspect of {PyTorch} is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of {PyTorch} on several common benchmarks.},
	number = {{arXiv}:1912.01703},
	publisher = {{arXiv}},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and {DeVito}, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	urldate = {2024-07-13},
	date = {2019-12-03},
	eprinttype = {arxiv},
	eprint = {1912.01703 [cs, stat]},
	keywords = {software},
}

@inproceedings{rahimi_random_2007,
	title = {Random Features for Large-Scale Kernel Machines},
	volume = {20},
	url = {https://proceedings.neurips.cc/paper/2007/hash/013a006f03dbc5392effeb8f18fda755-Abstract.html},
	abstract = {To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user speciﬁed shift- invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classiﬁcation and regression tasks linear machine learning al- gorithms applied to these features outperform state-of-the-art large-scale kernel machines.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Rahimi, Ali and Recht, Benjamin},
	urldate = {2024-05-27},
	date = {2007},
}

@article{allen_regimedependent_2019,
	title = {Regime‐dependent statistical post‐processing of ensemble forecasts},
	volume = {145},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.3638},
	doi = {10.1002/qj.3638},
	abstract = {Abstract 
            A number of realizations of one or more numerical weather prediction ({NWP}) models, initialised at a variety of initial conditions, compose an ensemble forecast. These forecasts exhibit systematic errors and biases that can be corrected by statistical post‐processing. Post‐processing yields calibrated forecasts by analysing the statistical relationship between historical forecasts and their corresponding observations. This article aims to extend post‐processing methodology to incorporate atmospheric circulation. The circulation, or flow, is largely responsible for the weather that we experience and it is hypothesized here that relationships between the {NWP} model and the atmosphere depend upon the prevailing flow. Numerous studies have focussed on the tendency of this flow to reduce to a set of recognisable arrangements, known as regimes, which recur and persist at fixed geographical locations. This dynamical phenomenon allows the circulation to be categorized into a small number of regime states. In a highly idealized model of the atmosphere, the Lorenz ‘96 system, ensemble forecasts are subjected to well‐known post‐processing techniques conditional on the system's underlying regime. Two different variables, one of the state variables and one related to the energy of the system, are forecasted and considerable improvements in forecast skill upon standard post‐processing are seen when the distribution of the predictand varies depending on the regime. Advantages of this approach and its inherent challenges are discussed, along with potential extensions for operational forecasters.},
	pages = {3535--3552},
	number = {725},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Allen, Sam and Ferro, Christopher A. T. and Kwasniok, Frank},
	urldate = {2024-07-23},
	date = {2019-10},
	langid = {english},
	keywords = {post-processing},
}

@article{brocker_reliability_2009,
	title = {Reliability, sufficiency, and the decomposition of proper scores},
	volume = {135},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.456},
	doi = {10.1002/qj.456},
	abstract = {Abstract 
             
              Scoring rules are an important tool for evaluating the performance of probabilistic forecasting schemes. A scoring rule is called strictly proper if its expectation is optimal if and only if the forecast probability represents the true distribution of the target. In the binary case, strictly proper scoring rules allow for a decomposition into terms related to the resolution and the reliability of a forecast. This fact is particularly well known for the Brier Score. In this article, this result is extended to forecasts for finite‐valued targets. Both resolution and reliability are shown to have a positive effect on the score. It is demonstrated that resolution and reliability are directly related to forecast attributes that are desirable on grounds independent of the notion of scores. This finding can be considered an epistemological justification of measuring forecast quality by proper scoring rules. A link is provided to the original work of {DeGroot} and Fienberg, extending their concepts of sufficiency and refinement. The relation to the conjectured sharpness principle of Gneiting, 
              et al., 
              is elucidated. Copyright © 2009 Royal Meteorological Society},
	pages = {1512--1519},
	number = {643},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Bröcker, Jochen},
	urldate = {2024-06-18},
	date = {2009-07},
	langid = {english},
	keywords = {scoring rules, verification},
}

@article{lang_remember_2020,
	title = {Remember the past: a comparison of time-adaptive training schemes for non-homogeneous regression},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/23/2020/},
	doi = {10.5194/npg-27-23-2020},
	shorttitle = {Remember the past},
	abstract = {Non-homogeneous regression is a frequently used post-processing method for increasing the predictive skill of probabilistic ensemble weather forecasts. To adjust for seasonally varying error characteristics between ensemble forecasts and corresponding observations, different time-adaptive training schemes, including the classical sliding training window, have been developed for non-homogeneous regression. This study compares three such training approaches with the sliding-window approach for the application of post-processing near-surface air temperature forecasts across central Europe. The predictive performance is evaluated conditional on three different groups of stations located in plains, in mountain foreland, and within mountainous terrain, as well as on a specific change in the ensemble forecast system of the European Centre for Medium-Range Weather Forecasts ({ECMWF}) used as input for the post-processing.

 The results show that time-adaptive training schemes using data over multiple years stabilize the temporal evolution of the coefficient estimates, yielding an increased predictive performance for all station types tested compared to the classical sliding-window approach based on the most recent days only. While this may not be surprising under fully stable model conditions, it is shown that “remembering the past” from multiple years of training data is typically also superior to the classical sliding-window approach when the ensemble prediction system is affected by certain model changes. Thus, reducing the variance of the non-homogeneous regression estimates due to increased training data appears to be more important than reducing its bias by adapting rapidly to the most current training data only.},
	pages = {23--34},
	number = {1},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Lang, Moritz N. and Lerch, Sebastian and Mayr, Georg J. and Simon, Thorsten and Stauffer, Reto and Zeileis, Achim},
	urldate = {2024-05-22},
	date = {2020-02-05},
}

@article{weyrich_responses_2020,
	title = {Responses to severe weather warnings and affective decision-making},
	volume = {20},
	issn = {1561-8633},
	url = {https://nhess.copernicus.org/articles/20/2811/2020/},
	doi = {10.5194/nhess-20-2811-2020},
	abstract = {When public agencies provide information provision to help people make better decisions, they often face the choice between economy and completeness. For weather services warning people of high-impact weather events, this choice is between offering standard warnings ({SWs}) only of the weather event itself, such as wind-speed, or also describing the likely impacts (so-called impact-based warnings, {IBWs}). Previous studies have shown {IBWs} to lead to a greater behavioral response. These studies, however, have relied on surveys describing hypothetical weather events; given that participants did not feel threatened, they may have been more likely to process the warning slowly and analytically, which could bias the results towards finding a greater response to the {IBWs}. In this study, we conducted a field experiment involving actual and potentially threatening weather events for which there was variance with respect to the time interval between the warning and the forecasted event and for which we randomly assigned participants to receive {SWs} or {IBWs}. We observe that shorter time intervals led to a greater behavioral response, suggesting that fear of an imminent threat is an important factor motivating behavior. We observe that {IBWs} did not lead to greater rates of behavioral change than {SWs}, suggesting that when fear is a driving factor, the additional information in {IBWs} may be of little importance. We note that our findings are highly contextualized, but we call into question the prevailing belief that {IBWs} are necessarily more helpful than {SWs}.},
	pages = {2811--2821},
	number = {10},
	journaltitle = {Natural Hazards and Earth System Sciences},
	author = {Weyrich, Philippe and Scolobig, Anna and Walther, Florian and Patt, Anthony},
	urldate = {2024-03-29},
	date = {2020-10-26},
	keywords = {decision-making, weather and climate services},
}

@article{ling_reynolds_2016,
	title = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
	volume = {807},
	issn = {0022-1120, 1469-7645},
	doi = {10.1017/jfm.2016.615},
	abstract = {There exists significant demand for improved Reynolds-averaged Navier–Stokes ({RANS}) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline {RANS} linear eddy viscosity and nonlinear eddy viscosity models is demonstrated.},
	pages = {155--166},
	journaltitle = {Journal of Fluid Mechanics},
	author = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
	urldate = {2022-12-05},
	date = {2016-11},
	langid = {english},
	keywords = {turbulence modelling, turbulence theory, turbulent flows},
}

@article{muschinski_robust_2023,
	title = {Robust weather-adaptive post-processing using model output statistics random forests},
	volume = {30},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/30/503/2023/},
	doi = {10.5194/npg-30-503-2023},
	abstract = {Physical numerical weather prediction models have biases and miscalibrations that can depend on the weather situation, which makes it difficult to post-process them effectively using the traditional model output statistics ({MOS}) framework based on parametric regression models. Consequently, much recent work has focused on using flexible machine learning methods that are able to take additional weather-related predictors into account during post-processing beyond the forecast of the variable of interest only. Some of these methods have achieved impressive results, but they typically require significantly more training data than traditional {MOS} and are less straightforward to implement and interpret.

 We propose {MOS} random forests, a new post-processing method that avoids these problems by fusing traditional {MOS} with a powerful machine learning method called random forests to estimate weather-adapted {MOS} coefficients from a set of predictors. Since the assumed parametric base model contains valuable prior knowledge, much smaller training data sizes are required to obtain skillful forecasts, and model results are easy to interpret. {MOS} random forests are straightforward to implement and typically work well, even with no or very little hyperparameter tuning. For the difficult task of post-processing daily precipitation sums in complex terrain, they outperform reference machine learning methods at most of the stations considered. Additionally, the method is highly robust in relation to changes in data size and works well even when less than 100 observations are available for training.},
	pages = {503--514},
	number = {4},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Muschinski, Thomas and Mayr, Georg J. and Zeileis, Achim and Simon, Thorsten},
	urldate = {2024-05-16},
	date = {2023-11-20},
}

@article{imhoff_scaledependent_2023,
	title = {Scale‐dependent blending of ensemble rainfall nowcasts and numerical weather prediction in the open‐source pysteps library},
	volume = {149},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4461},
	doi = {10.1002/qj.4461},
	abstract = {Abstract 
            Flash flood early warning requires accurate rainfall forecasts with a high spatial and temporal resolution. As the first few hours ahead are already not sufficiently well captured by the rainfall forecasts of numerical weather prediction ({NWP}) models, radar rainfall nowcasting can provide an alternative. Because this observation‐based method quickly loses skill after the first 2 hr of the forecast, it needs to be combined with {NWP} forecasts to extend the skillful lead time of short‐term rainfall forecasts, which should increase decision‐making times. We implemented an adaptive scale‐dependent ensemble blending method in the open‐source pysteps library, based on the Short‐Term Ensemble Prediction System scheme. In this implementation, the extrapolation (ensemble) nowcast, (ensemble) {NWP}, and noise components are combined with skill‐dependent weights that vary per spatial scale level. To constrain the (dis)appearance of rain in the ensemble members to regions around the rainy areas, we have developed a Lagrangian blended probability matching scheme and incremental masking strategy. We describe the implementation details and evaluate the method using three heavy and extreme (July 2021) rainfall events in four Belgian and Dutch catchments. We benchmark the results of the 48‐member blended forecasts against the Belgian {NWP} forecast, a 48‐member nowcast, and a simple 48‐member linear blending approach. Both on the radar domain and catchment scale, the introduced blending approach predominantly performs similarly or better than only nowcasting (in terms of event‐averaged continuous ranked probability score and critical success index values) and adds value compared with {NWP} for the first hours of the forecast, although the difference, particularly with the linear blending method, reduces when we focus on catchment‐average cumulative rainfall sums instead of instantaneous rainfall rates. By properly combining observations and {NWP} forecasts, blending methods such as these are a crucial component of seamless prediction systems.},
	pages = {1335--1364},
	number = {753},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Imhoff, Ruben O. and De Cruz, Lesley and Dewettinck, Wout and Brauer, Claudia C. and Uijlenhoet, Remko and Van Heeringen, Klaas‐Jan and Velasco‐Forero, Carlos and Nerini, Daniele and Van Ginderachter, Michiel and Weerts, Albrecht H.},
	urldate = {2024-07-17},
	date = {2023-04},
	langid = {english},
}

@article{imhoff_scaledependent_2023-1,
	title = {Scale‐dependent blending of ensemble rainfall nowcasts and numerical weather prediction in the open‐source pysteps library},
	volume = {149},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.4461},
	doi = {10.1002/qj.4461},
	abstract = {Abstract 
            Flash flood early warning requires accurate rainfall forecasts with a high spatial and temporal resolution. As the first few hours ahead are already not sufficiently well captured by the rainfall forecasts of numerical weather prediction ({NWP}) models, radar rainfall nowcasting can provide an alternative. Because this observation‐based method quickly loses skill after the first 2 hr of the forecast, it needs to be combined with {NWP} forecasts to extend the skillful lead time of short‐term rainfall forecasts, which should increase decision‐making times. We implemented an adaptive scale‐dependent ensemble blending method in the open‐source pysteps library, based on the Short‐Term Ensemble Prediction System scheme. In this implementation, the extrapolation (ensemble) nowcast, (ensemble) {NWP}, and noise components are combined with skill‐dependent weights that vary per spatial scale level. To constrain the (dis)appearance of rain in the ensemble members to regions around the rainy areas, we have developed a Lagrangian blended probability matching scheme and incremental masking strategy. We describe the implementation details and evaluate the method using three heavy and extreme (July 2021) rainfall events in four Belgian and Dutch catchments. We benchmark the results of the 48‐member blended forecasts against the Belgian {NWP} forecast, a 48‐member nowcast, and a simple 48‐member linear blending approach. Both on the radar domain and catchment scale, the introduced blending approach predominantly performs similarly or better than only nowcasting (in terms of event‐averaged continuous ranked probability score and critical success index values) and adds value compared with {NWP} for the first hours of the forecast, although the difference, particularly with the linear blending method, reduces when we focus on catchment‐average cumulative rainfall sums instead of instantaneous rainfall rates. By properly combining observations and {NWP} forecasts, blending methods such as these are a crucial component of seamless prediction systems.},
	pages = {1335--1364},
	number = {753},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Imhoff, Ruben O. and De Cruz, Lesley and Dewettinck, Wout and Brauer, Claudia C. and Uijlenhoet, Remko and Van Heeringen, Klaas‐Jan and Velasco‐Forero, Carlos and Nerini, Daniele and Van Ginderachter, Michiel and Weerts, Albrecht H.},
	urldate = {2024-07-21},
	date = {2023-04},
	langid = {english},
	keywords = {nowcasting, precipitation, software},
}

@misc{esteves_scaling_2023,
	title = {Scaling Spherical {CNNs}},
	url = {http://arxiv.org/abs/2306.05420},
	doi = {10.48550/arXiv.2306.05420},
	abstract = {Spherical {CNNs} generalize {CNNs} to functions on the sphere, by using spherical convolutions as the main linear operation. The most accurate and efficient way to compute spherical convolutions is in the spectral domain (via the convolution theorem), which is still costlier than the usual planar convolutions. For this reason, applications of spherical {CNNs} have so far been limited to small problems that can be approached with low model capacity. In this work, we show how spherical {CNNs} can be scaled for much larger problems. To achieve this, we make critical improvements including novel variants of common model components, an implementation of core operations to exploit hardware accelerator characteristics, and application-specific input representations that exploit the properties of our model. Experiments show our larger spherical {CNNs} reach state-of-the-art on several targets of the {QM}9 molecular benchmark, which was previously dominated by equivariant graph neural networks, and achieve competitive performance on multiple weather forecasting tasks. Our code is available at https://github.com/google-research/spherical-cnn.},
	number = {{arXiv}:2306.05420},
	publisher = {{arXiv}},
	author = {Esteves, Carlos and Slotine, Jean-Jacques and Makadia, Ameesh},
	urldate = {2024-05-29},
	date = {2023-06-08},
	eprinttype = {arxiv},
	eprint = {2306.05420 [cs]},
	keywords = {data-driven weather prediction, deterministic prediction},
}

@misc{nguyen_scaling_2023,
	title = {Scaling transformer neural networks for skillful and reliable medium-range weather forecasting},
	url = {http://arxiv.org/abs/2312.03876},
	doi = {10.48550/arXiv.2312.03876},
	abstract = {Weather forecasting is a fundamental problem for anticipating and mitigating the impacts of climate change. Recently, data-driven approaches for weather forecasting based on deep learning have shown great promise, achieving accuracies that are competitive with operational systems. However, those methods often employ complex, customized architectures without sufficient ablation analysis, making it difficult to understand what truly contributes to their success. Here we introduce Stormer, a simple transformer model that achieves state-of-the-art performance on weather forecasting with minimal changes to the standard transformer backbone. We identify the key components of Stormer through careful empirical analyses, including weather-specific embedding, randomized dynamics forecast, and pressure-weighted loss. At the core of Stormer is a randomized forecasting objective that trains the model to forecast the weather dynamics over varying time intervals. During inference, this allows us to produce multiple forecasts for a target lead time and combine them to obtain better forecast accuracy. On {WeatherBench} 2, Stormer performs competitively at short to medium-range forecasts and outperforms current methods beyond 7 days, while requiring orders-of-magnitude less training data and compute. Additionally, we demonstrate Stormer's favorable scaling properties, showing consistent improvements in forecast accuracy with increases in model size and training tokens. Code and checkpoints will be made publicly available.},
	number = {{arXiv}:2312.03876},
	publisher = {{arXiv}},
	author = {Nguyen, Tung and Shah, Rohan and Bansal, Hritik and Arcomano, Troy and Madireddy, Sandeep and Maulik, Romit and Kotamarthi, Veerabhadra and Foster, Ian and Grover, Aditya},
	urldate = {2024-06-05},
	date = {2023-12-06},
	eprinttype = {arxiv},
	eprint = {2312.03876 [physics]},
	keywords = {data-driven weather prediction},
}

@article{brehmer_scoring_2021,
	title = {Scoring Interval Forecasts: Equal-Tailed, Shortest, and Modal Interval},
	volume = {27},
	issn = {1350-7265},
	url = {http://arxiv.org/abs/2007.05709},
	doi = {10.3150/20-BEJ1298},
	shorttitle = {Scoring Interval Forecasts},
	abstract = {We consider different types of predictive intervals and ask whether they are elicitable, i.e. are unique minimizers of a loss or scoring function in expectation. The equal-tailed interval is elicitable, with a rich class of suitable loss functions, though subject to translation invariance, or positive homogeneity and differentiability, the Winkler interval score becomes a unique choice. The modal interval also is elicitable, with a sole consistent scoring function, up to equivalence. However, the shortest interval fails to be elicitable relative to practically relevant classes of distributions. These results provide guidance in interval forecast evaluation and support recent choices of performance measures in forecast competitions.},
	number = {3},
	journaltitle = {Bernoulli},
	shortjournal = {Bernoulli},
	author = {Brehmer, Jonas and Gneiting, Tilmann},
	urldate = {2024-05-25},
	date = {2021-05-01},
	eprinttype = {arxiv},
	eprint = {2007.05709 [math, stat]},
	keywords = {scoring rules, verification},
}

@article{matheson_scoring_1976,
	title = {Scoring Rules for Continuous Probability Distributions},
	volume = {22},
	issn = {0025-1909, 1526-5501},
	url = {https://pubsonline.informs.org/doi/10.1287/mnsc.22.10.1087},
	doi = {10.1287/mnsc.22.10.1087},
	abstract = {Personal, or subjective, probabilities are used as inputs to many inferential and decision-making models, and various procedures have been developed for the elicitation of such probabilities. Included among these elicitation procedures are scoring rules, which involve the computation of a score based on the assessor's stated probabilities and on the event that actually occurs. The development of scoring rules has, in general, been restricted to the elicitation of discrete probability distributions. In this paper, families of scoring rules for the elicitation of continuous probability distributions are developed and discussed.},
	pages = {1087--1096},
	number = {10},
	journaltitle = {Management Science},
	shortjournal = {Management Science},
	author = {Matheson, James E. and Winkler, Robert L.},
	urldate = {2024-07-17},
	date = {1976-06},
	langid = {english},
}

@article{dusterhus_seasonal_2020,
	title = {Seasonal statistical–dynamical prediction of the North Atlantic Oscillation by probabilistic post-processing and its evaluation},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/121/2020/},
	doi = {10.5194/npg-27-121-2020},
	abstract = {Dynamical models of various centres have shown in recent years seasonal prediction skill of the North Atlantic Oscillation ({NAO}). By filtering the ensemble members on the basis of statistical predictors, known as subsampling, it is possible to achieve even higher prediction skill. In this study the aim is to design a generalisation of the subsampling approach and establish it as a post-processing procedure.

 Instead of selecting discrete ensemble members for each year, as the subsampling approach does, the distributions of ensembles and statistical predictors are combined to create a probabilistic prediction of the winter {NAO}. By comparing the combined statistical–dynamical prediction with the predictions of its single components, it can be shown that it achieves similar results to the statistical prediction. At the same time it can be shown that, unlike the statistical prediction, the combined prediction has fewer years where it performs worse than the dynamical prediction.

 By applying the gained distributions to other meteorological variables, like geopotential height, precipitation and surface temperature, it can be shown that evaluating prediction skill depends highly on the chosen metric. Besides the common anomaly correlation ({ACC}) this study also presents scores based on the Earth mover's distance ({EMD}) and the integrated quadratic distance ({IQD}), which are designed to evaluate skills of probabilistic predictions. It shows that by evaluating the predictions for each year separately compared to applying a metric to all years at the same time, like correlation-based metrics, leads to different interpretations of the analysis.},
	pages = {121--131},
	number = {1},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Düsterhus, André},
	urldate = {2024-05-22},
	date = {2020-02-27},
}

@misc{scholz_sim2real_2023,
	title = {Sim2Real for Environmental Neural Processes},
	url = {http://arxiv.org/abs/2310.19932},
	doi = {10.48550/arXiv.2310.19932},
	abstract = {Machine learning ({ML})-based weather models have recently undergone rapid improvements. These models are typically trained on gridded reanalysis data from numerical data assimilation systems. However, reanalysis data comes with limitations, such as assumptions about physical laws and low spatiotemporal resolution. The gap between reanalysis and reality has sparked growing interest in training {ML} models directly on observations such as weather stations. Modelling scattered and sparse environmental observations requires scalable and flexible {ML} architectures, one of which is the convolutional conditional neural process ({ConvCNP}). {ConvCNPs} can learn to condition on both gridded and off-the-grid context data to make uncertainty-aware predictions at target locations. However, the sparsity of real observations presents a challenge for data-hungry deep learning models like the {ConvCNP}. One potential solution is 'Sim2Real': pre-training on reanalysis and fine-tuning on observational data. We analyse Sim2Real with a {ConvCNP} trained to interpolate surface air temperature over Germany, using varying numbers of weather stations for fine-tuning. On held-out weather stations, Sim2Real training substantially outperforms the same model architecture trained only with reanalysis data or only with station data, showing that reanalysis data can serve as a stepping stone for learning from real observations. Sim2Real could thus enable more accurate models for weather prediction and climate monitoring.},
	number = {{arXiv}:2310.19932},
	publisher = {{arXiv}},
	author = {Scholz, Jonas and Andersson, Tom R. and Vaughan, Anna and Requeima, James and Turner, Richard E.},
	urldate = {2024-05-27},
	date = {2023-10-30},
	eprinttype = {arxiv},
	eprint = {2310.19932 [physics]},
	keywords = {geostatistics, neural processes},
}

@incollection{stull_similarity_1988,
	location = {Dordrecht},
	title = {Similarity Theory},
	isbn = {9789400930278},
	url = {https://doi.org/10.1007/978-94-009-3027-8_9},
	abstract = {For a number of boundary layer situations, our knowledge of the governing physics is insufficient to derive laws based on first principles. Nevertheless, boundary layer observations frequently show consistent and repeatable characteristics, suggesting that we could develop empirical relationships for the variables of interest. Similarity theory provides a way to organize and group the variables to our maximum advantage, and in turn provides guidelines on how to design experiments to gain the most information.},
	pages = {347--404},
	booktitle = {An Introduction to Boundary Layer Meteorology},
	publisher = {Springer Netherlands},
	author = {Stull, Roland B.},
	editor = {Stull, Roland B.},
	urldate = {2024-07-22},
	date = {1988},
	langid = {english},
	doi = {10.1007/978-94-009-3027-8_9},
}

@article{lerch_simulation-based_2020,
	title = {Simulation-based comparison of multivariate ensemble post-processing methods},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/349/2020/},
	doi = {10.5194/npg-27-349-2020},
	abstract = {Many practical applications of statistical post-processing methods for ensemble weather forecasts require accurate modeling of spatial, temporal, and inter-variable dependencies. Over the past years, a variety of approaches has been proposed to address this need. We provide a comprehensive review and comparison of state-of-the-art methods for multivariate ensemble post-processing. We focus on generally applicable two-step approaches where ensemble predictions are first post-processed separately in each margin and multivariate dependencies are restored via copula functions in a second step. The comparisons are based on simulation studies tailored to mimic challenges occurring in practical applications and allow ready interpretation of the effects of different types of misspecifications in the mean, variance, and covariance structure of the ensemble forecasts on the performance of the post-processing methods. Overall, we find that the Schaake shuffle provides a compelling benchmark that is difficult to outperform, whereas the forecast quality of parametric copula approaches and variants of ensemble copula coupling strongly depend on the misspecifications at hand.},
	pages = {349--371},
	number = {2},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Lerch, Sebastian and Baran, Sándor and Möller, Annette and Groß, Jürgen and Schefzik, Roman and Hemri, Stephan and Graeter, Maximiliane},
	urldate = {2024-05-22},
	date = {2020-06-12},
}

@article{lerch_simulation-based_2020-1,
	title = {Simulation-based comparison of multivariate ensemble post-processing methods},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/349/2020/},
	doi = {10.5194/npg-27-349-2020},
	abstract = {Many practical applications of statistical post-processing methods for ensemble weather forecasts require accurate modeling of spatial, temporal, and inter-variable dependencies. Over the past years, a variety of approaches has been proposed to address this need. We provide a comprehensive review and comparison of state-of-the-art methods for multivariate ensemble post-processing. We focus on generally applicable two-step approaches where ensemble predictions are first post-processed separately in each margin and multivariate dependencies are restored via copula functions in a second step. The comparisons are based on simulation studies tailored to mimic challenges occurring in practical applications and allow ready interpretation of the effects of different types of misspecifications in the mean, variance, and covariance structure of the ensemble forecasts on the performance of the post-processing methods. Overall, we find that the Schaake shuffle provides a compelling benchmark that is difficult to outperform, whereas the forecast quality of parametric copula approaches and variants of ensemble copula coupling strongly depend on the misspecifications at hand.},
	pages = {349--371},
	number = {2},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Lerch, Sebastian and Baran, Sándor and Möller, Annette and Groß, Jürgen and Schefzik, Roman and Hemri, Stephan and Graeter, Maximiliane},
	urldate = {2024-07-15},
	date = {2020-06-12},
}

@article{richardson_skill_2000,
	title = {Skill and relative economic value of the {ECMWF} ensemble prediction system},
	volume = {126},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.49712656313},
	doi = {10.1002/qj.49712656313},
	abstract = {Abstract 
            The economic value of the European Centre for Medium‐Range Weather Forecasts ({ECMWF}) operational ensemble prediction system ({EPS}) is assessed relative to the value of a perfect deterministic forecast. The {EPS} has substantial relative value throughout the medium range. Probability forecasts derived from the {EPS} are of greater benefit than a deterministic forecast produced by the same model. Indeed, for many users, the probability forecasts have more value than a shorter‐range deterministic forecast. Based on the measures used here, the additional information in the {EPS} (reflecting the uncertainty in the initial conditions) provides a benefit to users equivalent to many years' development of the forecast model and assimilation system. 
            The impact of ensemble size on forecast value is considered. The difference in performance between ensembles with 10 and with 50 members may appear relatively small, based on standard skill measures, yet the larger ensembles have substantial benefit to a range of users. Further increases in ensemble size may be expected to provide additional value.},
	pages = {649--667},
	number = {563},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Richardson, D. S.},
	urldate = {2024-03-29},
	date = {2000-01},
	langid = {english},
	keywords = {economic value, verification, weather and climate services},
}

@article{perrels_socio-economic_2013,
	title = {Socio-economic benefits of weather and climate services in Europe},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/3.0/},
	issn = {1992-0636},
	url = {https://asr.copernicus.org/articles/10/65/2013/},
	doi = {10.5194/asr-10-65-2013},
	abstract = {Abstract. There is a rising interest around the world for a better understanding of the economic and social value added of weather services. National hydro-meteorological services and international cooperative bodies in meteorology have ever more to justify their use of public budgets. Furthermore, the development of hydrological and meteorological services is to a large extent steered by expectations regarding the eventual benefits of the envisaged new developments. This article provides a compact overview of the impediments for uptake of socio-economic benefit ({SEB}) studies, methods and results of {SEB} studies to date. It also discusses some pitfalls and crucial steps to enhance a broader uptake of {SEB} studies.},
	pages = {65--70},
	number = {1},
	journaltitle = {Advances in Science and Research},
	shortjournal = {Adv. Sci. Res.},
	author = {Perrels, A. and Frei, Th. and Espejo, F. and Jamin, L. and Thomalla, A.},
	urldate = {2024-06-11},
	date = {2013-05-28},
	langid = {english},
	keywords = {weather and climate services},
}

@article{dabernig_spatial_2017,
	title = {Spatial ensemble post‐processing with standardized anomalies},
	volume = {143},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/qj.2975},
	doi = {10.1002/qj.2975},
	abstract = {To post‐process ensemble predictions for a particular location, statistical methods are often used, especially in complex terrain such as the Alps. When expanded to several stations, the post‐processing has to be repeated at every station individually, thus losing information about spatial coherence and increasing computational cost. Therefore, the ensemble post‐processing is modified and applied simultaneously at multiple locations. We transform observations and predictions to standardized anomalies. Seasonal and site‐specific characteristics are eliminated by subtracting a climatological mean and dividing by the climatological standard deviation from both observations and numerical forecasts. This method allows us to forecast even at locations where no observations are available. The skill of these forecasts is comparable to forecasts post‐processed individually at every station and is even better on average.},
	pages = {909--916},
	number = {703},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Dabernig, Markus and Mayr, Georg J. and Messner, Jakob W. and Zeileis, Achim},
	urldate = {2024-07-08},
	date = {2017-01},
	langid = {english},
}

@article{feldmann_spatial_2015,
	title = {Spatial Postprocessing of Ensemble Forecasts for Temperature Using Nonhomogeneous Gaussian Regression},
	volume = {143},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/143/3/mwr-d-14-00210.1.xml},
	doi = {10.1175/MWR-D-14-00210.1},
	abstract = {Abstract Statistical postprocessing techniques are commonly used to improve the skill of ensembles from numerical weather forecasts. This paper considers spatial extensions of the well-established nonhomogeneous Gaussian regression ({NGR}) postprocessing technique for surface temperature and a recent modification thereof in which the local climatology is included in the regression model to permit locally adaptive postprocessing. In a comparative study employing 21-h forecasts from the Consortium for Small Scale Modelling ensemble predictive system over Germany ({COSMO}-{DE}), two approaches for modeling spatial forecast error correlations are considered: a parametric Gaussian random field model and the ensemble copula coupling ({ECC}) approach, which utilizes the spatial rank correlation structure of the raw ensemble. Additionally, the {NGR} methods are compared to both univariate and spatial versions of the ensemble Bayesian model averaging ({BMA}) postprocessing technique.},
	pages = {955--971},
	number = {3},
	journaltitle = {Monthly Weather Review},
	author = {Feldmann, Kira and Scheuerer, Michael and Thorarinsdottir, Thordis L.},
	urldate = {2024-07-15},
	date = {2015-03-01},
}

@article{winstral_spatial_2002,
	title = {Spatial Snow Modeling of Wind-Redistributed Snow Using Terrain-Based Parameters},
	volume = {3},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/3/5/1525-7541_2002_003_0524_ssmowr_2_0_co_2.xml},
	doi = {10.1175/1525-7541(2002)003<0524:SSMOWR>2.0.CO;2},
	abstract = {Abstract Wind is widely recognized as one of the dominant controls of snow accumulation and distribution in exposed alpine regions. Complex and highly variable wind fields in rugged terrain lead to similarly complex snow distribution fields with areas of no snow adjacent to areas of deep accumulation. Unfortunately, these complexities have limited inclusion of wind redistribution effects in spatial snow distribution models. In this study the difficulties associated with physically exhaustive wind field modeling are avoided and terrain-based parameters are developed to characterize wind effects. One parameter, , was based on maximum upwind slopes relative to seasonally averaged winds to characterize the wind scalar at each pixel location in an alpine basin. A second parameter, , measured upwind breaks in slope from a given location and was combined with an upwind application of to create a drift delineator parameter, D0, which was used to delineate sites of intense redeposition on lee slopes. Based on 504 snow depth samples from a May 1999 survey of the upper Green Lakes Valley, Colorado, the correlation of the developed parameters to the observed snow distribution and the effect of their inclusion in a spatial snow distribution model were quantified. The parameter was found to be a significant predictor, accounting for more of the variance in the observed snow depth than could be explained by elevation, solar radiation, or slope. Samples located in D0-delineated drift zones were shown to have significantly greater depths than samples located in nondrift zones. A regression tree model of snow distribution based on a predictor variable set of , D0, elevation, solar radiation, and slope explained 8\%–23\% more variance in the observed snow distribution, and performed noticeably better in unsampled areas of the basin, compared to a regression tree model based on only the latter three predictors.},
	pages = {524--538},
	number = {5},
	journaltitle = {Journal of Hydrometeorology},
	author = {Winstral, Adam and Elder, Kelly and Davis, Robert E.},
	urldate = {2024-05-27},
	date = {2002-10-01},
}

@article{scheuerer_spatially_2014,
	title = {Spatially Adaptive Post-Processing of Ensemble Forecasts for Temperature},
	volume = {63},
	rights = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {0035-9254, 1467-9876},
	url = {https://academic.oup.com/jrsssc/article/63/3/405/7073229},
	doi = {10.1111/rssc.12040},
	abstract = {Summary 
            We propose a statistical post-processing method that yields locally calibrated probabilistic forecasts of temperature, based on the output of an ensemble prediction system. It represents the mean of the predictive distributions as a sum of short-term averages of local temperatures and ensemble prediction system driven terms. For the spatial interpolation of temperature averages and local forecast uncertainty parameters we use an intrinsic Gaussian random-field model with a location-dependent nugget effect that accounts for small-scale variability. Applied to the {COSMO}-{DE} ensemble, our method yields locally calibrated and sharp probabilistic forecasts and compares favourably with other approaches.},
	pages = {405--422},
	number = {3},
	journaltitle = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Scheuerer, Michael and Büermann, Luca},
	urldate = {2024-07-23},
	date = {2014-04-01},
	langid = {english},
	keywords = {post-processing, temperature},
}

@article{dai_spatially_2021,
	title = {Spatially Coherent Postprocessing of Cloud Cover Ensemble Forecasts},
	volume = {149},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/149/12/MWR-D-21-0046.1.xml},
	doi = {10.1175/MWR-D-21-0046.1},
	abstract = {Abstract Statistical postprocessing is commonly applied to reduce location and dispersion errors of probabilistic forecasts provided by numerical weather prediction ({NWP}) models. If postprocessed forecast scenarios are required, the combination of ensemble model output statistics ({EMOS}) for univariate postprocessing with ensemble copula coupling ({ECC}) or the Schaake shuffle ({ScS}) to retain the dependence structure of the raw ensemble is a state-of-the-art approach. However, modern machine learning methods may lead to both a better univariate skill and more realistic forecast scenarios. In this study, we postprocess multimodel ensemble forecasts of cloud cover over Switzerland provided by {COSMO}-E and {ECMWF}-{IFS} using (i) {EMOS} + {ECC}, (ii) {EMOS} + {ScS}, (iii) dense neural networks (dense {NN}) + {ECC}, (iv) dense {NN} + {ScS}, and (v) conditional generative adversarial networks ({cGAN}). The different methods are verified using {EUMETSAT} satellite data. Dense {NN} shows the best univariate skill, but {cGAN} performed only slightly worse. Furthermore, {cGAN} generates realistic forecast scenario maps, while not relying on a dependence template like {ECC} or {ScS}, which is particularly favorable in the case of complex topography.},
	pages = {3923--3937},
	number = {12},
	journaltitle = {Monthly Weather Review},
	author = {Dai, Y. and Hemri, S.},
	urldate = {2022-04-19},
	date = {2021-12},
}

@article{wang_st-transnet_2024,
	title = {{ST}-{TransNet}: A Spatiotemporal Transformer Network for Uncertainty Estimation from a Single Deterministic Precipitation Forecast},
	volume = {152},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/152/5/MWR-D-23-0097.1.xml},
	doi = {10.1175/MWR-D-23-0097.1},
	shorttitle = {{ST}-{TransNet}},
	abstract = {Abstract The forecast uncertainty, particularly for precipitation, serves as a crucial indicator of the reliability of deterministic forecasts. Traditionally, forecast uncertainty is estimated by ensemble forecasting, which is computationally expensive since the forecast model is run multiple times with perturbations. Recently, deep learning methods have been explored to learn the statistical properties of ensemble prediction systems due to their low computational costs. However, accurately and effectively capturing the uncertainty information in precipitation forecasts remains challenging. In this study, we present a novel spatiotemporal transformer network ({ST}-{TransNet}) as an alternative approach to estimate uncertainty with ensemble spread and probabilistic forecasts, by learning from historical ensemble forecasts. {ST}-{TransNet} features a hierarchical structure for extracting multiscale features and incorporates a spatiotemporal transformer module with window-based attention to capture correlations in both spatial and temporal dimensions. Additionally, window-based attention can not only extract local precipitation patterns but also reduce computational costs. The proposed {ST}-{TransNet} is evaluated on the {TIGGE} ensemble forecast dataset and Global Precipitation Measurement ({GPM}) precipitation products. Results show that {ST}-{TransNet} outperforms both traditional and deep learning methods across various metrics. Case studies further demonstrate its ability to generate reasonable and accurate spread and probability forecasts from a single deterministic precipitation forecast. It demonstrates the capacity and efficiency of neural networks in estimating precipitation forecast uncertainty.},
	pages = {1163--1178},
	number = {5},
	journaltitle = {Monthly Weather Review},
	author = {Wang, Jingnan and Wang, Xiaodong and Guan, Jiping and Zhang, Lifeng and Chang, Tao and Yu, Wei},
	urldate = {2024-05-22},
	date = {2024-05-15},
}

@article{dimitriadis_stable_2021,
	title = {Stable reliability diagrams for probabilistic classifiers},
	volume = {118},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.2016191118},
	doi = {10.1073/pnas.2016191118},
	abstract = {Significance 
            Probabilistic classifiers assign predictive probabilities to binary events, such as rainfall tomorrow, a recession, or a personal health outcome. Such a system is reliable or calibrated if the predictive probabilities are matched by the observed frequencies. In practice, calibration is assessed graphically in reliability diagrams and quantified via the reliability component of mean scores. Extant approaches rely on binning and counting and have been hampered by ad hoc implementation decisions, a lack of reproducibility, and inefficiency. Here, we introduce the {CORP} approach, which uses the pool-adjacent-violators algorithm to generate optimally binned, reproducible, and provably statistically consistent reliability diagrams, along with a numerical measure of miscalibration based on a revisited score decomposition. 
          ,  
            A probability forecast or probabilistic classifier is reliable or calibrated if the predicted probabilities are matched by ex post observed frequencies, as examined visually in reliability diagrams. The classical binning and counting approach to plotting reliability diagrams has been hampered by a lack of stability under unavoidable, ad hoc implementation decisions. Here, we introduce the {CORP} approach, which generates provably statistically consistent, optimally binned, and reproducible reliability diagrams in an automated way. {CORP} is based on nonparametric isotonic regression and implemented via the pool-adjacent-violators ({PAV}) algorithm—essentially, the {CORP} reliability diagram shows the graph of the {PAV}-(re)calibrated forecast probabilities. The {CORP} approach allows for uncertainty quantification via either resampling techniques or asymptotic theory, furnishes a numerical measure of miscalibration, and provides a {CORP}-based Brier-score decomposition that generalizes to any proper scoring rule. We anticipate that judicious uses of the {PAV} algorithm yield improved tools for diagnostics and inference for a very wide range of statistical and machine learning methods.},
	pages = {e2016191118},
	number = {8},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
	author = {Dimitriadis, Timo and Gneiting, Tilmann and Jordan, Alexander I.},
	urldate = {2024-06-24},
	date = {2021-02-23},
	langid = {english},
}

@book{wilks_statistical_2019,
	title = {Statistical Methods in the Atmospheric Sciences},
	isbn = {9780128158234},
	url = {https://linkinghub.elsevier.com/retrieve/pii/C20170039216},
	publisher = {Elsevier},
	author = {Wilks, D S},
	urldate = {2024-05-13},
	date = {2019},
	langid = {english},
	doi = {10.1016/C2017-0-03921-6},
}

@book{wilks_statistical_2019-1,
	title = {Statistical Methods in the Atmospheric Sciences},
	isbn = {9780128158234},
	url = {https://linkinghub.elsevier.com/retrieve/pii/C20170039216},
	publisher = {Elsevier},
	author = {Wilks, Daniel S.},
	urldate = {2024-06-19},
	date = {2019},
	langid = {english},
	doi = {10.1016/C2017-0-03921-6},
	keywords = {post-processing},
}

@article{bouallegue_statistical_2023,
	title = {Statistical Modeling of 2-m Temperature and 10-m Wind Speed Forecast Errors},
	volume = {151},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/151/4/MWR-D-22-0107.1.xml},
	doi = {10.1175/MWR-D-22-0107.1},
	abstract = {Abstract Based on the principle “learn from past errors to correct current forecasts,” statistical postprocessing consists of optimizing forecasts generated by numerical weather prediction ({NWP}) models. In this context, machine learning ({ML}) offers state-of-the-art tools for training statistical models and making predictions based on large datasets. In our study, {ML}-based solutions are developed to reduce forecast errors of 2-m temperature and 10-m wind speed of the {ECMWF}’s operational medium-range, high-resolution forecasts produced with the Integrated Forecasting System ({IFS}). {IFS} forecasts and other spatiotemporal indicators are used as predictors after careful selection with the help of {ML} interpretability tools. Different {ML} approaches are tested: linear regression, random forest decision trees, and neural networks. Statistical models of systematic and random errors are derived sequentially where the random error is defined as the residual error after bias correction. In terms of output, bias correction and forecast uncertainty prediction are made available at any point from locations around the world. All three {ML} methods show a similar ability to capture situation-dependent biases leading to noteworthy performance improvements (between 10\% and 15\% improvement in terms of root-mean-square error for all lead times and variables), and a similar ability to provide reliable uncertainty predictions.},
	pages = {897--911},
	number = {4},
	journaltitle = {Monthly Weather Review},
	author = {Bouallègue, Zied Ben and Cooper, Fenwick and Chantry, Matthew and Düben, Peter and Bechtold, Peter and Sandu, Irina},
	urldate = {2024-05-22},
	date = {2023-03-30},
	keywords = {post-processing, temperature, wind},
}

@article{nousu_statistical_2019,
	title = {Statistical post-processing of ensemble forecasts of the height of new snow},
	volume = {26},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/26/339/2019/},
	doi = {10.5194/npg-26-339-2019},
	abstract = {Forecasting the height of new snow ({HN}) is crucial for avalanche hazard forecasting, road viability, ski resort management and tourism attractiveness. Météo-France operates the {PEARP}-S2M probabilistic forecasting system, including 35 members of the {PEARP} Numerical Weather Prediction system, where the {SAFRAN} downscaling tool refines the elevation resolution and the Crocus snowpack model represents the main physical processes in the snowpack. It provides better {HN} forecasts than direct {NWP} diagnostics but exhibits significant biases and underdispersion. We applied a statistical post-processing to these ensemble forecasts, based on non-homogeneous regression with a censored shifted Gamma distribution. Observations come from manual measurements of 24\&thinsp;h {HN} in the French Alps and Pyrenees. The calibration is tested at the station scale and the massif scale (i.e. aggregating different stations over areas of 1000\&thinsp;km2). Compared to the raw forecasts, similar improvements are obtained for both spatial scales. Therefore, the post-processing can be applied at any point of the massifs. Two training datasets are tested: (1) a 22-year homogeneous reforecast for which the {NWP} model resolution and physical options are identical to the operational system but without the same initial perturbations; (2) 3-year real-time forecasts with a heterogeneous model configuration but the same perturbation methods. The impact of the training dataset depends on lead time and on the evaluation criteria. The long-term reforecast improves the reliability of severe snowfall but leads to overdispersion due to the discrepancy in real-time perturbations. Thus, the development of reliable automatic forecasting products of {HN} needs long reforecasts as homogeneous as possible with the operational systems.},
	pages = {339--357},
	number = {3},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Nousu, Jari-Pekka and Lafaysse, Matthieu and Vernay, Matthieu and Bellier, Joseph and Evin, Guillaume and Joly, Bruno},
	urldate = {2024-05-22},
	date = {2019-09-26},
}

@article{baran_statistical_2023,
	title = {Statistical post‐processing of visibility ensemble forecasts},
	volume = {30},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.2157},
	doi = {10.1002/met.2157},
	abstract = {Abstract 
            To be able to produce accurate and reliable predictions of visibility has crucial importance in aviation meteorology, as well as in water‐ and road transportation. Nowadays, several meteorological services provide ensemble forecasts of visibility; however, the skill and reliability of visibility predictions are far reduced compared with other variables, such as temperature or wind speed. Hence, some form of calibration is strongly advised, which usually means estimation of the predictive distribution of the weather quantity at hand either by parametric or nonparametric approaches, including machine learning‐based techniques. As visibility observations—according to the suggestion of the World Meteorological Organization—are usually reported in discrete values, the predictive distribution for this particular variable is a discrete probability law, hence calibration can be reduced to a classification problem. Based on visibility ensemble forecasts of the European Centre for Medium‐Range Weather Forecasts covering two slightly overlapping domains in Central and Western Europe and two different time periods, we investigate the predictive performance of locally, semi‐locally and regionally trained proportional odds logistic regression ({POLR}) and multilayer perceptron ({MLP}) neural network classifiers. We show that while climatological forecasts outperform the raw ensemble by a wide margin, post‐processing results in further substantial improvement in forecast skill, and in general, {POLR} models are superior to their {MLP} counterparts.},
	pages = {e2157},
	number = {5},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Baran, Sándor and Lakatos, Mária},
	urldate = {2024-03-29},
	date = {2023-09},
	langid = {english},
	keywords = {ensemble prediction, post-processing},
}

@article{vannitsem_statistical_2021,
	title = {Statistical Postprocessing for Weather Forecasts: Review, Challenges, and Avenues in a Big Data World},
	volume = {102},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/102/3/BAMS-D-19-0308.1.xml},
	doi = {10.1175/BAMS-D-19-0308.1},
	shorttitle = {Statistical Postprocessing for Weather Forecasts},
	abstract = {Abstract Statistical postprocessing techniques are nowadays key components of the forecasting suites in many national meteorological services ({NMS}), with, for most of them, the objective of correcting the impact of different types of errors on the forecasts. The final aim is to provide optimal, automated, seamless forecasts for end users. Many techniques are now flourishing in the statistical, meteorological, climatological, hydrological, and engineering communities. The methods range in complexity from simple bias corrections to very sophisticated distribution-adjusting techniques that incorporate correlations among the prognostic variables. The paper is an attempt to summarize the main activities going on in this area from theoretical developments to operational applications, with a focus on the current challenges and potential avenues in the field. Among these challenges is the shift in {NMS} toward running ensemble numerical weather prediction ({NWP}) systems at the kilometer scale that produce very large datasets and require high-density high-quality observations, the necessity to preserve space–time correlation of high-dimensional corrected fields, the need to reduce the impact of model changes affecting the parameters of the corrections, the necessity for techniques to merge different types of forecasts and ensembles with different behaviors, and finally the ability to transfer research on statistical postprocessing to operations. Potential new avenues are also discussed.},
	pages = {E681--E699},
	number = {3},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Vannitsem, Stéphane and Bremnes, John Bjørnar and Demaeyer, Jonathan and Evans, Gavin R. and Flowerdew, Jonathan and Hemri, Stephan and Lerch, Sebastian and Roberts, Nigel and Theis, Susanne and Atencia, Aitor and Bouallègue, Zied Ben and Bhend, Jonas and Dabernig, Markus and Cruz, Lesley De and Hieta, Leila and Mestre, Olivier and Moret, Lionel and Plenković, Iris Odak and Schmeits, Maurice and Taillardat, Maxime and Bergh, Joris Van den and Schaeybroeck, Bert Van and Whan, Kirien and Ylhaisi, Jussi},
	urldate = {2024-02-26},
	date = {2021-04},
	keywords = {post-processing},
}

@book{vannitsem_statistical_2018,
	title = {Statistical Postprocessing of Ensemble Forecasts},
	isbn = {9780128123720},
	url = {https://linkinghub.elsevier.com/retrieve/pii/C20160032448},
	publisher = {Elsevier},
	author = {Vannitsem, Stéphane and Wilks, Daniel S. and Messner, Jakob W.},
	urldate = {2024-06-19},
	date = {2018},
	langid = {english},
	doi = {10.1016/C2016-0-03244-8},
	keywords = {post-processing},
}

@article{hess_statistical_2020,
	title = {Statistical postprocessing of ensemble forecasts for severe weather at Deutscher Wetterdienst},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/473/2020/},
	doi = {10.5194/npg-27-473-2020},
	abstract = {This paper gives an overview of Deutscher Wetterdienst's ({DWD}'s) postprocessing system called Ensemble-{MOS} together with its motivation and the design consequences for probabilistic forecasts of extreme events based on ensemble data. Forecasts of the ensemble systems {COSMO}-D2-{EPS} and {ECMWF}-{ENS} are statistically optimised and calibrated by Ensemble-{MOS} with a focus on severe weather in order to support the warning decision management at {DWD}.

 Ensemble mean and spread are used as predictors for linear and logistic multiple regressions to correct for conditional biases. The predictands are derived from synoptic observations and include temperature, precipitation amounts, wind gusts and many more and are statistically estimated in a comprehensive model output statistics ({MOS}) approach. Long time series and collections of stations are used as training data that capture a sufficient number of observed events, as required for robust statistical modelling.

 Logistic regressions are applied to probabilities that predefined meteorological events occur. Details of the implementation including the selection of predictors with testing for significance are presented. For probabilities of severe wind gusts global logistic parameterisations are developed that depend on local estimations of wind speed. In this way, robust probability forecasts for extreme events are obtained while local characteristics are preserved.

 The problems of Ensemble-{MOS}, such as model changes and consistency requirements, which occur with the operative {MOS} systems of the {DWD} are addressed.},
	pages = {473--487},
	number = {4},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Hess, Reinhold},
	urldate = {2024-05-22},
	date = {2020-10-06},
}

@thesis{schulz_statistical_2023,
	title = {Statistical Postprocessing of Numerical Weather Prediction Forecasts using Machine Learning},
	url = {https://publikationen.bibliothek.kit.edu/1000158905},
	abstract = {Nowadays, weather prediction is based on numerical models of the physics of the atmosphere. These models are usually run multiple times based on randomly perturbed initial conditions. The resulting so-called ensemble forecasts represent distinct scenarios of the future and provide probabilistic projections. However, these forecasts are subject to systematic errors such as biases and they are often unable to quantify the forecast uncertainty adequately. Statistical postprocessing methods aim to exploit structure in past pairs of forecasts and observations to correct these errors when applied to future forecasts. In this thesis, we develop statistical postprocessing methods based on the central paradigm of probabilistic forecasting, that is, to maximize the sharpness subject to calibration. A wide range of statistical and machine learning methods is presented with a focus on novel neural network-based postprocessing techniques. In particular, we analyze the aggregation of distributional forecasts from neural network ensembles and develop statistical postprocessing methods for ensemble forecasts of wind gusts, with a focus on European winter storms.},
	type = {phdthesis},
	author = {Schulz, Benedikt},
	urldate = {2024-05-22},
	date = {2023},
	langid = {german},
	doi = {10.5445/IR/1000158905},
}

@article{veldkamp_statistical_2021,
	title = {Statistical Postprocessing of Wind Speed Forecasts Using Convolutional Neural Networks},
	volume = {149},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/149/4/MWR-D-20-0219.1.xml},
	doi = {10.1175/MWR-D-20-0219.1},
	abstract = {Abstract Current statistical postprocessing methods for probabilistic weather forecasting are not capable of using full spatial patterns from the numerical weather prediction ({NWP}) model. In this paper, we incorporate spatial wind speed information by using convolutional neural networks ({CNNs}) and obtain probabilistic wind speed forecasts in the Netherlands for 48 h ahead, based on {KNMI}’s deterministic {HARMONIE}-{AROME} {NWP} model. The probabilistic forecasts from the {CNNs} are shown to have higher Brier skill scores for medium to higher wind speeds, as well as a better continuous ranked probability score ({CRPS}) and logarithmic score, than the forecasts from fully connected neural networks and quantile regression forests. As a secondary result, we have compared the {CNNs} using three different density estimation methods [quantized softmax ({QS}), kernel mixture networks, and fitting a truncated normal distribution], and found the probabilistic forecasts based on the {QS} method to be best.},
	pages = {1141--1152},
	number = {4},
	journaltitle = {Monthly Weather Review},
	author = {Veldkamp, Simon and Whan, Kirien and Dirksen, Sjoerd and Schmeits, Maurice},
	urldate = {2024-06-25},
	date = {2021-04-01},
	keywords = {convolutional neural network, post-processing, wind},
}

@misc{saleem_stc-vit_2024,
	title = {{STC}-{ViT}: Spatio Temporal Continuous Vision Transformer for Weather Forecasting},
	url = {http://arxiv.org/abs/2402.17966},
	doi = {10.48550/arXiv.2402.17966},
	shorttitle = {{STC}-{ViT}},
	abstract = {Operational weather forecasting system relies on computationally expensive physics-based models. Recently, transformer based models have shown remarkable potential in weather forecasting achieving state-of-the-art results. However, transformers are discrete models which limit their ability to learn the continuous spatio-temporal features of the dynamical weather system. We address this issue with {STC}-{ViT}, a Spatio-Temporal Continuous Vision Transformer for weather forecasting. {STC}-{ViT} incorporates the continuous time Neural {ODE} layers with multi-head attention mechanism to learn the continuous weather evolution over time. The attention mechanism is encoded as a differentiable function in the transformer architecture to model the complex weather dynamics. We evaluate {STC}-{ViT} against a operational Numerical Weather Prediction ({NWP}) model and several deep learning based weather forecasting models. {STC}-{ViT} performs competitively with current data-driven methods in global forecasting while only being trained at lower resolution data and with less compute power.},
	number = {{arXiv}:2402.17966},
	publisher = {{arXiv}},
	author = {Saleem, Hira and Salim, Flora and Purcell, Cormac},
	urldate = {2024-06-06},
	date = {2024-05-23},
	eprinttype = {arxiv},
	eprint = {2402.17966 [cs]},
	keywords = {data-driven weather prediction},
}

@article{gneiting_strictly_2007,
	title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
	rights = {© American Statistical Association},
	url = {https://www.tandfonline.com/doi/abs/10.1198/016214506000001437},
	doi = {10.1198/016214506000001437},
	abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is prope...},
	journaltitle = {Journal of the American Statistical Association},
	author = {Gneiting, Tilmann and Raftery, Adrian E.},
	urldate = {2024-05-25},
	date = {2007-03-01},
	note = {Publisher: Taylor \& Francis},
	keywords = {scoring rules, verification},
}

@misc{molder_sustainable_2021,
	title = {Sustainable data analysis with Snakemake},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	url = {https://f1000research.com/articles/10-33},
	doi = {10.12688/f1000research.29032.2},
	abstract = {Data analysis often entails a multitude of heterogeneous steps, from the application of various command line tools to the usage of scripting languages like R or Python for the generation of plots and tables. It is widely recognized that data analyses should ideally be conducted in a reproducible way.\&nbsp;Reproducibility enables technical validation and regeneration of results on the original or even new data. However, reproducibility alone is by no means sufficient to deliver an analysis that is of lasting impact (i.e., sustainable) for the field, or even just one research group. We postulate that it is equally important to ensure adaptability and transparency. The former describes the ability to modify the analysis to answer extended or slightly different research questions. The latter describes the ability to understand the analysis in order to judge whether it is not only technically, but methodologically valid. Here, we analyze the properties needed for a data analysis to become reproducible, adaptable, and transparent. We show how the popular workflow management system Snakemake can be used to guarantee this, and how it enables an ergonomic, combined, unified representation of all steps involved in data analysis, ranging from raw data processing, to quality control and fine-grained, interactive exploration and plotting of final results.},
	number = {10:33},
	publisher = {F1000Research},
	author = {Mölder, Felix and Jablonski, Kim Philipp and Letcher, Brice and Hall, Michael B. and Tomkins-Tinch, Christopher H. and Sochat, Vanessa and Forster, Jan and Lee, Soohyun and Twardziok, Sven O. and Kanitz, Alexander and Wilm, Andreas and Holtgrewe, Manuel and Rahmann, Sven and Nahnsen, Sven and Köster, Johannes},
	urldate = {2024-07-13},
	date = {2021-04-19},
	langid = {english},
	keywords = {adaptability, data analysis, reproducibility, scalability, sustainability, transparency, workflow management},
}

@article{riccio_technical_2024,
	title = {Technical note: Accurate, reliable, and high-resolution air quality predictions by improving the Copernicus Atmosphere Monitoring Service using a novel statistical post-processing method},
	volume = {24},
	issn = {1680-7316},
	url = {https://acp.copernicus.org/articles/24/1673/2024/},
	doi = {10.5194/acp-24-1673-2024},
	shorttitle = {Technical note},
	abstract = {Starting from the regional air quality forecasts produced by the Copernicus Atmosphere Monitoring Service ({CAMS}), we propose a novel post-processing approach to improve and downscale results on a finer scale. Our approach is based on the combination of ensemble model output statistics ({EMOS}) with a spatio-temporal interpolation process performed through the stochastic partial differential equation–integrated nested laplace approximation ({SPDE}-{INLA}). Our interpolation approach includes several spatial and spatio-temporal predictors, including meteorological variables. A use case is provided that scales down the {CAMS} forecasts on the Italian peninsula. The calibration is focused on the concentrations of several air quality pollutants ({PM}10, {PM}2.5, {NO}2, and O3) at a daily resolution from a set of 750 monitoring sites, distributed throughout the Italian country. Our results show the key role that conditioning variables play in improving the forecast capabilities of ensemble predictions, thus allowing for a net improvement in the calibration with respect to ordinary {EMOS} strategies. From a deterministic point of view, the performance of the predictive model shows a significant improvement in the performance of the raw ensemble forecast, with an almost-zero bias, significantly reduced root mean square errors, and correlations that are almost always higher than 0.9 for each pollutant; moreover, the post-processing approach is able to significantly improve the prediction of exceedances, even for very low thresholds, such as those recently recommended by the World Health Organisation. This is particularly significant if a forecasting approach is used to predict air quality conditions and plan adequate human health protection measures, even for low alert thresholds. From a probabilistic point of view, the quality of the forecast was verified in terms of reliability and credible intervals. After post-processing, the predictive probability density functions were sharp and much better calibrated than the raw ensemble forecast. Finally, we present some additional results based on a set of gridded (4 km × 4 km) maps covering the entire Italian country for the detection of areas where pollution peaks occur (exceedances of the current and/or proposed regulatory thresholds).},
	pages = {1673--1689},
	number = {3},
	journaltitle = {Atmospheric Chemistry and Physics},
	author = {Riccio, Angelo and Chianese, Elena},
	urldate = {2024-05-22},
	date = {2024-02-06},
}

@article{roebber_complex_1996,
	title = {The Complex Relationship between Forecast Skill and Forecast Value: A Real-World Analysis},
	volume = {11},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/11/4/1520-0434_1996_011_0544_tcrbfs_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1996)011<0544:TCRBFS>2.0.CO;2},
	shorttitle = {The Complex Relationship between Forecast Skill and Forecast Value},
	abstract = {For routine forecasts of temperature and precipitation, the relative skill advantage of human forecasters with respect to the numerical–statistical guidance is small (and diminishing). Since the relationship between forecast skill and the value of those forecasts is complex, the authors have examined their value across a range of real-world user contexts. It is found that although in most cases the meteorological information possessed considerable value to the users, human intervention in making those forecasts (as measured by National Weather Service forecasts) has generally led to minimal gains in value beyond that which is obtainable through direct use of numerical–statistical guidance. An important exception is the use of meteorological information by gas utilities during peak wintertime periods; in those circumstances, the value of human intervention was considerable. The presence of information in the National Weather Service forecasts independent of that contained in the numerical–statistical guidance was also established. Despite this, application of the additional information through a combined National Weather Service/guidance forecast provided only a small gain in value in most cases. In the most successful forecast context (the gas utility), the combined approach led to a loss of value relative to the unaltered National Weather Service forecasts. However, recent trends toward increased skill in probability of precipitation forecasts have led to some gains in the relative value of the National Weather Service forecasts, concurrent with a shift toward smaller optimal cost–loss ratio distributions, findings that are significant with respect to practical business considerations. Furthermore, all of the applications studied showed the potential for considerable further growth in forecast value with continued increases in forecast skill. The relevance of our findings to the future of public and private meteorological forecasting is briefly discussed.},
	pages = {544--559},
	number = {4},
	journaltitle = {Weather and Forecasting},
	author = {Roebber, Paul J. and Bosart, Lance F.},
	urldate = {2024-06-11},
	date = {1996-12-01},
	note = {Publisher: American Meteorological Society
Section: Weather and Forecasting},
	keywords = {weather and climate services},
}

@article{palmer_economic_2002,
	title = {The economic value of ensemble forecasts as a tool for risk assessment: From days to decades},
	volume = {128},
	issn = {0035-9009, 1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1256/0035900021643593},
	doi = {10.1256/0035900021643593},
	shorttitle = {The economic value of ensemble forecasts as a tool for risk assessment},
	abstract = {Abstract 
            Despite the revolutionary development of numerical weather and climate prediction ({NWCP}) in the second half of the last century, quantitative interaction between model developers and forecast customers has been rather limited. This is apparent in the diverse ways in which weather forecasts are assessed by these two groups: root‐mean‐square error of 500 {hPa} height on the one hand; pounds, euros or dollars saved on the other. 
            These differences of approach are changing with the development of ensemble forecasting. Ensemble forecasts provide a qualitative tool for the assessment of weather and climate risk for a range of user applications, and on a range of time‐scales, from days to decades. Examples of the commercial application of ensemble forecasting, from electricity generation, ship routeing, pollution modelling, weather‐risk finance, disease prediction and crop yield modelling, are shown from all these time‐scales. 
            A generic user decision model is described that allows one to assess the potential economic value of numerical weather and climate forecasts for a range of customers. Using this, it is possible to relate analytically, potential economic value to conventional meteorological skill scores. A generalized meteorological measure of forecast skill is proposed which takes the distribution of customers into account. It is suggested that when customers' exposure to weather or climate risk can be quantified, such more generalized measures of skill should be used in assessing the performance of an operational {NWCP} system. Copyright © 2002 Royal Meteorological Society.},
	pages = {747--774},
	number = {581},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	shortjournal = {Quart J Royal Meteoro Soc},
	author = {Palmer, T. N.},
	urldate = {2024-03-29},
	date = {2002-04},
	langid = {english},
	keywords = {economic value, weather and climate services},
}

@article{zhu_economic_2002,
	title = {The economic value of ensemble-based weather forecasts},
	volume = {83},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/83/1/1520-0477_2002_083_0073_tevoeb_2_3_co_2.xml},
	doi = {10.1175/1520-0477(2002)083<0073:TEVOEB>2.3.CO;2},
	abstract = {The potential economic benefit associated with the use of an ensemble of forecasts versus an equivalent or higher-resolution control forecast is discussed. Neither forecast systems are postprocessed, except a simple calibration that is applied to make them reliable. A simple decision-making model is used where all potential users of weather forecasts are characterized by the ratio between the cost of their action to prevent weather-related damages, and the loss that they incur in case they do not protect their operations. It is shown that the ensemble forecast system can be used by a much wider range of users. Furthermore, for many, and for beyond 4-day lead time for all users, the ensemble provides greater potential economic benefit than a control forecast, even if the latter is run at higher horizontal resolution. It is argued that the added benefits derive from 1) the fact that the ensemble provides a more detailed forecast probability distribution, allowing the users to tailor their weather forecast–related actions to their particular cost–loss situation, and 2) the ensemble's ability to differentiate between high-and low-predictability cases. While single forecasts can statistically be supplemented by more detailed probability distributions, it is not clear whether with more sophisticated postprocessing they can identify more and less predictable forecast cases as successfully as ensembles do.},
	pages = {73--84},
	number = {1},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Zhu, Yuejian and Toth, Zoltan and Wobus, Richard and Richardson, David and Mylne, Kenneth},
	urldate = {2024-06-11},
	date = {2002-01-01},
	langid = {english},
	note = {Publisher: American Meteorological Society
Section: Bulletin of the American Meteorological Society},
	keywords = {weather and climate services},
}

@article{lee_economic_2007,
	title = {The economic value of weather forecasts for decision‐making problems in the profit/loss situation},
	volume = {14},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.44},
	doi = {10.1002/met.44},
	abstract = {Abstract 
            This article presents a method to estimate the economic value of forecasts for profit‐oriented enterprise decision‐making problems related to the levels of preparations for goods or services. The sales of goods or services in the study are supposed to be influenced and predicted by meteorological variables. Value is calculated in terms of monetary profit (or benefit) returned from the user's decision under the specific payoff structure, which is represented by a profit/loss ratio model. The decision is determined as a function of the user's subjective reliability of forecasts and forecast probability. The resulting value score ({VS}) curve shows the scaled economic values relative to the value of a perfect forecast, specified by a function of the profit/loss ratios for different decision makers. The proposed evaluation method, based on the profit/loss ratio model and the {VS}, is illustrated using hypothetical sets of forecasts, and later verified by applying site‐specific probability and deterministic forecasts, each of which is generated from the Korea and China Meteorological Administrations ({KMA} and {CMA}). The application results show that decision makers with high subjective reliability of forecasts can receive great benefits from a given forecast, and there are ranges of profit/loss ratios in which each of the forecast sources used for the evaluation is preferred. Copyright © 2007 Royal Meteorological Society},
	pages = {455--463},
	number = {4},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Lee, Ki‐Kwang and Lee, Joong‐Woo},
	urldate = {2024-03-29},
	date = {2007-12},
	langid = {english},
	keywords = {economic value, weather and climate services},
}

@article{demaeyer_euppbench_2023,
	title = {The {EUPPBench} postprocessing benchmark dataset v1.0},
	volume = {15},
	issn = {1866-3508},
	url = {https://essd.copernicus.org/articles/15/2635/2023/},
	doi = {10.5194/essd-15-2635-2023},
	abstract = {Statistical postprocessing of medium-range weather forecasts is an important component of modern forecasting systems. Since the beginning of modern data science, numerous new postprocessing methods have been proposed, complementing an already very diverse field. However, one of the questions that frequently arises when considering different methods in the framework of implementing operational postprocessing is the relative performance of the methods for a given specific task. It is particularly challenging to find or construct a common comprehensive dataset that can be used to perform such comparisons. Here, we introduce the first version of {EUPPBench} ({EUMETNET} postprocessing benchmark), a dataset of time-aligned forecasts and observations, with the aim to facilitate and standardize this process. This dataset is publicly available at https://github.com/{EUPP}-benchmark/climetlab-eumetnet-postprocessing-benchmark (31 December 2022) and on Zenodo (https://doi.org/10.5281/zenodo.7429236, Demaeyer, 2022b and https://doi.org/10.5281/zenodo.7708362, Bhend et al., 2023). We provide examples showing how to download and use the data, we propose a set of evaluation methods, and we perform a first benchmark of several methods for the correction of 2 m temperature forecasts.},
	pages = {2635--2653},
	number = {6},
	journaltitle = {Earth System Science Data},
	author = {Demaeyer, Jonathan and Bhend, Jonas and Lerch, Sebastian and Primo, Cristina and Van Schaeybroeck, Bert and Atencia, Aitor and Ben Bouallègue, Zied and Chen, Jieyu and Dabernig, Markus and Evans, Gavin and Faganeli Pucer, Jana and Hooper, Ben and Horat, Nina and Jobst, David and Merše, Janko and Mlakar, Peter and Möller, Annette and Mestre, Olivier and Taillardat, Maxime and Vannitsem, Stéphane},
	urldate = {2024-05-22},
	date = {2023-06-28},
	keywords = {post-processing},
}

@article{buizza_forecast_2015,
	title = {The forecast skill horizon},
	volume = {141},
	rights = {© 2015 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.2619},
	doi = {10.1002/qj.2619},
	abstract = {Numerical weather prediction has seen, in the past 25 years, a shift from a ‘deterministic’ approach, based on single numerical integrations, to a probabilistic one, with ensembles of numerical integrations used to estimate the probability distribution function of forecast states. This shift to a probabilistic approach enabled a better extraction of predictive signals at longer lead times and provided a meaningful framework for extending the forecast length beyond 10 days. In this work, the limit of predictive skill is assessed for {ECMWF} monthly ensemble forecasts at different spatial and temporal scales. The forecast skill horizon is defined as the lead time when the ensemble ceases to be more skilful than a climatological distribution, using a continuous ranked probability score as metric. Results based on 32-day ensemble forecasts indicate that the forecast skill horizon is sensitive to the spatial and temporal scale of the predicted phenomena, to the variable considered and the area analysed. On average over 1 year of forecasts, the forecast skill horizon for instantaneous, grid-point fields is between 16 and 23 days, while it is considerably longer for time- and spatial-average fields. Forecast skill horizons longer than the 2 weeks that were thought to be the limit are now achievable thanks to major advances in numerical weather prediction. More specifically, they are possible because forecasts are now framed in probabilistic terms, with a probability distribution estimated using ensembles generated using forecast models that include more components (e.g. a dynamical ocean and ocean waves) and more faithfully represent processes. Moreover, the forecasts start from more accurate initial conditions constructed using better data-assimilation methods and more observational data.},
	pages = {3366--3382},
	number = {693},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	author = {Buizza, Roberto and Leutbecher, Martin},
	urldate = {2024-05-10},
	date = {2015},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.2619},
	keywords = {ensemble prediction, extended-range prediction, predictability},
}

@article{sweeney_future_2020,
	title = {The future of forecasting for renewable energy},
	volume = {9},
	issn = {2041-8396, 2041-840X},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/wene.365},
	doi = {10.1002/wene.365},
	abstract = {Abstract 
            Forecasting for wind and solar renewable energy is becoming more important as the amount of energy generated from these sources increases. Forecast skill is improving, but so too is the way forecasts are being used. In this paper, we present a brief overview of the state‐of‐the‐art of forecasting wind and solar energy. We describe approaches in statistical and physical modeling for time scales from minutes to days ahead, for both deterministic and probabilistic forecasting. Our focus changes then to consider the future of forecasting for renewable energy. We discuss recent advances which show potential for great improvement in forecast skill. Beyond the forecast itself, we consider new products which will be required to aid decision making subject to risk constraints. Future forecast products will need to include probabilistic information, but deliver it in a way tailored to the end user and their specific decision making problems. Businesses operating in this sector may see a change in business models as more people compete in this space, with different combinations of skills, data and modeling being required for different products. The transaction of data itself may change with the adoption of blockchain technology, which could allow providers and end users to interact in a trusted, yet decentralized way. Finally, we discuss new industry requirements and challenges for scenarios with high amounts of renewable energy. New forecasting products have the potential to model the impact of renewables on the power system, and aid dispatch tools in guaranteeing system security. 
             
              This article is categorized under: 
               
                 
                  Energy Infrastructure {\textgreater} Systems and Infrastructure 
                 
                 
                  Wind Power {\textgreater} Systems and Infrastructure 
                 
                 
                  Photovoltaics {\textgreater} Systems and Infrastructure},
	pages = {e365},
	number = {2},
	journaltitle = {{WIREs} Energy and Environment},
	shortjournal = {{WIREs} Energy \& Environment},
	author = {Sweeney, Conor and Bessa, Ricardo J. and Browell, Jethro and Pinson, Pierre},
	urldate = {2024-03-29},
	date = {2020-03},
	langid = {english},
	keywords = {energy meteorology, weather and climate services},
}

@article{thorpe_global_2022,
	title = {The global weather enterprise, part 1: the jigsaw pieces},
	volume = {77},
	rights = {© 2022 Royal Meteorological Society.},
	issn = {1477-8696},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wea.4261},
	doi = {10.1002/wea.4261},
	shorttitle = {The global weather enterprise, part 1},
	abstract = {In this series of three articles, the global endeavour by a wide range of organisations and a large number of individuals to create high-quality weather and climate information is presented. In part 1, the elements that make up the global weather enterprise are described; in part 2, the way in which the information is produced via global co-operation is outlined and in part 3, the future outlook is considered.},
	pages = {349--351},
	number = {10},
	journaltitle = {Weather},
	author = {Thorpe, Alan},
	urldate = {2024-05-13},
	date = {2022-10},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wea.4261},
	keywords = {economic value, weather and climate services},
}

@article{thorpe_global_2023,
	title = {The global weather enterprise, part 3: an evolving picture},
	volume = {78},
	rights = {© 2022 Royal Meteorological Society.},
	issn = {1477-8696},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wea.4347},
	doi = {10.1002/wea.4347},
	shorttitle = {The global weather enterprise, part 3},
	abstract = {In this series of three articles, the global endeavour by a wide range of organisations and many individuals to create high-quality weather and climate information is presented. In part 1, the elements that make up the global weather enterprise are described, in part 2, the way in which the information is produced via global co-operation is outlined and in part 3, the outlook is considered. [Correction after first publication 20 December 2022: the text was edited to remove reference to a previous image.]},
	pages = {74--78},
	number = {3},
	journaltitle = {Weather},
	author = {Thorpe, Alan},
	urldate = {2024-05-13},
	date = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wea.4347},
	keywords = {economic value, weather and climate services},
}

@article{haiden_integrated_2011,
	title = {The Integrated Nowcasting through Comprehensive Analysis ({INCA}) System and Its Validation over the Eastern Alpine Region},
	volume = {26},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/26/2/2010waf2222451_1.xml},
	doi = {10.1175/2010WAF2222451.1},
	abstract = {Abstract This paper presents the Integrated Nowcasting through Comprehensive Analysis ({INCA}) system, which has been developed for use in mountainous terrain. Analysis and nowcasting fields include temperature, humidity, wind, precipitation amount, precipitation type, cloudiness, and global radiation. The analysis part of the system combines surface station data with remote sensing data in such a way that the observations at the station locations are reproduced, whereas the remote sensing data provide the spatial structure for the interpolation. The nowcasting part employs classical correlation-based motion vectors derived from previous consecutive analyses. In the case of precipitation the nowcast includes an intensity-dependent elevation effect. After 2–6 h of forecast time the nowcast is merged into an {NWP} forecast provided by a limited-area model, using a predefined temporal weighting function. Cross validation of the analysis and verification of the nowcast are performed. Analysis quality is high for temperature, but comparatively low for wind and precipitation, because of the limited representativeness of station data in mountainous terrain, which can be only partially compensated by the analysis algorithm. Significant added value of the system compared to the {NWP} forecast is found in the first few hours of the nowcast. At longer lead times the effects of the latest observations becomes small, but in the case of temperature the downscaling of the {NWP} forecast within the {INCA} system continues to provide some improvement compared to the direct {NWP} output.},
	pages = {166--183},
	number = {2},
	journaltitle = {Weather and Forecasting},
	author = {Haiden, T. and Kann, A. and Wittmann, C. and Pistotnik, G. and Bica, B. and Gruber, C.},
	urldate = {2024-07-21},
	date = {2011-04-01},
}

@article{hoskins_potential_2013,
	title = {The potential for skill across the range of the seamless weather-climate prediction problem: a stimulus for our science},
	volume = {139},
	rights = {Copyright © 2012 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qj.1991},
	doi = {10.1002/qj.1991},
	shorttitle = {The potential for skill across the range of the seamless weather-climate prediction problem},
	abstract = {Predictability is considered in the context of the seamless weather-climate prediction problem, and the notion is developed that there can be predictive power on all time-scales. On all scales there are phenomena that occur as well as longer time-scales and external conditions that should combine to give some predictability. To what extent this theoretical predictability may actually be realised and, further, to what extent it may be useful is not clear. However the potential should provide a stimulus to, and high profile for, our science and its application for many years. Copyright © 2012 Royal Meteorological Society},
	pages = {573--584},
	number = {672},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	author = {Hoskins, Brian},
	urldate = {2024-05-10},
	date = {2013},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/qj.1991},
	keywords = {predictability},
}

@article{bauer_quiet_2015,
	title = {The quiet revolution of numerical weather prediction},
	volume = {525},
	rights = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14956},
	doi = {10.1038/nature14956},
	abstract = {Advances in numerical weather prediction represent a quiet revolution because they have resulted from a steady accumulation of scientific knowledge and technological advances over many years that, with only a few exceptions, have not been associated with the aura of fundamental physics breakthroughs. Nonetheless, the impact of numerical weather prediction is among the greatest of any area of physical science. As a computational problem, global weather prediction is comparable to the simulation of the human brain and of the evolution of the early Universe, and it is performed every day at major operational centres across the world.},
	pages = {47--55},
	number = {7567},
	journaltitle = {Nature},
	author = {Bauer, Peter and Thorpe, Alan and Brunet, Gilbert},
	urldate = {2021-10-19},
	date = {2015-09},
	langid = {english},
	keywords = {numerical weather prediction, review},
}

@article{greybush_regime_2008,
	title = {The Regime Dependence of Optimally Weighted Ensemble Model Consensus Forecasts of Surface Temperature},
	volume = {23},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/23/6/2008waf2007078_1.xml},
	doi = {10.1175/2008WAF2007078.1},
	abstract = {Abstract Previous methods for creating consensus forecasts weight individual ensemble members based upon their relative performance over the previous N days, implicitly making a short-term persistence assumption about the underlying flow regime. A postprocessing scheme in which model performance is linked to underlying weather regimes could improve the skill of deterministic ensemble model consensus forecasts. Here, principal component analysis of several synoptic- and mesoscale fields from the North American Regional Reanalysis dataset provides an objective means for characterizing atmospheric regimes. Clustering techniques, including K-means and a genetic algorithm, are developed that use the resulting principal components to distinguish among the weather regimes. This pilot study creates a weighted consensus from 48-h surface temperature predictions produced by the University of Washington Mesoscale Ensemble, a varied-model (differing physics and parameterization schemes) multianalysis ensemble with eight members. Different optimal weights are generated for each weather regime. A second regime-dependent consensus technique uses linear regression to predict the relative performance of the ensemble members based upon the principal components. Consensus forecasts obtained by the regime-dependent schemes are compared using cross validation with traditional N-day ensemble consensus forecasts for four locations in the Pacific Northwest, and show improvement over methods that rely on the short-term persistence assumption.},
	pages = {1146--1161},
	number = {6},
	journaltitle = {Weather and Forecasting},
	author = {Greybush, Steven J. and Haupt, Sue Ellen and Young, George S.},
	urldate = {2024-05-22},
	date = {2008-12-01},
}

@article{lawrence_relationship_2005,
	title = {The Relationship between Relative Humidity and the Dewpoint Temperature in Moist Air: A Simple Conversion and Applications},
	volume = {86},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/86/2/bams-86-2-225.xml},
	doi = {10.1175/BAMS-86-2-225},
	shorttitle = {The Relationship between Relative Humidity and the Dewpoint Temperature in Moist Air},
	abstract = {The relative humidity ({RH}) and the dewpoint temperature (td) are two widely used indicators of the amount of moisture in air. The exact conversion from {RH} to td, as well as highly accurate approximations, are too complex to be done easily without the help of a calculator or computer. However, there is a very simple rule of thumb that can be very useful for approximating the conversion for moist air ({RH} {\textgreater} 50\%), which does not appear to be widely known by the meteorological community: td decreases by about 1°C for every 5\% decrease in {RH} (starting at td= t, the dry bulb temperature, when {RH} = 100\%). This article examines the mathematical basis and accuracy of this and other relationships between the dewpoint and relative humidity. Several useful applications of the simple conversion are presented, in particular the computation of the cumulus cloud-base level (or lifting condensation level) as {zLCL} {\textgreater}{\textgreater} (20 + t/5)(100 – {RH}), where {zLCL} is in meters when t is in degrees Celcius and {RH} in percent. Finally, a historical perspective is given with anecdotes about some of the early work in this field.},
	pages = {225--234},
	number = {2},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Lawrence, Mark G.},
	urldate = {2024-07-13},
	date = {2005-02-01},
	langid = {english},
}

@misc{ben-bouallegue_rise_2023,
	title = {The rise of data-driven weather forecasting},
	url = {http://arxiv.org/abs/2307.10128},
	doi = {10.48550/arXiv.2307.10128},
	abstract = {Data-driven modeling based on machine learning ({ML}) is showing enormous potential for weather forecasting. Rapid progress has been made with impressive results for some applications. The uptake of {ML} methods could be a game-changer for the incremental progress in traditional numerical weather prediction ({NWP}) known as the 'quiet revolution' of weather forecasting. The computational cost of running a forecast with standard {NWP} systems greatly hinders the improvements that can be made from increasing model resolution and ensemble sizes. An emerging new generation of {ML} models, developed using high-quality reanalysis datasets like {ERA}5 for training, allow forecasts that require much lower computational costs and that are highly-competitive in terms of accuracy. Here, we compare for the first time {ML}-generated forecasts with standard {NWP}-based forecasts in an operational-like context, initialized from the same initial conditions. Focusing on deterministic forecasts, we apply common forecast verification tools to assess to what extent a data-driven forecast produced with one of the recently developed {ML} models ({PanguWeather}) matches the quality and attributes of a forecast from one of the leading global {NWP} systems (the {ECMWF} {IFS}). The results are very promising, with comparable skill for both global metrics and extreme events, when verified against both the operational analysis and synoptic observations. Increasing forecast smoothness and bias drift with forecast lead time are identified as current drawbacks of {ML}-based forecasts. A new {NWP} paradigm is emerging relying on inference from {ML} models and state-of-the-art analysis and reanalysis datasets for forecast initialization and model training.},
	number = {{arXiv}:2307.10128},
	publisher = {{arXiv}},
	author = {Ben-Bouallegue, Zied and Clare, Mariana C. A. and Magnusson, Linus and Gascon, Estibaliz and Maier-Gerber, Michael and Janousek, Martin and Rodwell, Mark and Pinault, Florian and Dramsch, Jesper S. and Lang, Simon T. K. and Raoult, Baudouin and Rabier, Florence and Chevallier, Matthieu and Sandu, Irina and Dueben, Peter and Chantry, Matthew and Pappenberger, Florian},
	urldate = {2024-06-05},
	date = {2023-11-03},
	eprinttype = {arxiv},
	eprint = {2307.10128 [physics]},
	keywords = {data-driven weather prediction},
}

@article{bouallegue_rise_2024,
	title = {The rise of data-driven weather forecasting: A first statistical assessment of machine learning-based weather forecasts in an operational-like context},
	volume = {-1},
	issn = {0003-0007, 1520-0477},
	url = {https://journals.ametsoc.org/view/journals/bams/aop/BAMS-D-23-0162.1/BAMS-D-23-0162.1.xml},
	doi = {10.1175/BAMS-D-23-0162.1},
	shorttitle = {The rise of data-driven weather forecasting},
	abstract = {Abstract Data-driven modeling based on machine learning ({ML}) is showing enormous potential for weather forecasting. Rapid progress has been made with impressive results for some applications. The uptake of {ML} methods could be a game-changer for the incremental progress in traditional numerical weather prediction ({NWP}) known as the “quiet revolution” of weather forecasting. The computational cost of running a forecast with standard {NWP} systems greatly hinders the improvements that can be made from increasing model resolution and ensemble sizes. An emerging new generation of {ML} models, developed using high-quality reanalysis datasets like {ERA}5 for training, allow forecasts that require much lower computational costs and that are highly-competitive in terms of accuracy. Here, we compare for the first time {ML}-generated forecasts with standard {NWP}-based forecasts in an operational-like context, initialized from the same initial conditions. Focusing on deterministic forecasts, we apply common forecast verification tools to assess to what extent a data-driven forecast produced with one of the recently developed {ML} models ({PanguWeather}) matches the quality and attributes of a forecast from one of the leading global {NWP} systems (the {ECMWF} {IFS}). The results are very promising, with comparable accuracy for both global metrics and extreme events, when verified against both the operational {IFS} analysis and synoptic observations. Overly smooth forecasts, increasing bias with forecast lead time, and poor performance in predicting tropical cyclone intensity are identified as current drawbacks of {ML}-based forecasts. A new {NWP} paradigm is emerging relying on inference from {ML} models and state-of-the-art analysis and reanalysis datasets for forecast initialization and model training.},
	issue = {aop},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Bouallègue, Zied Ben and Clare, Mariana C. A. and Magnusson, Linus and Gascón, Estibaliz and Maier-Gerber, Michael and Janoušek, Martin and Rodwell, Mark and Pinault, Florian and Dramsch, Jesper S. and Lang, Simon T. K. and Raoult, Baudouin and Rabier, Florence and Chevallier, Matthieu and Sandu, Irina and Dueben, Peter and Chantry, Matthew and Pappenberger, Florian},
	urldate = {2024-05-24},
	date = {2024-02-29},
	keywords = {data-driven weather prediction},
}

@article{clark_schaake_2004,
	title = {The Schaake Shuffle: A Method for Reconstructing Space–Time Variability in Forecasted Precipitation and Temperature Fields},
	volume = {5},
	issn = {1525-7541, 1525-755X},
	url = {https://journals.ametsoc.org/view/journals/hydr/5/1/1525-7541_2004_005_0243_tssamf_2_0_co_2.xml},
	doi = {10.1175/1525-7541(2004)005<0243:TSSAMF>2.0.CO;2},
	shorttitle = {The Schaake Shuffle},
	abstract = {Abstract A number of statistical methods that are used to provide local-scale ensemble forecasts of precipitation and temperature do not contain realistic spatial covariability between neighboring stations or realistic temporal persistence for subsequent forecast lead times. To demonstrate this point, output from a global-scale numerical weather prediction model is used in a stepwise multiple linear regression approach to downscale precipitation and temperature to individual stations located in and around four study basins in the United States. Output from the forecast model is downscaled for lead times up to 14 days. Residuals in the regression equation are modeled stochastically to provide 100 ensemble forecasts. The precipitation and temperature ensembles from this approach have a poor representation of the spatial variability and temporal persistence. The spatial correlations for downscaled output are considerably lower than observed spatial correlations at short forecast lead times (e.g., less than 5 days) when there is high accuracy in the forecasts. At longer forecast lead times, the downscaled spatial correlations are close to zero. Similarly, the observed temporal persistence is only partly present at short forecast lead times. A method is presented for reordering the ensemble output in order to recover the space–time variability in precipitation and temperature fields. In this approach, the ensemble members for a given forecast day are ranked and matched with the rank of precipitation and temperature data from days randomly selected from similar dates in the historical record. The ensembles are then reordered to correspond to the original order of the selection of historical data. Using this approach, the observed intersite correlations, intervariable correlations, and the observed temporal persistence are almost entirely recovered. This reordering methodology also has applications for recovering the space–time variability in modeled streamflow.},
	pages = {243--262},
	number = {1},
	journaltitle = {Journal of Hydrometeorology},
	author = {Clark, Martyn and Gangopadhyay, Subhrendu and Hay, Lauren and Rajagopalan, Balaji and Wilby, Robert},
	urldate = {2024-05-27},
	date = {2004-02-01},
}

@article{glahn_use_1972,
	title = {The Use of Model Output Statistics ({MOS}) in Objective Weather Forecasting},
	volume = {11},
	url = {https://journals.ametsoc.org/view/journals/apme/11/8/1520-0450_1972_011_1203_tuomos_2_0_co_2.xml},
	doi = {10.1175/1520-0450(1972)011<1203:TUOMOS>2.0.CO;2},
	pages = {1203 -- 1211},
	number = {8},
	journaltitle = {Journal of Applied Meteorology and Climatology},
	author = {Glahn, Harry R. and Lowry, Dale A.},
	date = {1972},
	note = {Place: Boston {MA}, {USA}
Publisher: American Meteorological Society},
}

@misc{jobst_time_2024,
	title = {Time Series based Ensemble Model Output Statistics for Temperature Forecasts Postprocessing},
	url = {http://arxiv.org/abs/2402.00555},
	doi = {10.48550/arXiv.2402.00555},
	abstract = {Nowadays, weather prediction is based on numerical weather prediction ({NWP}) models to produce an ensemble of forecasts. Despite of large improvements over the last few decades, they still tend to exhibit systematic bias and dispersion errors. Consequently, these forecasts may be improved by statistical postprocessing. This work proposes an extension of the ensemble model output statistics ({EMOS}) method in a time series framework. Besides of taking account of seasonality and trend in the location and scale parameter of the predictive distribution, the autoregressive process in the mean forecast errors or the standardized forecast errors is considered. The models can be further extended by allowing generalized autoregressive conditional heteroscedasticity ({GARCH}). Last but not least, it is outlined how to use these models for arbitrary forecast horizons. To illustrate the performance of the suggested {EMOS} models in time series fashion, we present a case study for the postprocessing of 2 m surface temperature forecasts using five different lead times and a set of observation stations in Germany. The results indicate that the time series {EMOS} extensions are able to significantly outperform the benchmark {EMOS} and autoregressive adjusted {EMOS} ({AR}-{EMOS}) in most of the lead time-station cases. To complement this article, our method is accompanied by an R-package called {tsEMOS}.},
	number = {{arXiv}:2402.00555},
	publisher = {{arXiv}},
	author = {Jobst, David and Möller, Annette and Groß, Jürgen},
	urldate = {2024-07-23},
	date = {2024-02-01},
	eprinttype = {arxiv},
	eprint = {2402.00555 [stat]},
	keywords = {post-processing, temperature},
}

@article{scher_toward_2018,
	title = {Toward Data‐Driven Weather and Climate Forecasting: Approximating a Simple General Circulation Model With Deep Learning},
	volume = {45},
	issn = {0094-8276, 1944-8007},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2018GL080704},
	doi = {10.1029/2018GL080704},
	shorttitle = {Toward Data‐Driven Weather and Climate Forecasting},
	abstract = {Abstract 
            It is shown that it is possible to emulate the dynamics of a simple general circulation model with a deep neural network. After being trained on the model, the network can predict the complete model state several time steps ahead—which conceptually is making weather forecasts in the model world. Additionally, after being initialized with an arbitrary model state, the network can through repeatedly feeding back its predictions into its inputs create a climate run, which has similar climate statistics to the climate of the general circulation model. This network climate run shows no long‐term drift, even though no conservation properties were explicitly designed into the network. 
          ,  
            Plain Language Summary 
             
              Numerical weather prediction and climate models are complex computer programs that represent the physics of the atmosphere. They are essential tools for predicting the weather and for studying the Earth's climate. Recently, a lot of progress has been made in machine learning methods. These are data‐driven algorithms that learn from existing data. We show that it is possible that such an algorithm 
              learns 
              the dynamics of a simple climate model. After being presented with enough data from the climate model, the network can successfully predict the time evolution of the model's state, thus replacing the dynamics of the model. This finding is an important step toward purely 
              data‐driven 
              weather forecasting—thus weather forecasting without the use of traditional numerical models and also opens up new possibilities for climate modeling. 
             
          ,  
            Key Points 
             
               
                 
                  A neural network can emulate the dynamics of a simple general circulation model 
                 
                 
                  The trained network can successfully forecast the model weather 
                 
                 
                  The network can produce a realistic representation of the model climate},
	number = {22},
	journaltitle = {Geophysical Research Letters},
	shortjournal = {Geophysical Research Letters},
	author = {Scher, S.},
	urldate = {2024-06-06},
	date = {2018-11-28},
	langid = {english},
	keywords = {data-driven weather prediction},
}

@article{haupt_towards_2021,
	title = {Towards implementing artificial intelligence post-processing in weather and climate: proposed actions from the Oxford 2019 workshop},
	volume = {379},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2020.0091},
	doi = {10.1098/rsta.2020.0091},
	shorttitle = {Towards implementing artificial intelligence post-processing in weather and climate},
	abstract = {The most mature aspect of applying artificial intelligence ({AI})/machine learning ({ML}) to problems in the atmospheric sciences is likely post-processing of model output. This article provides some history and current state of the science of post-processing with {AI} for weather and climate models. Deriving from the discussion at the 2019 Oxford workshop on Machine Learning for Weather and Climate, this paper also presents thoughts on medium-term goals to advance such use of {AI}, which include assuring that algorithms are trustworthy and interpretable, adherence to {FAIR} data practices to promote usability, and development of techniques that leverage our physical knowledge of the atmosphere. The coauthors propose several actionable items and have initiated one of those: a repository for datasets from various real weather and climate problems that can be addressed using {AI}. Five such datasets are presented and permanently archived, together with Jupyter notebooks to process them and assess the results in comparison with a baseline technique. The coauthors invite the readers to test their own algorithms in comparison with the baseline and to archive their results.
            This article is part of the theme issue ‘Machine learning for weather and climate modelling’.},
	pages = {20200091},
	number = {2194},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Phil. Trans. R. Soc. A.},
	author = {Haupt, Sue Ellen and Chapman, William and Adams, Samantha V. and Kirkwood, Charlie and Hosking, J. Scott and Robinson, Niall H. and Lerch, Sebastian and Subramanian, Aneesh C.},
	urldate = {2022-05-09},
	date = {2021-04-05},
	langid = {english},
	keywords = {artificial intelligence, climate, machine learning, post-processing},
}

@article{bojinski_towards_2023,
	title = {Towards nowcasting in Europe in 2030},
	volume = {30},
	issn = {1350-4827, 1469-8080},
	url = {https://rmets.onlinelibrary.wiley.com/doi/10.1002/met.2124},
	doi = {10.1002/met.2124},
	abstract = {Abstract 
            The increasing impact of severe weather over Europe on lives and weather‐sensitive economies can be mitigated by accurate 0–6 h forecasts (nowcasts), supporting a vital ‘last line of defence’ for civil protection and many other applications. Recognizing lack of skill in some complex situations, often at convective and local sub‐kilometre scales and associated with rare events, we identify seven recommendations with the aim to improve nowcasting in Europe by the national meteorological and hydrological services ({NMHSs}) by 2030. These recommendations are based on a review of user needs, the state of the observing system, techniques based on observations and high‐resolution numerical weather models, as well as tools, data and infrastructure supporting the nowcasting community in Europe. Denser and more accurate observations are necessary particularly in the boundary layer to better characterize the ingredients of severe storms. A key driver for improvement is next‐generation European satellite data becoming available as of 2023. Seamless ensemble prediction methods to produce enhanced weather forecasts with 0–24 h lead times and probabilistic products require further development. Such products need to be understood and interpreted by skilled forecasters operating in an evolving forecasting context. We argue that stronger co‐development and collaboration between providers and users of nowcasting‐relevant data and information are key ingredients for progress. We recommend establishing pan‐European nowcasting consortia, better exchange of data, common development platforms and common verification approaches as key elements for progressing nowcasting in Europe in this decade.},
	pages = {e2124},
	number = {4},
	journaltitle = {Meteorological Applications},
	shortjournal = {Meteorological Applications},
	author = {Bojinski, Stephan and Blaauboer, Dick and Calbet, Xavier and De Coning, Estelle and Debie, Frans and Montmerle, Thibaut and Nietosvaara, Vesa and Norman, Katie and Bañón Peregrín, Luis and Schmid, Franziska and Strelec Mahović, Nataša and Wapler, Kathrin},
	urldate = {2024-03-29},
	date = {2023-07},
	langid = {english},
	keywords = {nowcasting},
}

@inproceedings{beucler_towards_2020,
	title = {Towards Physically-Consistent, Data-Driven Models of Convection},
	doi = {10.1109/IGARSS39084.2020.9324569},
	abstract = {Data-driven algorithms, in particular neural networks, can emulate the effect of sub-grid scale processes in coarse-resolution climate models if trained on high-resolution climate simulations. However, they may violate key physical constraints and lack the ability to generalize outside of their training set. Here, we show that physical constraints can be enforced in neural networks, either approximately by adapting the loss function or to within machine precision by adapting the architecture. As these physical constraints are insufficient to guarantee generalizability, we additionally propose to physically rescale the training and validation data to improve the ability of neural networks to generalize to unseen climates. Code-github.com/theucler/{CBRAIN}-{CAM}.},
	eventtitle = {{IGARSS} 2020 - 2020 {IEEE} International Geoscience and Remote Sensing Symposium},
	pages = {3987--3990},
	booktitle = {{IGARSS} 2020 - 2020 {IEEE} International Geoscience and Remote Sensing Symposium},
	author = {Beucler, Tom and Pritchard, Michael and Gentine, Pierre and Rasp, Stephan},
	date = {2020-09},
	note = {{ISSN}: 2153-7003},
}

@article{christianson_traditional_2023,
	title = {Traditional kriging versus modern Gaussian processes for large‐scale mining data},
	volume = {16},
	issn = {1932-1864, 1932-1872},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/sam.11635},
	doi = {10.1002/sam.11635},
	abstract = {Abstract 
            The canonical technique for nonlinear modeling of spatial/point‐referenced data is known as kriging in geostatistics, and as Gaussian Process ({GP}) regression for surrogate modeling and statistical learning. This article reviews many similarities shared between kriging and {GPs}, but also highlights some important differences. One is that {GPs} impose a process that can be used to automate kernel/variogram inference, thus removing the human from the loop. The {GP} framework also suggests a probabilistically valid means of scaling to handle a large corpus of training data, that is, an alternative to ordinary kriging. Finally, recent {GP} implementations are tailored to make the most of modern computing architectures, such as multi‐core workstations and multi‐node supercomputers. We argue that such distinctions are important even in classically geostatistical settings. To back that up, we present out‐of‐sample validation exercises using two, real, large‐scale borehole data sets acquired in the mining of gold and other minerals. We compare classic kriging with several variations of modern {GPs} and conclude that the latter is more economical (fewer human and compute resources), more accurate and offers better uncertainty quantification. We go on to show how the fully generative modeling apparatus provided by {GPs} can gracefully accommodate left‐censoring of small measurements, as commonly occurs in mining data and other borehole assays.},
	pages = {488--506},
	number = {5},
	journaltitle = {Statistical Analysis and Data Mining: The {ASA} Data Science Journal},
	shortjournal = {Statistical Analysis},
	author = {Christianson, Ryan B. and Pollyea, Ryan M. and Gramacy, Robert B.},
	urldate = {2024-05-27},
	date = {2023-10},
	langid = {english},
	keywords = {geostatistics},
}

@misc{maronas_transforming_2021,
	title = {Transforming Gaussian Processes With Normalizing Flows},
	url = {http://arxiv.org/abs/2011.01596},
	doi = {10.48550/arXiv.2011.01596},
	abstract = {Gaussian Processes ({GPs}) can be used as flexible, non-parametric function priors. Inspired by the growing body of work on Normalizing Flows, we enlarge this class of priors through a parametric invertible transformation that can be made input-dependent. Doing so also allows us to encode interpretable prior knowledge (e.g., boundedness constraints). We derive a variational approximation to the resulting Bayesian inference problem, which is as fast as stochastic variational {GP} regression (Hensman et al., 2013; Dezfouli and Bonilla,2015). This makes the model a computationally efficient alternative to other hierarchical extensions of {GP} priors (Lazaro-Gredilla,2012; Damianou and Lawrence, 2013). The resulting algorithm's computational and inferential performance is excellent, and we demonstrate this on a range of data sets. For example, even with only 5 inducing points and an input-dependent flow, our method is consistently competitive with a standard sparse {GP} fitted using 100 inducing points.},
	number = {{arXiv}:2011.01596},
	publisher = {{arXiv}},
	author = {Maroñas, Juan and Hamelijnck, Oliver and Knoblauch, Jeremias and Damoulas, Theodoros},
	urldate = {2024-05-27},
	date = {2021-02-25},
	eprinttype = {arxiv},
	eprint = {2011.01596 [cs]},
	keywords = {gaussian processes},
}

@article{hemri_trends_2014,
	title = {Trends in the predictive performance of raw ensemble weather forecasts},
	volume = {41},
	issn = {0094-8276, 1944-8007},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1002/2014GL062472},
	doi = {10.1002/2014GL062472},
	abstract = {Abstract This study applies statistical postprocessing to ensemble forecasts of near‐surface temperature, 24 h precipitation totals, and near‐surface wind speed from the global model of the European Centre for Medium‐Range Weather Forecasts ({ECMWF}). The main objective is to evaluate the evolution of the difference in skill between the raw ensemble and the postprocessed forecasts. Reliability and sharpness, and hence skill, of the former is expected to improve over time. Thus, the gain by postprocessing is expected to decrease. Based on {ECMWF} forecasts from January 2002 to March 2014 and corresponding observations from globally distributed stations, we generate postprocessed forecasts by ensemble model output statistics ({EMOS}) for each station and variable. Given the higher average skill of the postprocessed forecasts, we analyze the evolution of the difference in skill between raw ensemble and {EMOS}. This skill gap remains almost constant over time indicating that postprocessing will keep adding skill in the foreseeable future. , Key Points Evolution of raw ensemble forecast skill Future benefits from statistical postprocessing Global distribution of forecast skill development},
	pages = {9197--9205},
	number = {24},
	journaltitle = {Geophysical Research Letters},
	author = {Hemri, S. and Scheuerer, M. and Pappenberger, F. and Bogner, K. and Haiden, T.},
	urldate = {2023-10-26},
	date = {2014-12},
	langid = {english},
	keywords = {post-processing, verification},
}

@misc{liaw_tune_2018,
	title = {Tune: A Research Platform for Distributed Model Selection and Training},
	url = {http://arxiv.org/abs/1807.05118},
	doi = {10.48550/arXiv.1807.05118},
	shorttitle = {Tune},
	abstract = {Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.},
	number = {{arXiv}:1807.05118},
	publisher = {{arXiv}},
	author = {Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E. and Stoica, Ion},
	urldate = {2024-07-13},
	date = {2018-07-13},
	eprinttype = {arxiv},
	eprint = {1807.05118 [cs, stat]},
	keywords = {software},
}

@article{lazo_us_2011,
	title = {U.S. Economic Sensitivity to Weather Variability},
	volume = {92},
	url = {https://journals.ametsoc.org/view/journals/bams/92/6/2011bams2928_1.xml},
	doi = {10.1175/2011BAMS2928.1},
	abstract = {To estimate the economic effects of weather variability in the United States, the authors define and measure weather sensitivity as the variability in economic output that is attributable to weather variability, accounting for changes in technology and changes in levels of economic inputs (i.e., capital, labor, and energy). Using 24 yr of economic data and weather observations, quantitative models of the relationship between state-level sectoral economic output and weather variability are developed for the 11 nongovernmental sectors of the U.S. economy; temperature and precipitation measures were used as proxies for all weather impacts. All 11 sectors are found to have statistically significant sensitivity to weather variability. Economic inputs were then constant and economic output was estimated in the 11 estimated sector models, varying the weather inputs only using 70 yr of historic weather observations. It was found that U.S. economic output varies by up to \$485 billion yr−1 of 2008 gross domestic product, about 3.4\%, owing to weather variability. U.S. states that are more sensitive to weather variability are identified and sectors are ranked by their degree of weather sensitivity. This work illustrates a valid approach to measuring the economic impact of weather variability, gives baseline information and methods for more detailed studies of the sensitivity of each sector to weather variability, and lays the groundwork for assessing the value of current or improved weather forecast information given the economic impacts of weather variability.},
	pages = {709--720},
	number = {6},
	journaltitle = {Bulletin of the American Meteorological Society},
	author = {Lazo, Jeffrey K. and Lawson, Megan and Larsen, Peter H. and Waldman, Donald M.},
	urldate = {2024-03-29},
	date = {2011-06-01},
	keywords = {economic value, weather and climate services},
}

@book{olafsson_uncertainties_2021,
	location = {Amsterdam Oxford Cambridge},
	title = {Uncertainties in numerical weather prediction},
	isbn = {978-0-12-815491-5},
	abstract = {"Uncertainties in Numerical Weather Prediction is a comprehensive work on the most current understandings of uncertainties and predictability in numerical simulations of the atmosphere. It provides general knowledge on all aspects of uncertainties in the weather prediction models in a single, easy to use reference. The book illustrates particular uncertainties in observations and data assimilation, as well as the errors associated with numerical integration methods. Stochastic methods in parameterization of subgrid processes are also assessed, as are uncertainties associated with surface-atmosphere exchange, orographic flows and processes in the atmospheric boundary layer"--},
	pagetotal = {351},
	publisher = {Elsevier},
	author = {Ólafsson, Haraldur and Bao, Jian-Wen},
	date = {2021},
}

@article{slingo_uncertainty_2011,
	title = {Uncertainty in weather and climate prediction},
	volume = {369},
	issn = {1364-503X, 1471-2962},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0161},
	doi = {10.1098/rsta.2011.0161},
	abstract = {Following Lorenz's seminal work on chaos theory in the 1960s, probabilistic approaches to prediction have come to dominate the science of weather and climate forecasting. This paper gives a perspective on Lorenz's work and how it has influenced the ways in which we seek to represent uncertainty in forecasts on all lead times from hours to decades. It looks at how model uncertainty has been represented in probabilistic prediction systems and considers the challenges posed by a changing climate. Finally, the paper considers how the uncertainty in projections of climate change can be addressed to deliver more reliable and confident assessments that support decision-making on adaptation and mitigation.},
	pages = {4751--4767},
	number = {1956},
	journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Phil. Trans. R. Soc. A.},
	author = {Slingo, Julia and Palmer, Tim},
	urldate = {2024-03-25},
	date = {2011-12-13},
	langid = {english},
	keywords = {uncertainty},
}

@misc{bulte_uncertainty_2024,
	title = {Uncertainty quantification for data-driven weather models},
	url = {http://arxiv.org/abs/2403.13458},
	doi = {10.48550/arXiv.2403.13458},
	abstract = {Artificial intelligence ({AI})-based data-driven weather forecasting models have experienced rapid progress over the last years. Recent studies, with models trained on reanalysis data, achieve impressive results and demonstrate substantial improvements over state-of-the-art physics-based numerical weather prediction models across a range of variables and evaluation metrics. Beyond improved predictions, the main advantages of data-driven weather models are their substantially lower computational costs and the faster generation of forecasts, once a model has been trained. However, most efforts in data-driven weather forecasting have been limited to deterministic, point-valued predictions, making it impossible to quantify forecast uncertainties, which is crucial in research and for optimal decision making in applications. Our overarching aim is to systematically study and compare uncertainty quantification methods to generate probabilistic weather forecasts from a state-of-the-art deterministic data-driven weather model, Pangu-Weather. Specifically, we compare approaches for quantifying forecast uncertainty based on generating ensemble forecasts via perturbations to the initial conditions, with the use of statistical and machine learning methods for post-hoc uncertainty quantification. In a case study on medium-range forecasts of selected weather variables over Europe, the probabilistic forecasts obtained by using the Pangu-Weather model in concert with uncertainty quantification methods show promising results and provide improvements over ensemble forecasts from the physics-based ensemble weather model of the European Centre for Medium-Range Weather Forecasts for lead times of up to 5 days.},
	number = {{arXiv}:2403.13458},
	publisher = {{arXiv}},
	author = {Bülte, Christopher and Horat, Nina and Quinting, Julian and Lerch, Sebastian},
	urldate = {2024-05-22},
	date = {2024-03-20},
	eprinttype = {arxiv},
	eprint = {2403.13458 [physics, stat]},
	keywords = {uncertainty},
}

@article{schefzik_uncertainty_2013,
	title = {Uncertainty Quantification in Complex Simulation Models Using Ensemble Copula Coupling},
	volume = {28},
	issn = {0883-4237, 2168-8745},
	url = {https://projecteuclid.org/journals/statistical-science/volume-28/issue-4/Uncertainty-Quantification-in-Complex-Simulation-Models-Using-Ensemble-Copula-Coupling/10.1214/13-STS443.full},
	doi = {10.1214/13-STS443},
	abstract = {Critical decisions frequently rely on high-dimensional output from complex computer simulation models that show intricate cross-variable, spatial and temporal dependence structures, with weather and climate predictions being key examples. There is a strongly increasing recognition of the need for uncertainty quantification in such settings, for which we propose and review a general multi-stage procedure called ensemble copula coupling ({ECC}), proceeding as follows: 1. Generate a raw ensemble, consisting of multiple runs of the computer model that differ in the inputs or model parameters in suitable ways. 2. Apply statistical postprocessing techniques, such as Bayesian model averaging or nonhomogeneous regression, to correct for systematic errors in the raw ensemble, to obtain calibrated and sharp predictive distributions for each univariate output variable individually. 3. Draw a sample from each postprocessed predictive distribution. 4. Rearrange the sampled values in the rank order structure of the raw ensemble to obtain the {ECC} postprocessed ensemble. The use of ensembles and statistical postprocessing have become routine in weather forecasting over the past decade. We show that seemingly unrelated, recent advances can be interpreted, fused and consolidated within the framework of {ECC}, the common thread being the adoption of the empirical copula of the raw ensemble. Depending on the use of Quantiles, Random draws or Transformations at the sampling stage, we distinguish the {ECC}-Q, {ECC}-R and {ECC}-T variants, respectively. We also describe relations to the Schaake shuffle and extant copula-based techniques. In a case study, the {ECC} approach is applied to predictions of temperature, pressure, precipitation and wind over Germany, based on the 50-member European Centre for Medium-Range Weather Forecasts ({ECMWF}) ensemble.},
	pages = {616--640},
	number = {4},
	journaltitle = {Statistical Science},
	author = {Schefzik, Roman and Thorarinsdottir, Thordis L. and Gneiting, Tilmann},
	urldate = {2024-05-27},
	date = {2013-11},
	keywords = {ensemble prediction, multivariate prediction, numerical weather prediction},
}

@incollection{richner_understanding_2013,
	location = {Dordrecht},
	title = {Understanding and Forecasting Alpine Foehn},
	isbn = {9789400740983},
	url = {https://doi.org/10.1007/978-94-007-4098-3_4},
	abstract = {This chapter focuses on the history, physics, climatology, forecasting and the broad effects of Alpine foehn on human populations. In the European Alps, foehn winds have been studied since the mid-1800s. The main focus of the investigations was the question of why foehn winds are so warm. While it soon became clear that adiabatic processes provide an explanation, the role of wet adiabatic rising on the upwind side of the Alps continued to be strongly debated. The so-called textbook theory for foehn – heat gain by wet adiabatic, forced lifting on the upwind side followed by dry adiabatic descent in the lee – represents only an extreme situation. Foehn occurs also with partial or complete blocking of the upwind air mass, i.e., with limited or no heat gain by wet adiabatic expansion. The second focus is on processes which lead to descending air masses after passing the mountain ridge. A discussion of the most important processes shows that there seems to be no theory which is applicable in all situations. Forecasting foehn is still a challenge to meteorologists. While the general foehn situation can be predicted reliably, today’s numerical models still often poorly simulate the sudden break in of potentially devastating foehn air in the lee. Efforts to improve this must continue because foehn storms have a significant societal impact (threat to transportation systems and massive increase of fire danger) as several recent incidents show.},
	pages = {219--260},
	booktitle = {Mountain Weather Research and Forecasting: Recent Progress and Current Challenges},
	publisher = {Springer Netherlands},
	author = {Richner, Hans and Hächler, Patrick},
	editor = {Chow, Fotini K. and De Wekker, Stephan F.J. and Snyder, Bradley J.},
	urldate = {2024-07-23},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-94-007-4098-3_4},
}

@article{raftery_using_2005,
	title = {Using Bayesian Model Averaging to Calibrate Forecast Ensembles},
	volume = {133},
	issn = {1520-0493, 0027-0644},
	url = {https://journals.ametsoc.org/view/journals/mwre/133/5/mwr2906.1.xml},
	doi = {10.1175/MWR2906.1},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="{abstractTitle} text-title my-1" id="d1249e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Ensembles used for probabilistic weather forecasting often exhibit a spread-error correlation, but they tend to be underdispersive. This paper proposes a statistical method for postprocessing ensembles based on Bayesian model averaging ({BMA}), which is a standard method for combining predictive distributions from different sources. The {BMA} predictive probability density function ({PDF}) of any quantity of interest is a weighted average of {PDFs} centered on the individual bias-corrected forecasts, where the weights are equal to posterior probabilities of the models generating the forecasts and reflect the models' relative contributions to predictive skill over the training period. The {BMA} weights can be used to assess the usefulness of ensemble members, and this can be used as a basis for selecting ensemble members; this can be useful given the cost of running large ensembles. The {BMA} {PDF} can be represented as an unweighted ensemble of any desired size, by simulating from the {BMA} predictive distribution.{\textless}/p{\textgreater}{\textless}p{\textgreater}The {BMA} predictive variance can be decomposed into two components, one corresponding to the between-forecast variability, and the second to the within-forecast variability. Predictive {PDFs} or intervals based solely on the ensemble spread incorporate the first component but not the second. Thus {BMA} provides a theoretical explanation of the tendency of ensembles to exhibit a spread-error correlation but yet be underdispersive.{\textless}/p{\textgreater}{\textless}p{\textgreater}The method was applied to 48-h forecasts of surface temperature in the Pacific Northwest in January–June 2000 using the University of Washington fifth-generation Pennsylvania State University–{NCAR} Mesoscale Model ({MM}5) ensemble. The predictive {PDFs} were much better calibrated than the raw ensemble, and the {BMA} forecasts were sharp in that 90\% {BMA} prediction intervals were 66\% shorter on average than those produced by sample climatology. As a by-product, {BMA} yields a deterministic point forecast, and this had root-mean-square errors 7\% lower than the best of the ensemble members and 8\% lower than the ensemble mean. Similar results were obtained for forecasts of sea level pressure. Simulation experiments show that {BMA} performs reasonably well when the underlying ensemble is calibrated, or even overdispersed.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	pages = {1155--1174},
	number = {5},
	journaltitle = {Monthly Weather Review},
	author = {Raftery, Adrian E. and Gneiting, Tilmann and Balabdaoui, Fadoua and Polakowski, Michael},
	urldate = {2020-12-21},
	date = {2005-05-01},
	note = {Publisher: American Meteorological Society
Section: Monthly Weather Review},
}

@article{bernhardt_using_2009,
	title = {Using wind fields from a high‐resolution atmospheric model for simulating snow dynamics in mountainous terrain},
	volume = {23},
	rights = {http://onlinelibrary.wiley.com/{termsAndConditions}\#vor},
	issn = {0885-6087, 1099-1085},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/hyp.7208},
	doi = {10.1002/hyp.7208},
	abstract = {Abstract 
            Wind‐induced snow transport has remarkable effects on the snow cover spatial variability and on the temporal dynamics of snowmelt runoff. For accurate snow cover modelling, valid atmospheric forcing fields are essential. Since it is impossible to generate appropriate wind fields by a simple spatial interpolation of station data, a new approach was developed: A modified version of the Penn State University‐National Centre for Atmospheric Research ({MM}5) model was used to generate wind fields with 200‐m resolution. Because of the high computational costs of {MM}5, it was not practicable to include the wind field generation as an operational part of the snow cover modelling. Therefore, an archive consisting of 220 wind fields was generated prior to the simulation of the snow transport processes. These fields represent the most relevant synoptic situations for wind‐induced snow transport occurring at our test site. The criteria to generate which wind field to use in a specific snow model time step are mean wind speed and direction at the 700 {hPa} level derived from German Weather Service/Deutscher Wetterdienst ({DWD}) Lokalmodell ({LM}) analysis data. The wind field library provided physically derived wind speed and direction fields that were used to drive a snow transport model ({SnowTran}‐3D) in a high Alpine area in the Berchtesgaden National Park, Germany. In complex Alpine terrain, the procedure provides an alternative to simple interpolation methods, yielding improved physical realism at reasonable computational expense. Copyright © 2008 John Wiley \& Sons, Ltd.},
	pages = {1064--1075},
	number = {7},
	journaltitle = {Hydrological Processes},
	shortjournal = {Hydrological Processes},
	author = {Bernhardt, M. and Zängl, G. and Liston, G. E. and Strasser, U. and Mauser, W.},
	urldate = {2024-05-27},
	date = {2009-03-30},
	langid = {english},
	keywords = {wind},
}

@misc{ramavajjala_verification_2023,
	title = {Verification against in-situ observations for Data-Driven Weather Prediction},
	url = {http://arxiv.org/abs/2305.00048},
	doi = {10.48550/arXiv.2305.00048},
	abstract = {Data-driven weather prediction models ({DDWPs}) have made rapid strides in recent years, demonstrating an ability to approximate Numerical Weather Prediction ({NWP}) models to a high degree of accuracy. The fast, accurate, and low-cost {DDWP} forecasts make their use in operational forecasting an attractive proposition, however, there remains work to be done in rigorously evaluating {DDWPs} in a true operational setting. Typically trained and evaluated using {ERA}5 reanalysis data, {DDWPs} have been tested only in a simulation, which cannot represent the real world with complete accuracy even if it is of a very high quality. The safe use of {DDWPs} in operational forecasting requires more thorough "real-world" verification, as well as a careful examination of how {DDWPs} are currently trained and evaluated. It is worth asking, for instance, how well do the reanalysis datasets, used for training, simulate the real world? With an eye towards climate justice and the uneven availability of weather data: is the simulation equally good for all regions of the world, and would {DDWPs} exacerbate biases present in the training data? Does a good performance in simulation correspond to good performance in operational settings? In addition to approximating the physics of {NWP} models, how can {ML} be uniquely deployed to provide more accurate weather forecasts? As a first step towards answering such questions, we present a robust dataset of in-situ observations derived from the {NOAA} {MADIS} program to serve as a benchmark to validate {DDWPs} in an operational setting. By providing a large corpus of quality-controlled, in-situ observations, this dataset provides a meaningful real-world task that all {NWPs} and {DDWPs} can be tested against. We hope that this data can be used not only to rigorously and fairly compare operational weather models but also to spur future research in new directions.},
	number = {{arXiv}:2305.00048},
	publisher = {{arXiv}},
	author = {Ramavajjala, Vivek and Mitra, Peetak P.},
	urldate = {2024-05-29},
	date = {2023-09-05},
	eprinttype = {arxiv},
	eprint = {2305.00048 [physics]},
	keywords = {data-driven weather prediction, verification},
}

@article{steinheuer_vertical_2020,
	title = {Vertical profiles of wind gust statistics from a regional reanalysis using multivariate extreme value theory},
	volume = {27},
	issn = {1023-5809},
	url = {https://npg.copernicus.org/articles/27/239/2020/},
	doi = {10.5194/npg-27-239-2020},
	abstract = {Many applications require wind gust estimates at very different atmospheric height levels. For example, the renewable energy sector is interested in wind and gust predictions at the hub height of a wind power plant. However, numerical weather prediction models typically only derive estimates for wind gusts at the standard measurement height of 10\&thinsp;m above the land surface. Here, we present a statistical post-processing method to derive a conditional distribution for hourly peak wind speed as a function of height. The conditioning variables are taken from the {COSMO}-{REA}6 regional reanalysis. The post-processing method was trained using peak wind speed observations at five vertical levels between 10 and 250\&thinsp;m from the Hamburg Weather Mast. The statistical post-processing method is based on a censored generalized extreme value ({cGEV}) distribution with non-homogeneous parameters. We use a least absolute shrinkage and selection operator to select the most informative variables. Vertical variations of the {cGEV} parameters are approximated using Legendre polynomials, such that predictions may be derived at any desired vertical height. Further, the Pickands dependence function is used to assess dependencies between gusts at different heights. The most important predictors are the 10\&thinsp;m gust diagnostic, the barotropic and the baroclinic mode of absolute horizontal wind speed, the mean absolute horizontal wind at 700\&thinsp;{hPa}, the surface pressure tendency, and the lifted index. Proper scores show improvements of up to 60\&thinsp;\% with respect to climatology, especially at higher vertical levels. The post-processing model with a Legendre approximation is able to provide reliable predictions of gusts' statistics at non-observed intermediate levels. The strength of dependency between gusts at different levels is non-homogeneous and strongly modulated by the vertical stability of the atmosphere.},
	pages = {239--252},
	number = {2},
	journaltitle = {Nonlinear Processes in Geophysics},
	author = {Steinheuer, Julian and Friederichs, Petra},
	urldate = {2024-05-22},
	date = {2020-04-23},
}

@article{meenal_weather_2022,
	title = {Weather Forecasting for Renewable Energy System: A Review},
	volume = {29},
	issn = {1886-1784},
	url = {https://doi.org/10.1007/s11831-021-09695-3},
	doi = {10.1007/s11831-021-09695-3},
	shorttitle = {Weather Forecasting for Renewable Energy System},
	abstract = {Energy crisis and climate change are the major concerns which has led to a significant growth in the renewable energy resources which includes mainly the solar and wind power generation. In smart grid, there is a increase in the penetration level of solar {PV} and wind power generation. The solar radiation received at the earth surface is greatly dependent on various atmospheric parameters. Forecasting of solar radiation and photovoltaic power is a major concern in terms of efficient integration of solar {PV} plants in the power grid. There are significant challenges in smart grid energy management due to the variability of large-scale renewable energy generation. Renewable energy forecasting is critical to reduce the uncertainty related to renewable energy generation for a wide range of planning, investment and decision-making purposes. As renewable energy sources are highly intermittent and variable, all the forecasting models available in the literature contain errors. This paper presents an overview of current and new development of weather forecasting such as solar and wind forecasting techniques for renewable energy system in smart grid. Many forecasting models such as physical models, statistical models, artificial intelligence based models, machine learning and deep learning based models were discussed. It is observed that, despite having no clear understanding on atmospheric physics, the artificial intelligence based methods such as machine learning and deep learning method produces reasonable weather forecasting results.},
	pages = {2875--2891},
	number = {5},
	journaltitle = {Archives of Computational Methods in Engineering},
	shortjournal = {Arch Computat Methods Eng},
	author = {Meenal, R. and Binu, D. and Ramya, K. C. and Michael, Prawin Angel and Vinoth Kumar, K. and Rajasekaran, E. and Sangeetha, B.},
	urldate = {2024-03-29},
	date = {2022-08-01},
	langid = {english},
	keywords = {economic value, energy meteorology, weather and climate services},
}

@book{richardson_weather_1922,
	title = {Weather Prediction by Numerical Process},
	publisher = {University Press},
	author = {Richardson, Lewis Fry},
	date = {1922},
}

@incollection{coiffier_weather_2011,
	location = {Cambridge},
	title = {Weather prediction equations},
	isbn = {978-1-107-00103-9},
	url = {https://www.cambridge.org/core/books/fundamentals-of-numerical-weather-prediction/weather-prediction-equations/5C98FAEBE233505D8212CF9C2BDFF5D9},
	abstract = {{IntroductionThe} equations used to build the various types of model simulating the evolution of the atmosphere are obtained from the basic general equations by making a number of simplifications. These simplifications are justified by analysis of the order of magnitude of the various terms in the equations for the scales to be represented (see Table 1.1) and by the degree of simplification to be achieved so as to simulate the behaviour of the atmosphere.From the equations describing the behaviour of a nonviscous fluid (also known as the Euler equations), the traditional approximation in meteorology consists in approximating the atmosphere to a thin layer and leads to a system of nonhydrostatic equations that allows for the proper handling of mesoscale atmospheric motion in particular. The hydrostatic approximation consists in neglecting vertical acceleration and leads to what are called the primitive equations (as opposed to the filtered equations, which involve an additional hypothesis of balance between mass and wind fields and that were used to build the first operational numerical models). Although they do not allow convective motion to be simulated explicitly, the primitive equations are widely used both for weather forecasting models and for general atmospheric circulation models.},
	pages = {15--38},
	booktitle = {Fundamentals of Numerical Weather Prediction},
	publisher = {Cambridge University Press},
	editor = {Coiffier, Jean},
	urldate = {2024-05-25},
	date = {2011},
	doi = {10.1017/CBO9780511734458.006},
}

@report{weusthoff_weather_2011,
	title = {Weather Type Classification at {MeteoSwiss}},
	number = {235},
	institution = {Federal Office of Meteorology and Climatology {MeteoSwiss}},
	author = {Weusthoff, Tanja},
	date = {2011},
}

@misc{rasp_weatherbench_2024,
	title = {{WeatherBench} 2: A benchmark for the next generation of data-driven global weather models},
	url = {http://arxiv.org/abs/2308.15560},
	doi = {10.48550/arXiv.2308.15560},
	shorttitle = {{WeatherBench} 2},
	abstract = {{WeatherBench} 2 is an update to the global, medium-range (1-14 day) weather forecasting benchmark proposed by Rasp et al. (2020), designed with the aim to accelerate progress in data-driven weather modeling. {WeatherBench} 2 consists of an open-source evaluation framework, publicly available training, ground truth and baseline data as well as a continuously updated website with the latest metrics and state-of-the-art models: https://sites.research.google/weatherbench. This paper describes the design principles of the evaluation framework and presents results for current state-of-the-art physical and data-driven weather models. The metrics are based on established practices for evaluating weather forecasts at leading operational weather centers. We define a set of headline scores to provide an overview of model performance. In addition, we also discuss caveats in the current evaluation setup and challenges for the future of data-driven weather forecasting.},
	number = {{arXiv}:2308.15560},
	publisher = {{arXiv}},
	author = {Rasp, Stephan and Hoyer, Stephan and Merose, Alexander and Langmore, Ian and Battaglia, Peter and Russel, Tyler and Sanchez-Gonzalez, Alvaro and Yang, Vivian and Carver, Rob and Agrawal, Shreya and Chantry, Matthew and Bouallegue, Zied Ben and Dueben, Peter and Bromberg, Carla and Sisk, Jared and Barrington, Luke and Bell, Aaron and Sha, Fei},
	urldate = {2024-05-29},
	date = {2024-01-26},
	eprinttype = {arxiv},
	eprint = {2308.15560 [physics]},
	keywords = {data-driven weather prediction},
}

@article{rasp_weatherbench_2020,
	title = {{WeatherBench}: A benchmark dataset for data-driven weather forecasting},
	volume = {12},
	issn = {1942-2466, 1942-2466},
	url = {http://arxiv.org/abs/2002.00469},
	doi = {10.1029/2020MS002203},
	shorttitle = {{WeatherBench}},
	abstract = {Data-driven approaches, most prominently deep learning, have become powerful tools for prediction in many domains. A natural question to ask is whether data-driven methods could also be used to predict global weather patterns days in advance. First studies show promise but the lack of a common dataset and evaluation metrics make inter-comparison between studies difficult. Here we present a benchmark dataset for data-driven medium-range weather forecasting, a topic of high scientific interest for atmospheric and computer scientists alike. We provide data derived from the {ERA}5 archive that has been processed to facilitate the use in machine learning models. We propose simple and clear evaluation metrics which will enable a direct comparison between different methods. Further, we provide baseline scores from simple linear regression techniques, deep learning models, as well as purely physical forecasting models. The dataset is publicly available at https://github.com/pangeo-data/{WeatherBench} and the companion code is reproducible with tutorials for getting started. We hope that this dataset will accelerate research in data-driven weather forecasting.},
	pages = {e2020MS002203},
	number = {11},
	journaltitle = {Journal of Advances in Modeling Earth Systems},
	shortjournal = {J Adv Model Earth Syst},
	author = {Rasp, Stephan and Dueben, Peter D. and Scher, Sebastian and Weyn, Jonathan A. and Mouatadid, Soukayna and Thuerey, Nils},
	urldate = {2024-06-06},
	date = {2020-11},
	eprinttype = {arxiv},
	eprint = {2002.00469 [physics, stat]},
	keywords = {data-driven weather prediction},
}

@misc{allen_weighted_2022,
	title = {Weighted verification tools to evaluate univariate and multivariate forecasts for high-impact weather events},
	url = {http://arxiv.org/abs/2209.04872},
	doi = {10.48550/arXiv.2209.04872},
	abstract = {To mitigate the impacts associated with adverse weather conditions, meteorological services issue weather warnings to the general public. These warnings rely heavily on forecasts issued by underlying prediction systems. When deciding which prediction system(s) to utilise to construct warnings, it is important to compare systems in their ability to forecast the occurrence and severity of extreme weather events. However, evaluating forecasts for extreme events is known to be a challenging task. This is exacerbated further by the fact that high-impact weather often manifests as a result of several confounding features, a realisation that has led to considerable research on so-called compound weather events. Both univariate and multivariate methods are therefore required to evaluate forecasts for high-impact weather. In this paper, we discuss weighted verification tools, which allow particular outcomes to be emphasised during forecast evaluation. We review and compare different approaches to construct weighted scoring rules, both in a univariate and multivariate setting, and we leverage existing results on weighted scores to introduce weighted probability integral transform ({PIT}) histograms, allowing forecast calibration to be assessed conditionally on particular outcomes having occurred. To illustrate the practical benefit afforded by these weighted verification tools, they are employed in a case study to evaluate forecasts for extreme heat events issued by the Swiss Federal Office of Meteorology and Climatology ({MeteoSwiss}).},
	number = {{arXiv}:2209.04872},
	publisher = {{arXiv}},
	author = {Allen, Sam and Bhend, Jonas and Martius, Olivia and Ziegel, Johanna},
	urldate = {2024-05-27},
	date = {2022-09-11},
	eprinttype = {arxiv},
	eprint = {2209.04872 [stat]},
	keywords = {scoring rules, verification},
}

@article{murphy_what_1993,
	title = {What Is a Good Forecast? An Essay on the Nature of Goodness in Weather Forecasting},
	volume = {8},
	issn = {1520-0434, 0882-8156},
	url = {https://journals.ametsoc.org/view/journals/wefo/8/2/1520-0434_1993_008_0281_wiagfa_2_0_co_2.xml},
	doi = {10.1175/1520-0434(1993)008<0281:WIAGFA>2.0.CO;2},
	shorttitle = {What Is a Good Forecast?},
	abstract = {Abstract Differences of opinion exist among forecasters—and between forecasters and users—regarding the meaning of the phrase “good (bad) weather forecasts.” These differences of opinion are fueled by a lack of clarity and/or understanding concerning the nature of goodness in weather forecasting. This lack of clarity and understanding complicates the processes of formulating and evaluating weather forecasts and undermines their ultimate usefulness. Three distinct types of goodness are identified in this paper: 1) the correspondence between forecasters’ judgments and their forecasts (type 1 goodness, or consistency), 2) the correspondence between the forecasts and the matching observations (type 2 goodness, or quality), and 3) the incremental economic and/or other benefits realized by decision makers through the use of the forecasts (type 3 goodness, or value). Each type of goodness is defined and described in some detail. In addition, issues related to the measurement of consistency, quality, and value are discussed. Relationships among the three types of goodness are also considered. It is shown by example that the level of consistency directly impacts the levels of both quality and value. Moreover, recent studies of quality/value relationships have revealed that these relationships are inherently nonlinear and may not be monotonic unless the multifaceted nature of quality is respected. Some implications of these considerations for various practices related to operational forecasting are discussed. Changes in these practices that could enhance the goodness of weather forecasts in one or more respects are identified.},
	pages = {281--293},
	number = {2},
	journaltitle = {Weather and Forecasting},
	author = {Murphy, Allan H.},
	urldate = {2024-03-29},
	date = {1993-06-01},
	keywords = {economic value, verification, weather and climate services},
}

@article{millner_what_2009,
	title = {What Is the True Value of Forecasts?},
	volume = {1},
	issn = {1948-8327, 1948-8335},
	url = {https://journals.ametsoc.org/view/journals/wcas/1/1/2009wcas1001_1.xml},
	doi = {10.1175/2009WCAS1001.1},
	abstract = {Abstract Understanding the economic value of weather and climate forecasts is of tremendous practical importance. Traditional models that have attempted to gauge forecast value have focused on a best-case scenario, in which forecast users are assumed to be statistically sophisticated, hyperrational decision makers with perfect knowledge and understanding of forecast performance. These models provide a normative benchmark for assessing forecast value, but say nothing about the value that actual forecast users realize. Real forecast users are subject to a variety of behavioral effects and informational constraints that violate the assumptions of normative models. In this paper, one of the normative assumptions about user behavior is relaxed—users are no longer assumed to be in possession of a perfect statistical understanding of forecast performance. In the case of a cost–loss decision, it is shown that a model of users’ forecast use choices based on the psychological theory of reinforcement learning leads to a behavioral adjustment factor that lowers the relative value score that the user achieves. The dependence of this factor on the user’s decision parameters (the ratio of costs to losses) and the forecast skill is deduced. Differences between the losses predicted by the behavioral and normative models are greatest for users with intermediate cost–loss ratios, and when forecasts have intermediate skill. The relevance of the model as a tool for directing user education initiatives is briefly discussed, and a direction for future research is proposed.},
	pages = {22--37},
	number = {1},
	journaltitle = {Weather, Climate, and Society},
	author = {Millner, Antony},
	urldate = {2024-03-29},
	date = {2009-10-01},
	keywords = {economic value, weather and climate services},
}

@article{dujardin_windtopo_2022,
	title = {Wind‐Topo: Downscaling near‐surface wind fields to high‐resolution topography in highly complex terrain with deep learning},
	volume = {148},
	issn = {0035-9009, 1477-870X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qj.4265},
	doi = {10.1002/qj.4265},
	shorttitle = {Wind‐Topo},
	pages = {1368--1388},
	number = {744},
	journaltitle = {Quarterly Journal of the Royal Meteorological Society},
	author = {Dujardin, Jérôme and Lehning, Michael},
	urldate = {2023-05-15},
	date = {2022-04},
	langid = {english},
	keywords = {complex terrain, convolutional neural network, deep learning, downscaling, orographic effect, wind},
}
